{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x40CuzhpNhE-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZoluXOdNhE_",
        "outputId": "66d95b05-ca99-43fb-d084-f539b5ed5d28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Device configuration GPU/CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu_WMuiYNhE_",
        "outputId": "0e632349-881f-4d6a-c4d2-c522d27c6cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUE4DhP7NhFA"
      },
      "source": [
        "## VGG-16 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gFJZgfjxNhFB"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3XXdSy52NhFB"
      },
      "outputs": [],
      "source": [
        "# # Hyperparameters\n",
        "num_classes = 10\n",
        "# num_epochs = 30\n",
        "# batch_size = 64\n",
        "# learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps49sCQQNhFC",
        "tags": []
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XX0TUApNhFC",
        "outputId": "eb48f8ad-7a1c-4fff-93fe-9a7bc8651828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-100 dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2761))\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split dataset into train and validation sets (80% train, 20% validation)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i7NF-kDNhFD",
        "outputId": "6d46237f-caf6-4223-f4e4-72442b19fd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([64, 3, 32, 32]), Labels: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for inputs, labels in train_loader:\n",
        "    print(f\"Input shape: {inputs.shape}, Labels: {labels.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WQZM0X2CNhFD"
      },
      "outputs": [],
      "source": [
        "# model = VGG16(num_classes=num_classes).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "57vOFZOfNhFD"
      },
      "outputs": [],
      "source": [
        "# # Hyperparameters\n",
        "num_classes = 10\n",
        "# num_epochs = 30\n",
        "# batch_size = 64\n",
        "# learning_rate = 0.01\n",
        "\n",
        "config_1 = {\n",
        "    \"num_epochs\": 50,\n",
        "    \"batch_size\": 128,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"StepLR\",\n",
        "        \"step_size\": 15,\n",
        "        \"gamma\": 0.1\n",
        "    }\n",
        "}\n",
        "\n",
        "config_2 = {\n",
        "    \"num_epochs\": 40,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"optimizer\": \"SGD\",\n",
        "    \"momentum\": 0.9,\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"CosineAnnealingLR\",\n",
        "        \"T_max\": 40\n",
        "    }\n",
        "}\n",
        "\n",
        "config_3 = {\n",
        "    \"num_epochs\": 100,\n",
        "    \"batch_size\": 32,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"ReduceLROnPlateau\",\n",
        "        \"mode\": \"min\",\n",
        "        \"factor\": 0.1,\n",
        "        \"patience\": 10\n",
        "    },\n",
        "    \"regularization\": {\n",
        "        \"dropout_rate\": 0.5\n",
        "    }\n",
        "}\n",
        "\n",
        "def config_test(selected_config):\n",
        "    print(selected_config[\"num_epochs\"])\n",
        "    # Atribuindo os hiperparâmetros escolhidos\n",
        "    num_epochs = selected_config[\"num_epochs\"]\n",
        "    batch_size = selected_config[\"batch_size\"]\n",
        "    learning_rate = selected_config[\"learning_rate\"]\n",
        "\n",
        "    model = VGG16(num_classes=num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if selected_config[\"optimizer\"] == \"Adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif selected_config[\"optimizer\"] == \"SGD\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=selected_config.get(\"momentum\", 0))\n",
        "\n",
        "    # Configurando o scheduler baseado na configuração\n",
        "    if selected_config[\"scheduler\"][\"type\"] == \"StepLR\":\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            optimizer,\n",
        "            step_size=selected_config[\"scheduler\"][\"step_size\"],\n",
        "            gamma=selected_config[\"scheduler\"][\"gamma\"]\n",
        "        )\n",
        "    elif selected_config[\"scheduler\"][\"type\"] == \"CosineAnnealingLR\":\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=selected_config[\"scheduler\"][\"T_max\"]\n",
        "        )\n",
        "    elif selected_config[\"scheduler\"][\"type\"] == \"ReduceLROnPlateau\":\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode=selected_config[\"scheduler\"][\"mode\"],\n",
        "            factor=selected_config[\"scheduler\"][\"factor\"],\n",
        "            patience=selected_config[\"scheduler\"][\"patience\"]\n",
        "        )\n",
        "\n",
        "\n",
        "    return num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtvmzsrNhFE"
      },
      "source": [
        "# Training Original VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(dataloader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "RVikul5zi1nE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate=1.5, batch_size=10):\n",
        "  total_step = len(train_loader)\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, (inputs, labels) in enumerate(train_loader):\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % 100 == 99:  # Print every 100 mini-batches\n",
        "              print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "              running_loss = 0.0\n",
        "\n",
        "      # Validate the model\n",
        "      val_loss , val_accuracy = validate(model, val_loader)\n",
        "      print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "3kY4ncykFNXG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, dataloader):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "emlWNyTsI5Ol"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "pJsDHrk-ZbOs"
      },
      "source": [
        "### Test 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8rn_wX4qNhFE",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "cb716a6d-8d99-4cd2-ab43-d7bc982fae33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "Epoch [1/50], Step [100/625], Loss: 2.3983\n",
            "Epoch [1/50], Step [200/625], Loss: 2.1476\n",
            "Epoch [1/50], Step [300/625], Loss: 2.0277\n",
            "Epoch [1/50], Step [400/625], Loss: 1.9565\n",
            "Epoch [1/50], Step [500/625], Loss: 1.9542\n",
            "Epoch [1/50], Step [600/625], Loss: 1.9375\n",
            "Epoch [1/50], Validation Loss: 1.8950, Validation Accuracy: 20.96%\n",
            "Epoch [2/50], Step [100/625], Loss: 1.9705\n",
            "Epoch [2/50], Step [200/625], Loss: 1.9053\n",
            "Epoch [2/50], Step [300/625], Loss: 1.8797\n",
            "Epoch [2/50], Step [400/625], Loss: 1.8673\n",
            "Epoch [2/50], Step [500/625], Loss: 1.8665\n",
            "Epoch [2/50], Step [600/625], Loss: 1.8510\n",
            "Epoch [2/50], Validation Loss: 1.8468, Validation Accuracy: 24.58%\n",
            "Epoch [3/50], Step [100/625], Loss: 1.8237\n",
            "Epoch [3/50], Step [200/625], Loss: 1.7756\n",
            "Epoch [3/50], Step [300/625], Loss: 1.7231\n",
            "Epoch [3/50], Step [400/625], Loss: 1.6742\n",
            "Epoch [3/50], Step [500/625], Loss: 1.6365\n",
            "Epoch [3/50], Step [600/625], Loss: 1.6431\n",
            "Epoch [3/50], Validation Loss: 1.5943, Validation Accuracy: 37.06%\n",
            "Epoch [4/50], Step [100/625], Loss: 1.5975\n",
            "Epoch [4/50], Step [200/625], Loss: 1.5461\n",
            "Epoch [4/50], Step [300/625], Loss: 1.5410\n",
            "Epoch [4/50], Step [400/625], Loss: 1.4994\n",
            "Epoch [4/50], Step [500/625], Loss: 1.4935\n",
            "Epoch [4/50], Step [600/625], Loss: 1.4880\n",
            "Epoch [4/50], Validation Loss: 1.4373, Validation Accuracy: 45.81%\n",
            "Epoch [5/50], Step [100/625], Loss: 1.3996\n",
            "Epoch [5/50], Step [200/625], Loss: 1.4286\n",
            "Epoch [5/50], Step [300/625], Loss: 1.3735\n",
            "Epoch [5/50], Step [400/625], Loss: 1.3229\n",
            "Epoch [5/50], Step [500/625], Loss: 1.3281\n",
            "Epoch [5/50], Step [600/625], Loss: 1.2869\n",
            "Epoch [5/50], Validation Loss: 1.2622, Validation Accuracy: 53.60%\n",
            "Epoch [6/50], Step [100/625], Loss: 1.2809\n",
            "Epoch [6/50], Step [200/625], Loss: 1.2482\n",
            "Epoch [6/50], Step [300/625], Loss: 1.2134\n",
            "Epoch [6/50], Step [400/625], Loss: 1.1890\n",
            "Epoch [6/50], Step [500/625], Loss: 1.1498\n",
            "Epoch [6/50], Step [600/625], Loss: 1.1761\n",
            "Epoch [6/50], Validation Loss: 1.1753, Validation Accuracy: 59.01%\n",
            "Epoch [7/50], Step [100/625], Loss: 1.1209\n",
            "Epoch [7/50], Step [200/625], Loss: 1.0931\n",
            "Epoch [7/50], Step [300/625], Loss: 1.0975\n",
            "Epoch [7/50], Step [400/625], Loss: 1.1089\n",
            "Epoch [7/50], Step [500/625], Loss: 1.0612\n",
            "Epoch [7/50], Step [600/625], Loss: 1.0862\n",
            "Epoch [7/50], Validation Loss: 1.1293, Validation Accuracy: 59.76%\n",
            "Epoch [8/50], Step [100/625], Loss: 1.0330\n",
            "Epoch [8/50], Step [200/625], Loss: 1.0299\n",
            "Epoch [8/50], Step [300/625], Loss: 1.0165\n",
            "Epoch [8/50], Step [400/625], Loss: 0.9608\n",
            "Epoch [8/50], Step [500/625], Loss: 0.9642\n",
            "Epoch [8/50], Step [600/625], Loss: 0.9898\n",
            "Epoch [8/50], Validation Loss: 1.0042, Validation Accuracy: 65.73%\n",
            "Epoch [9/50], Step [100/625], Loss: 0.9521\n",
            "Epoch [9/50], Step [200/625], Loss: 0.9094\n",
            "Epoch [9/50], Step [300/625], Loss: 0.9326\n",
            "Epoch [9/50], Step [400/625], Loss: 0.9400\n",
            "Epoch [9/50], Step [500/625], Loss: 0.8804\n",
            "Epoch [9/50], Step [600/625], Loss: 0.8972\n",
            "Epoch [9/50], Validation Loss: 0.9011, Validation Accuracy: 68.89%\n",
            "Epoch [10/50], Step [100/625], Loss: 0.8334\n",
            "Epoch [10/50], Step [200/625], Loss: 0.8629\n",
            "Epoch [10/50], Step [300/625], Loss: 0.8400\n",
            "Epoch [10/50], Step [400/625], Loss: 0.8509\n",
            "Epoch [10/50], Step [500/625], Loss: 0.8326\n",
            "Epoch [10/50], Step [600/625], Loss: 0.8214\n",
            "Epoch [10/50], Validation Loss: 0.8807, Validation Accuracy: 69.20%\n",
            "Epoch [11/50], Step [100/625], Loss: 0.7774\n",
            "Epoch [11/50], Step [200/625], Loss: 0.7878\n",
            "Epoch [11/50], Step [300/625], Loss: 0.7774\n",
            "Epoch [11/50], Step [400/625], Loss: 0.7920\n",
            "Epoch [11/50], Step [500/625], Loss: 0.7722\n",
            "Epoch [11/50], Step [600/625], Loss: 0.7660\n",
            "Epoch [11/50], Validation Loss: 0.8997, Validation Accuracy: 70.70%\n",
            "Epoch [12/50], Step [100/625], Loss: 0.7436\n",
            "Epoch [12/50], Step [200/625], Loss: 0.7491\n",
            "Epoch [12/50], Step [300/625], Loss: 0.7231\n",
            "Epoch [12/50], Step [400/625], Loss: 0.7150\n",
            "Epoch [12/50], Step [500/625], Loss: 0.7282\n",
            "Epoch [12/50], Step [600/625], Loss: 0.6997\n",
            "Epoch [12/50], Validation Loss: 0.7652, Validation Accuracy: 75.41%\n",
            "Epoch [13/50], Step [100/625], Loss: 0.6736\n",
            "Epoch [13/50], Step [200/625], Loss: 0.6756\n",
            "Epoch [13/50], Step [300/625], Loss: 0.6587\n",
            "Epoch [13/50], Step [400/625], Loss: 0.6771\n",
            "Epoch [13/50], Step [500/625], Loss: 0.7088\n",
            "Epoch [13/50], Step [600/625], Loss: 0.6636\n",
            "Epoch [13/50], Validation Loss: 0.6986, Validation Accuracy: 76.92%\n",
            "Epoch [14/50], Step [100/625], Loss: 0.6495\n",
            "Epoch [14/50], Step [200/625], Loss: 0.6314\n",
            "Epoch [14/50], Step [300/625], Loss: 0.6353\n",
            "Epoch [14/50], Step [400/625], Loss: 0.6243\n",
            "Epoch [14/50], Step [500/625], Loss: 0.6403\n",
            "Epoch [14/50], Step [600/625], Loss: 0.6336\n",
            "Epoch [14/50], Validation Loss: 0.7665, Validation Accuracy: 75.38%\n",
            "Epoch [15/50], Step [100/625], Loss: 0.5861\n",
            "Epoch [15/50], Step [200/625], Loss: 0.5788\n",
            "Epoch [15/50], Step [300/625], Loss: 0.5832\n",
            "Epoch [15/50], Step [400/625], Loss: 0.5920\n",
            "Epoch [15/50], Step [500/625], Loss: 0.5847\n",
            "Epoch [15/50], Step [600/625], Loss: 0.6114\n",
            "Epoch [15/50], Validation Loss: 0.7306, Validation Accuracy: 76.97%\n",
            "Epoch [16/50], Step [100/625], Loss: 0.5137\n",
            "Epoch [16/50], Step [200/625], Loss: 0.4490\n",
            "Epoch [16/50], Step [300/625], Loss: 0.4614\n",
            "Epoch [16/50], Step [400/625], Loss: 0.4453\n",
            "Epoch [16/50], Step [500/625], Loss: 0.4473\n",
            "Epoch [16/50], Step [600/625], Loss: 0.4242\n",
            "Epoch [16/50], Validation Loss: 0.5752, Validation Accuracy: 81.49%\n",
            "Epoch [17/50], Step [100/625], Loss: 0.4293\n",
            "Epoch [17/50], Step [200/625], Loss: 0.4495\n",
            "Epoch [17/50], Step [300/625], Loss: 0.4104\n",
            "Epoch [17/50], Step [400/625], Loss: 0.4212\n",
            "Epoch [17/50], Step [500/625], Loss: 0.4282\n",
            "Epoch [17/50], Step [600/625], Loss: 0.4238\n",
            "Epoch [17/50], Validation Loss: 0.5542, Validation Accuracy: 82.07%\n",
            "Epoch [18/50], Step [100/625], Loss: 0.4122\n",
            "Epoch [18/50], Step [200/625], Loss: 0.4074\n",
            "Epoch [18/50], Step [300/625], Loss: 0.4069\n",
            "Epoch [18/50], Step [400/625], Loss: 0.4275\n",
            "Epoch [18/50], Step [500/625], Loss: 0.3941\n",
            "Epoch [18/50], Step [600/625], Loss: 0.4026\n",
            "Epoch [18/50], Validation Loss: 0.5528, Validation Accuracy: 81.79%\n",
            "Epoch [19/50], Step [100/625], Loss: 0.3933\n",
            "Epoch [19/50], Step [200/625], Loss: 0.3870\n",
            "Epoch [19/50], Step [300/625], Loss: 0.3898\n",
            "Epoch [19/50], Step [400/625], Loss: 0.3992\n",
            "Epoch [19/50], Step [500/625], Loss: 0.4056\n",
            "Epoch [19/50], Step [600/625], Loss: 0.3933\n",
            "Epoch [19/50], Validation Loss: 0.5268, Validation Accuracy: 83.12%\n",
            "Epoch [20/50], Step [100/625], Loss: 0.3881\n",
            "Epoch [20/50], Step [200/625], Loss: 0.3860\n",
            "Epoch [20/50], Step [300/625], Loss: 0.3841\n",
            "Epoch [20/50], Step [400/625], Loss: 0.3878\n",
            "Epoch [20/50], Step [500/625], Loss: 0.3934\n",
            "Epoch [20/50], Step [600/625], Loss: 0.3786\n",
            "Epoch [20/50], Validation Loss: 0.5409, Validation Accuracy: 82.67%\n",
            "Epoch [21/50], Step [100/625], Loss: 0.3686\n",
            "Epoch [21/50], Step [200/625], Loss: 0.3692\n",
            "Epoch [21/50], Step [300/625], Loss: 0.3821\n",
            "Epoch [21/50], Step [400/625], Loss: 0.3904\n",
            "Epoch [21/50], Step [500/625], Loss: 0.3695\n",
            "Epoch [21/50], Step [600/625], Loss: 0.3940\n",
            "Epoch [21/50], Validation Loss: 0.5431, Validation Accuracy: 82.65%\n",
            "Epoch [22/50], Step [100/625], Loss: 0.3647\n",
            "Epoch [22/50], Step [200/625], Loss: 0.3774\n",
            "Epoch [22/50], Step [300/625], Loss: 0.3540\n",
            "Epoch [22/50], Step [400/625], Loss: 0.3734\n",
            "Epoch [22/50], Step [500/625], Loss: 0.3706\n",
            "Epoch [22/50], Step [600/625], Loss: 0.3805\n",
            "Epoch [22/50], Validation Loss: 0.5251, Validation Accuracy: 83.20%\n",
            "Epoch [23/50], Step [100/625], Loss: 0.3464\n",
            "Epoch [23/50], Step [200/625], Loss: 0.3591\n",
            "Epoch [23/50], Step [300/625], Loss: 0.3582\n",
            "Epoch [23/50], Step [400/625], Loss: 0.3449\n",
            "Epoch [23/50], Step [500/625], Loss: 0.3609\n",
            "Epoch [23/50], Step [600/625], Loss: 0.3733\n",
            "Epoch [23/50], Validation Loss: 0.5298, Validation Accuracy: 83.26%\n",
            "Epoch [24/50], Step [100/625], Loss: 0.3354\n",
            "Epoch [24/50], Step [200/625], Loss: 0.3668\n",
            "Epoch [24/50], Step [300/625], Loss: 0.3637\n",
            "Epoch [24/50], Step [400/625], Loss: 0.3361\n",
            "Epoch [24/50], Step [500/625], Loss: 0.3529\n",
            "Epoch [24/50], Step [600/625], Loss: 0.3618\n",
            "Epoch [24/50], Validation Loss: 0.5204, Validation Accuracy: 83.45%\n",
            "Epoch [25/50], Step [100/625], Loss: 0.3488\n",
            "Epoch [25/50], Step [200/625], Loss: 0.3450\n",
            "Epoch [25/50], Step [300/625], Loss: 0.3536\n",
            "Epoch [25/50], Step [400/625], Loss: 0.3471\n",
            "Epoch [25/50], Step [500/625], Loss: 0.3357\n",
            "Epoch [25/50], Step [600/625], Loss: 0.3427\n",
            "Epoch [25/50], Validation Loss: 0.5148, Validation Accuracy: 83.33%\n",
            "Epoch [26/50], Step [100/625], Loss: 0.3298\n",
            "Epoch [26/50], Step [200/625], Loss: 0.3380\n",
            "Epoch [26/50], Step [300/625], Loss: 0.3211\n",
            "Epoch [26/50], Step [400/625], Loss: 0.3340\n",
            "Epoch [26/50], Step [500/625], Loss: 0.3262\n",
            "Epoch [26/50], Step [600/625], Loss: 0.3320\n",
            "Epoch [26/50], Validation Loss: 0.5103, Validation Accuracy: 83.99%\n",
            "Epoch [27/50], Step [100/625], Loss: 0.3218\n",
            "Epoch [27/50], Step [200/625], Loss: 0.3230\n",
            "Epoch [27/50], Step [300/625], Loss: 0.3265\n",
            "Epoch [27/50], Step [400/625], Loss: 0.3358\n",
            "Epoch [27/50], Step [500/625], Loss: 0.3291\n",
            "Epoch [27/50], Step [600/625], Loss: 0.3287\n",
            "Epoch [27/50], Validation Loss: 0.5141, Validation Accuracy: 83.68%\n",
            "Epoch [28/50], Step [100/625], Loss: 0.3204\n",
            "Epoch [28/50], Step [200/625], Loss: 0.3235\n",
            "Epoch [28/50], Step [300/625], Loss: 0.3139\n",
            "Epoch [28/50], Step [400/625], Loss: 0.3103\n",
            "Epoch [28/50], Step [500/625], Loss: 0.3414\n",
            "Epoch [28/50], Step [600/625], Loss: 0.3231\n",
            "Epoch [28/50], Validation Loss: 0.5206, Validation Accuracy: 84.19%\n",
            "Epoch [29/50], Step [100/625], Loss: 0.3141\n",
            "Epoch [29/50], Step [200/625], Loss: 0.3055\n",
            "Epoch [29/50], Step [300/625], Loss: 0.3177\n",
            "Epoch [29/50], Step [400/625], Loss: 0.3229\n",
            "Epoch [29/50], Step [500/625], Loss: 0.3188\n",
            "Epoch [29/50], Step [600/625], Loss: 0.3289\n",
            "Epoch [29/50], Validation Loss: 0.5093, Validation Accuracy: 84.20%\n",
            "Epoch [30/50], Step [100/625], Loss: 0.3056\n",
            "Epoch [30/50], Step [200/625], Loss: 0.3132\n",
            "Epoch [30/50], Step [300/625], Loss: 0.3149\n",
            "Epoch [30/50], Step [400/625], Loss: 0.3279\n",
            "Epoch [30/50], Step [500/625], Loss: 0.3014\n",
            "Epoch [30/50], Step [600/625], Loss: 0.3101\n",
            "Epoch [30/50], Validation Loss: 0.5192, Validation Accuracy: 83.71%\n",
            "Epoch [31/50], Step [100/625], Loss: 0.3031\n",
            "Epoch [31/50], Step [200/625], Loss: 0.3057\n",
            "Epoch [31/50], Step [300/625], Loss: 0.2821\n",
            "Epoch [31/50], Step [400/625], Loss: 0.2935\n",
            "Epoch [31/50], Step [500/625], Loss: 0.2957\n",
            "Epoch [31/50], Step [600/625], Loss: 0.2997\n",
            "Epoch [31/50], Validation Loss: 0.5191, Validation Accuracy: 84.13%\n",
            "Epoch [32/50], Step [100/625], Loss: 0.2731\n",
            "Epoch [32/50], Step [200/625], Loss: 0.2892\n",
            "Epoch [32/50], Step [300/625], Loss: 0.3120\n",
            "Epoch [32/50], Step [400/625], Loss: 0.2808\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c8a2f67d9a93>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_t2_test.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-6fcef41abd30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Print every 100 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_1)\n",
        "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
        "torch.save(model.state_dict(), \"model_t2_test.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvaGF1pXNhFE"
      },
      "source": [
        "The code in the cell looks correct and should work without any errors, given that all the necessary variables and modules are already defined and imported in the previous cells. However, to ensure that the code runs smoothly, you should make sure that the `train_loader`, `val_loader`, `model`, `criterion`, `optimizer`, `device`, and `num_epochs` are properly defined and imported.\n",
        "\n",
        "\n",
        "\n",
        "Made changes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = calculate_accuracy(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj_msbsBJdTT",
        "outputId": "2df9fe3b-c5ac-4c4b-b79a-64823bf9764b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "iQLQ8GAqZbOu"
      },
      "source": [
        "### Test 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "collapsed": true,
        "id": "zsTRenpCZbOu"
      },
      "outputs": [],
      "source": [
        "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
        "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
        "torch.save(model.state_dict(), \"model_t2_test2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = calculate_accuracy(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCIjGjlsJluy",
        "outputId": "f9ada8b3-a6f0-4d88-d3bd-07bb73afa0f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "Yn1CV0LbZbOu"
      },
      "source": [
        "### Test 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "jqqS2ljFZbOu",
        "outputId": "7aa21862-0125-473f-d0ca-69186753220a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "Epoch [1/100], Step [100/625], Loss: 2.2177\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-7f859e7929e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_t2_test3.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-6fcef41abd30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-a8832f94332c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_3)\n",
        "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
        "torch.save(model.state_dict(), \"model_t2_test3.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = calculate_accuracy(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvD1Ge4IIv_R",
        "outputId": "68c98976-f3b9-4ab0-cd32-ea04f621fc24"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 21.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw7H8lkoNhFF"
      },
      "source": [
        "# Training Pruned VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prune models"
      ],
      "metadata": {
        "id": "YWSC-Bf2uYff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Function to apply pruning to specific layers -> LOCAL\n",
        "def apply_pruning(model, conv_layers_, pruning_method, amount, structured=False):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for name, layer in conv_layers_:\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        if structured:\n",
        "            if pruning_method == 'l1_structured':\n",
        "                prune.ln_structured(layer, name='weight', amount=amount, n=1, dim=0)  # Prune output channels\n",
        "                print(f\"Applied L1 Structured pruning to layer: {name}\")\n",
        "            elif pruning_method == 'l2_structured':\n",
        "                prune.ln_structured(layer, name='weight', amount=amount, n=2, dim=0)\n",
        "                print(f\"Applied L2 Structured pruning to layer: {name}\")\n",
        "            elif pruning_method == 'random_structured':\n",
        "                prune.random_structured(layer, name='weight', amount=amount, dim=0)\n",
        "                print(f\"Applied Random Structured pruning to layer: {name}\")\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported structured pruning method: {pruning_method}\")\n",
        "        else:\n",
        "            if pruning_method == 'l1_unstructured':\n",
        "                prune.l1_unstructured(layer, name='weight', amount=amount)\n",
        "                print(f\"Applied L1 Unstructured pruning to layer: {name}\")\n",
        "            # elif pruning_method == 'l2_unstructured':\n",
        "            #     prune.l2_unstructured(layer, name='weight', amount=amount)\n",
        "            #     print(f\"Applied L2 Unstructured pruning to layer: {name}\")\n",
        "            elif pruning_method == 'random_unstructured':\n",
        "                prune.random_unstructured(layer, name='weight', amount=amount)\n",
        "                print(f\"Applied Random Unstructured pruning to layer: {name}\")\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported unstructured pruning method: {pruning_method}\")"
      ],
      "metadata": {
        "id": "LlF14kojJvmm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to enforce pruning masks\n",
        "def enforce_pruning_masks(model):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            if hasattr(module, 'weight_mask'):\n",
        "                module.weight.data.mul_(module.weight_mask)"
      ],
      "metadata": {
        "id": "Y-uVsA5xV5nh"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all convolutional layers in VGG16\n",
        "def get_conv_layers(model):\n",
        "    conv_layers = []\n",
        "    for name, module in model.features.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            conv_layers.append((name, module))\n",
        "    return conv_layers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1NAkPjVpI4pI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, num_classes=10):\n",
        "    model = VGG16(num_classes)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    return model"
      ],
      "metadata": {
        "id": "EQAFcOHxjHMd"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Pruning Conv2d layers - 10%"
      ],
      "metadata": {
        "id": "oy1tISJI_4-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
        "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
        "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
        "\n",
        "for method in pruning_methods_all:\n",
        "  # Load pretrained model\n",
        "  model = load_model(\"/content/model_t2.h5\")\n",
        "\n",
        "  # Prune 20% of weights in all Conv2d layers\n",
        "  conv_layers = get_conv_layers(model)\n",
        "  if method in pruning_methods_structured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.1, structured=True)\n",
        "  elif method in pruning_methods_unstructured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.1, structured=False)\n",
        "\n",
        "  # # Consolidate pruning\n",
        "  # for layer in model.modules():\n",
        "  #     if isinstance(layer, (nn.Conv2d)):\n",
        "  #         prune.remove(layer, 'weight')\n",
        "\n",
        "  torch.save(model.state_dict(), f'vgg16_pruned_allConv2dlayers_{method}_0.1.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_XNJKFVo_8sw",
        "outputId": "03c150f7-1631-4817-e41c-2ea3d2823a48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0f8825b257a2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied L1 Structured pruning to layer: 0\n",
            "Applied L1 Structured pruning to layer: 3\n",
            "Applied L1 Structured pruning to layer: 7\n",
            "Applied L1 Structured pruning to layer: 10\n",
            "Applied L1 Structured pruning to layer: 14\n",
            "Applied L1 Structured pruning to layer: 17\n",
            "Applied L1 Structured pruning to layer: 20\n",
            "Applied L1 Structured pruning to layer: 24\n",
            "Applied L1 Structured pruning to layer: 27\n",
            "Applied L1 Structured pruning to layer: 30\n",
            "Applied L1 Structured pruning to layer: 34\n",
            "Applied L1 Structured pruning to layer: 37\n",
            "Applied L1 Structured pruning to layer: 40\n",
            "Applied L2 Structured pruning to layer: 0\n",
            "Applied L2 Structured pruning to layer: 3\n",
            "Applied L2 Structured pruning to layer: 7\n",
            "Applied L2 Structured pruning to layer: 10\n",
            "Applied L2 Structured pruning to layer: 14\n",
            "Applied L2 Structured pruning to layer: 17\n",
            "Applied L2 Structured pruning to layer: 20\n",
            "Applied L2 Structured pruning to layer: 24\n",
            "Applied L2 Structured pruning to layer: 27\n",
            "Applied L2 Structured pruning to layer: 30\n",
            "Applied L2 Structured pruning to layer: 34\n",
            "Applied L2 Structured pruning to layer: 37\n",
            "Applied L2 Structured pruning to layer: 40\n",
            "Applied Random Structured pruning to layer: 0\n",
            "Applied Random Structured pruning to layer: 3\n",
            "Applied Random Structured pruning to layer: 7\n",
            "Applied Random Structured pruning to layer: 10\n",
            "Applied Random Structured pruning to layer: 14\n",
            "Applied Random Structured pruning to layer: 17\n",
            "Applied Random Structured pruning to layer: 20\n",
            "Applied Random Structured pruning to layer: 24\n",
            "Applied Random Structured pruning to layer: 27\n",
            "Applied Random Structured pruning to layer: 30\n",
            "Applied Random Structured pruning to layer: 34\n",
            "Applied Random Structured pruning to layer: 37\n",
            "Applied Random Structured pruning to layer: 40\n",
            "Applied L1 Unstructured pruning to layer: 0\n",
            "Applied L1 Unstructured pruning to layer: 3\n",
            "Applied L1 Unstructured pruning to layer: 7\n",
            "Applied L1 Unstructured pruning to layer: 10\n",
            "Applied L1 Unstructured pruning to layer: 14\n",
            "Applied L1 Unstructured pruning to layer: 17\n",
            "Applied L1 Unstructured pruning to layer: 20\n",
            "Applied L1 Unstructured pruning to layer: 24\n",
            "Applied L1 Unstructured pruning to layer: 27\n",
            "Applied L1 Unstructured pruning to layer: 30\n",
            "Applied L1 Unstructured pruning to layer: 34\n",
            "Applied L1 Unstructured pruning to layer: 37\n",
            "Applied L1 Unstructured pruning to layer: 40\n",
            "Applied Random Unstructured pruning to layer: 0\n",
            "Applied Random Unstructured pruning to layer: 3\n",
            "Applied Random Unstructured pruning to layer: 7\n",
            "Applied Random Unstructured pruning to layer: 10\n",
            "Applied Random Unstructured pruning to layer: 14\n",
            "Applied Random Unstructured pruning to layer: 17\n",
            "Applied Random Unstructured pruning to layer: 20\n",
            "Applied Random Unstructured pruning to layer: 24\n",
            "Applied Random Unstructured pruning to layer: 27\n",
            "Applied Random Unstructured pruning to layer: 30\n",
            "Applied Random Unstructured pruning to layer: 34\n",
            "Applied Random Unstructured pruning to layer: 37\n",
            "Applied Random Unstructured pruning to layer: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Pruning Conv2d layers - 20%"
      ],
      "metadata": {
        "id": "FTSvDyH-f35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
        "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
        "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
        "\n",
        "for method in pruning_methods_all:\n",
        "  # Load pretrained model\n",
        "  model = load_model(\"/content/model_t2.h5\")\n",
        "\n",
        "  # Prune 20% of weights in all Conv2d layers\n",
        "  conv_layers = get_conv_layers(model)\n",
        "  if method in pruning_methods_structured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.2, structured=True)\n",
        "  elif method in pruning_methods_unstructured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.2, structured=False)\n",
        "\n",
        "  # # Consolidate pruning\n",
        "  # for layer in model.modules():\n",
        "  #     if isinstance(layer, (nn.Conv2d)):\n",
        "  #         prune.remove(layer, 'weight')\n",
        "\n",
        "  torch.save(model.state_dict(), f'vgg16_pruned_allConv2dlayers_{method}_0.2.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wzuFYW_8b-ML",
        "outputId": "c08fd651-408a-4dd0-f367-575ce60ecdee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0f8825b257a2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied L1 Structured pruning to layer: 0\n",
            "Applied L1 Structured pruning to layer: 3\n",
            "Applied L1 Structured pruning to layer: 7\n",
            "Applied L1 Structured pruning to layer: 10\n",
            "Applied L1 Structured pruning to layer: 14\n",
            "Applied L1 Structured pruning to layer: 17\n",
            "Applied L1 Structured pruning to layer: 20\n",
            "Applied L1 Structured pruning to layer: 24\n",
            "Applied L1 Structured pruning to layer: 27\n",
            "Applied L1 Structured pruning to layer: 30\n",
            "Applied L1 Structured pruning to layer: 34\n",
            "Applied L1 Structured pruning to layer: 37\n",
            "Applied L1 Structured pruning to layer: 40\n",
            "Applied L2 Structured pruning to layer: 0\n",
            "Applied L2 Structured pruning to layer: 3\n",
            "Applied L2 Structured pruning to layer: 7\n",
            "Applied L2 Structured pruning to layer: 10\n",
            "Applied L2 Structured pruning to layer: 14\n",
            "Applied L2 Structured pruning to layer: 17\n",
            "Applied L2 Structured pruning to layer: 20\n",
            "Applied L2 Structured pruning to layer: 24\n",
            "Applied L2 Structured pruning to layer: 27\n",
            "Applied L2 Structured pruning to layer: 30\n",
            "Applied L2 Structured pruning to layer: 34\n",
            "Applied L2 Structured pruning to layer: 37\n",
            "Applied L2 Structured pruning to layer: 40\n",
            "Applied Random Structured pruning to layer: 0\n",
            "Applied Random Structured pruning to layer: 3\n",
            "Applied Random Structured pruning to layer: 7\n",
            "Applied Random Structured pruning to layer: 10\n",
            "Applied Random Structured pruning to layer: 14\n",
            "Applied Random Structured pruning to layer: 17\n",
            "Applied Random Structured pruning to layer: 20\n",
            "Applied Random Structured pruning to layer: 24\n",
            "Applied Random Structured pruning to layer: 27\n",
            "Applied Random Structured pruning to layer: 30\n",
            "Applied Random Structured pruning to layer: 34\n",
            "Applied Random Structured pruning to layer: 37\n",
            "Applied Random Structured pruning to layer: 40\n",
            "Applied L1 Unstructured pruning to layer: 0\n",
            "Applied L1 Unstructured pruning to layer: 3\n",
            "Applied L1 Unstructured pruning to layer: 7\n",
            "Applied L1 Unstructured pruning to layer: 10\n",
            "Applied L1 Unstructured pruning to layer: 14\n",
            "Applied L1 Unstructured pruning to layer: 17\n",
            "Applied L1 Unstructured pruning to layer: 20\n",
            "Applied L1 Unstructured pruning to layer: 24\n",
            "Applied L1 Unstructured pruning to layer: 27\n",
            "Applied L1 Unstructured pruning to layer: 30\n",
            "Applied L1 Unstructured pruning to layer: 34\n",
            "Applied L1 Unstructured pruning to layer: 37\n",
            "Applied L1 Unstructured pruning to layer: 40\n",
            "Applied Random Unstructured pruning to layer: 0\n",
            "Applied Random Unstructured pruning to layer: 3\n",
            "Applied Random Unstructured pruning to layer: 7\n",
            "Applied Random Unstructured pruning to layer: 10\n",
            "Applied Random Unstructured pruning to layer: 14\n",
            "Applied Random Unstructured pruning to layer: 17\n",
            "Applied Random Unstructured pruning to layer: 20\n",
            "Applied Random Unstructured pruning to layer: 24\n",
            "Applied Random Unstructured pruning to layer: 27\n",
            "Applied Random Unstructured pruning to layer: 30\n",
            "Applied Random Unstructured pruning to layer: 34\n",
            "Applied Random Unstructured pruning to layer: 37\n",
            "Applied Random Unstructured pruning to layer: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Pruning Conv2d layers - 30%"
      ],
      "metadata": {
        "id": "8cbKcqnE-07B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
        "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
        "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
        "\n",
        "for method in pruning_methods_all:\n",
        "  # Load pretrained model\n",
        "  model = load_model(\"/content/model_t2.h5\")\n",
        "\n",
        "  # Prune 20% of weights in all Conv2d layers\n",
        "  conv_layers = get_conv_layers(model)\n",
        "  if method in pruning_methods_structured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.3, structured=True)\n",
        "  elif method in pruning_methods_unstructured:\n",
        "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.3, structured=False)\n",
        "\n",
        "  # # Consolidate pruning\n",
        "  # for layer in model.modules():\n",
        "  #     if isinstance(layer, (nn.Conv2d)):\n",
        "  #         prune.remove(layer, 'weight')\n",
        "\n",
        "  torch.save(model.state_dict(), f'vgg16_pruned_allConv2dlayers_{method}_0.3.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jJ8XBdaj-wg-",
        "outputId": "2b2fe095-a2ff-4c49-e690-a98a9e931398"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0f8825b257a2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied L1 Structured pruning to layer: 0\n",
            "Applied L1 Structured pruning to layer: 3\n",
            "Applied L1 Structured pruning to layer: 7\n",
            "Applied L1 Structured pruning to layer: 10\n",
            "Applied L1 Structured pruning to layer: 14\n",
            "Applied L1 Structured pruning to layer: 17\n",
            "Applied L1 Structured pruning to layer: 20\n",
            "Applied L1 Structured pruning to layer: 24\n",
            "Applied L1 Structured pruning to layer: 27\n",
            "Applied L1 Structured pruning to layer: 30\n",
            "Applied L1 Structured pruning to layer: 34\n",
            "Applied L1 Structured pruning to layer: 37\n",
            "Applied L1 Structured pruning to layer: 40\n",
            "Applied L2 Structured pruning to layer: 0\n",
            "Applied L2 Structured pruning to layer: 3\n",
            "Applied L2 Structured pruning to layer: 7\n",
            "Applied L2 Structured pruning to layer: 10\n",
            "Applied L2 Structured pruning to layer: 14\n",
            "Applied L2 Structured pruning to layer: 17\n",
            "Applied L2 Structured pruning to layer: 20\n",
            "Applied L2 Structured pruning to layer: 24\n",
            "Applied L2 Structured pruning to layer: 27\n",
            "Applied L2 Structured pruning to layer: 30\n",
            "Applied L2 Structured pruning to layer: 34\n",
            "Applied L2 Structured pruning to layer: 37\n",
            "Applied L2 Structured pruning to layer: 40\n",
            "Applied Random Structured pruning to layer: 0\n",
            "Applied Random Structured pruning to layer: 3\n",
            "Applied Random Structured pruning to layer: 7\n",
            "Applied Random Structured pruning to layer: 10\n",
            "Applied Random Structured pruning to layer: 14\n",
            "Applied Random Structured pruning to layer: 17\n",
            "Applied Random Structured pruning to layer: 20\n",
            "Applied Random Structured pruning to layer: 24\n",
            "Applied Random Structured pruning to layer: 27\n",
            "Applied Random Structured pruning to layer: 30\n",
            "Applied Random Structured pruning to layer: 34\n",
            "Applied Random Structured pruning to layer: 37\n",
            "Applied Random Structured pruning to layer: 40\n",
            "Applied L1 Unstructured pruning to layer: 0\n",
            "Applied L1 Unstructured pruning to layer: 3\n",
            "Applied L1 Unstructured pruning to layer: 7\n",
            "Applied L1 Unstructured pruning to layer: 10\n",
            "Applied L1 Unstructured pruning to layer: 14\n",
            "Applied L1 Unstructured pruning to layer: 17\n",
            "Applied L1 Unstructured pruning to layer: 20\n",
            "Applied L1 Unstructured pruning to layer: 24\n",
            "Applied L1 Unstructured pruning to layer: 27\n",
            "Applied L1 Unstructured pruning to layer: 30\n",
            "Applied L1 Unstructured pruning to layer: 34\n",
            "Applied L1 Unstructured pruning to layer: 37\n",
            "Applied L1 Unstructured pruning to layer: 40\n",
            "Applied Random Unstructured pruning to layer: 0\n",
            "Applied Random Unstructured pruning to layer: 3\n",
            "Applied Random Unstructured pruning to layer: 7\n",
            "Applied Random Unstructured pruning to layer: 10\n",
            "Applied Random Unstructured pruning to layer: 14\n",
            "Applied Random Unstructured pruning to layer: 17\n",
            "Applied Random Unstructured pruning to layer: 20\n",
            "Applied Random Unstructured pruning to layer: 24\n",
            "Applied Random Unstructured pruning to layer: 27\n",
            "Applied Random Unstructured pruning to layer: 30\n",
            "Applied Random Unstructured pruning to layer: 34\n",
            "Applied Random Unstructured pruning to layer: 37\n",
            "Applied Random Unstructured pruning to layer: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fine Tune models for comparison"
      ],
      "metadata": {
        "id": "JHbG5o3RDAci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate=1.5, batch_size=10):\n",
        "  total_step = len(train_loader)\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, (inputs, labels) in enumerate(train_loader):\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          # # Enforce pruning masks to maintain sparsity\n",
        "          # enforce_pruning_masks(model)\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % 100 == 99:  # Print every 100 mini-batches\n",
        "              print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "              running_loss = 0.0\n",
        "\n",
        "      # Validate the model\n",
        "      val_loss , val_accuracy = validate(model, val_loader)\n",
        "      print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "f7iCV01yVcfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_buffer = {}\n",
        "for method in pruning_methods_all:\n",
        "  for percentage in [0.1, 0.2, 0.3]:\n",
        "    models_buffer[f\"/content/vgg16_pruned_allConv2dlayers_{method}_{percentage}\"] = load_model(f\"/content/vgg16_pruned_allConv2dlayers_{method}_{percentage}.pth\")\n",
        "\n",
        "models_buffer"
      ],
      "metadata": {
        "id": "tLdlsDQmZfsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using config 2 since it is the config of best professor model\n",
        "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
        "\n",
        "for pruned_model_name in models_buffer.keys():\n",
        "  pruned_finetuned_model = finetune(train_loader, val_loader, num_epochs, models_buffer[pruned_model_name], criterion, optimizer, scheduler)\n",
        "\n",
        "  # accuracy = calculate_accuracy(pruned_model, test_loader)\n",
        "  # print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "  # Consolidate pruning\n",
        "  for layer in pruned_finetuned_model.modules():\n",
        "      if isinstance(layer, (nn.Conv2d)):\n",
        "          prune.remove(layer, 'weight')\n",
        "\n",
        "  for layer in models_buffer[pruned_model_name].modules():\n",
        "      if isinstance(layer, (nn.Conv2d)):\n",
        "          prune.remove(layer, 'weight')\n",
        "\n",
        "  torch.save(pruned_finetuned_model.state_dict(), f\"{pruned_model_name}_finetuned_frozen.pth\")\n",
        "  torch.save(models_buffer[pruned_model_name].state_dict(), f\"{pruned_model_name}_frozen.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "MRivNV3mDCZ0",
        "outputId": "32aeec3e-bfa6-4824-9478-b71258aac8b6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "Epoch [1/40], Step [100/625], Loss: 3.6778\n",
            "Epoch [1/40], Step [200/625], Loss: 3.7729\n",
            "Epoch [1/40], Step [300/625], Loss: 3.6335\n",
            "Epoch [1/40], Step [400/625], Loss: 3.7209\n",
            "Epoch [1/40], Step [500/625], Loss: 3.6237\n",
            "Epoch [1/40], Step [600/625], Loss: 3.6792\n",
            "Epoch [1/40], Validation Loss: 3.5062, Validation Accuracy: 34.39%\n",
            "Epoch [2/40], Step [100/625], Loss: 3.4952\n",
            "Epoch [2/40], Step [200/625], Loss: 3.4902\n",
            "Epoch [2/40], Step [300/625], Loss: 3.5108\n",
            "Epoch [2/40], Step [400/625], Loss: 3.4771\n",
            "Epoch [2/40], Step [500/625], Loss: 3.4961\n",
            "Epoch [2/40], Step [600/625], Loss: 3.4712\n",
            "Epoch [2/40], Validation Loss: 3.4850, Validation Accuracy: 34.53%\n",
            "Epoch [3/40], Step [100/625], Loss: 3.4927\n",
            "Epoch [3/40], Step [200/625], Loss: 3.5144\n",
            "Epoch [3/40], Step [300/625], Loss: 3.4771\n",
            "Epoch [3/40], Step [400/625], Loss: 3.4905\n",
            "Epoch [3/40], Step [500/625], Loss: 3.4942\n",
            "Epoch [3/40], Step [600/625], Loss: 3.4506\n",
            "Epoch [3/40], Validation Loss: 3.5496, Validation Accuracy: 34.37%\n",
            "Epoch [4/40], Step [100/625], Loss: 3.5540\n",
            "Epoch [4/40], Step [200/625], Loss: 3.5429\n",
            "Epoch [4/40], Step [300/625], Loss: 3.4805\n",
            "Epoch [4/40], Step [400/625], Loss: 3.4443\n",
            "Epoch [4/40], Step [500/625], Loss: 3.4798\n",
            "Epoch [4/40], Step [600/625], Loss: 3.4646\n",
            "Epoch [4/40], Validation Loss: 3.5101, Validation Accuracy: 34.54%\n",
            "Epoch [5/40], Step [100/625], Loss: 3.4388\n",
            "Epoch [5/40], Step [200/625], Loss: 3.5205\n",
            "Epoch [5/40], Step [300/625], Loss: 3.4572\n",
            "Epoch [5/40], Step [400/625], Loss: 3.4939\n",
            "Epoch [5/40], Step [500/625], Loss: 3.5083\n",
            "Epoch [5/40], Step [600/625], Loss: 3.5470\n",
            "Epoch [5/40], Validation Loss: 3.5112, Validation Accuracy: 34.68%\n",
            "Epoch [6/40], Step [100/625], Loss: 3.5548\n",
            "Epoch [6/40], Step [200/625], Loss: 3.4627\n",
            "Epoch [6/40], Step [300/625], Loss: 3.4860\n",
            "Epoch [6/40], Step [400/625], Loss: 3.5296\n",
            "Epoch [6/40], Step [500/625], Loss: 3.5168\n",
            "Epoch [6/40], Step [600/625], Loss: 3.5416\n",
            "Epoch [6/40], Validation Loss: 3.5087, Validation Accuracy: 34.46%\n",
            "Epoch [7/40], Step [100/625], Loss: 3.5388\n",
            "Epoch [7/40], Step [200/625], Loss: 3.5362\n",
            "Epoch [7/40], Step [300/625], Loss: 3.4737\n",
            "Epoch [7/40], Step [400/625], Loss: 3.5212\n",
            "Epoch [7/40], Step [500/625], Loss: 3.4646\n",
            "Epoch [7/40], Step [600/625], Loss: 3.4446\n",
            "Epoch [7/40], Validation Loss: 3.4785, Validation Accuracy: 35.09%\n",
            "Epoch [8/40], Step [100/625], Loss: 3.4910\n",
            "Epoch [8/40], Step [200/625], Loss: 3.4982\n",
            "Epoch [8/40], Step [300/625], Loss: 3.5387\n",
            "Epoch [8/40], Step [400/625], Loss: 3.4852\n",
            "Epoch [8/40], Step [500/625], Loss: 3.4480\n",
            "Epoch [8/40], Step [600/625], Loss: 3.5338\n",
            "Epoch [8/40], Validation Loss: 3.4740, Validation Accuracy: 34.71%\n",
            "Epoch [9/40], Step [100/625], Loss: 3.4846\n",
            "Epoch [9/40], Step [200/625], Loss: 3.4832\n",
            "Epoch [9/40], Step [300/625], Loss: 3.4487\n",
            "Epoch [9/40], Step [400/625], Loss: 3.5127\n",
            "Epoch [9/40], Step [500/625], Loss: 3.5099\n",
            "Epoch [9/40], Step [600/625], Loss: 3.4326\n",
            "Epoch [9/40], Validation Loss: 3.4657, Validation Accuracy: 34.84%\n",
            "Epoch [10/40], Step [100/625], Loss: 3.5212\n",
            "Epoch [10/40], Step [200/625], Loss: 3.5638\n",
            "Epoch [10/40], Step [300/625], Loss: 3.4781\n",
            "Epoch [10/40], Step [400/625], Loss: 3.4570\n",
            "Epoch [10/40], Step [500/625], Loss: 3.5280\n",
            "Epoch [10/40], Step [600/625], Loss: 3.4267\n",
            "Epoch [10/40], Validation Loss: 3.5215, Validation Accuracy: 34.55%\n",
            "Epoch [11/40], Step [100/625], Loss: 3.5151\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-03caad7df4a5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpruned_model_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mpruned_finetuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpruned_model_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_finetuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{pruned_model_name}_finetuned.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-6fcef41abd30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Print every 100 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXES_gnyNhFF"
      },
      "source": [
        "# Training with Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AxwDk_vNhFF"
      },
      "outputs": [],
      "source": [
        "def train_student(student_model, teacher_model, train_loader, val_loader, num_epochs, soft_target_loss_weight, ce_loss_weight, temperature):\n",
        "    student_model.train()\n",
        "    teacher_model.eval()\n",
        "\n",
        "    optimizer = torch.optim.SGD(student_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass through teacher model\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(inputs)\n",
        "                teacher_probs = nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
        "\n",
        "            # Forward pass through student model\n",
        "            student_outputs = student_model(inputs)\n",
        "            student_probs = nn.functional.log_softmax(student_outputs / temperature, dim=1)\n",
        "\n",
        "            # Compute distillation loss\n",
        "            soft_target_loss = torch.sum(teacher_probs * (teacher_probs.log() - student_probs))/ student_probs.size()[0] * (temperature**2)\n",
        "\n",
        "            label_loss = ce_loss(student_outputs, labels)\n",
        "\n",
        "            loss = soft_target_loss_weight * soft_target_loss + ce_loss_weight * label_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:  # Print every 100 mini-batches\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validate the student model\n",
        "        student_model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = student_model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "        student_model.train()\n",
        "\n",
        "    torch.save(student_model.state_dict(), \"student_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQg1zr4eNhFF"
      },
      "outputs": [],
      "source": [
        "teacher = VGG16(num_classes)\n",
        "teacher.load_state_dict(torch.load(\"teacher.pth\", weights_only=True))\n",
        "teacher.eval()\n",
        "\n",
        "student = None\n",
        "\n",
        "train_student(student, teacher, train_loader, val_loader, num_epochs,0.25, 0.75, 2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "JNFMFGH0VFE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparing inference time, memory consumption, and model performance."
      ],
      "metadata": {
        "id": "ZWxCI6LHVHzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate pruned, pruned and finetuned and pruned and KD models\n",
        "(TODO add KD on evaluation)"
      ],
      "metadata": {
        "id": "nhIUjtAsix22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model size\n",
        "import os\n",
        "\n",
        "def get_model_size(model_path):\n",
        "    size = os.path.getsize(model_path) / (1024 * 1024)  # Convert to MB\n",
        "    return size"
      ],
      "metadata": {
        "id": "pFGCMk9RpLCK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sparsity\n",
        "def calculate_sparsity(model):\n",
        "    total_weights = 0\n",
        "    zero_weights = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            total_weights += param.numel()\n",
        "            zero_weights += torch.sum(param == 0).item()\n",
        "    sparsity = 100.0 * zero_weights / total_weights\n",
        "    return sparsity"
      ],
      "metadata": {
        "id": "sybIhtk3pg4r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def get_inference_time(model, test_loader, device, num_iterations=100):\n",
        "    model.eval()\n",
        "    total_time = 0.0\n",
        "    with torch.no_grad():\n",
        "        # Warm-up\n",
        "        for _ in range(10):\n",
        "            try:\n",
        "                inputs, _ = next(iter(test_loader))\n",
        "            except StopIteration:\n",
        "                break\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        # Timing\n",
        "        for i, (inputs, _) in enumerate(test_loader):\n",
        "            if i >= num_iterations:\n",
        "                break\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            if device.type == 'cuda':\n",
        "                torch.cuda.synchronize()  # Wait for GPU operations to finish\n",
        "            end_time = time.time()\n",
        "            total_time += (end_time - start_time)\n",
        "\n",
        "    avg_time_per_batch = total_time / num_iterations\n",
        "    return avg_time_per_batch\n"
      ],
      "metadata": {
        "id": "MXnRDatnSB3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluation(pruning_methods_all, percentages, test_loader, device, inference_iterations = 100):\n",
        "\n",
        "  models_buffer = {\n",
        "        'pruned': {},\n",
        "        'finetuned': {}\n",
        "    }\n",
        "  # add 'kd' : {} above\n",
        "\n",
        "  for method in pruning_methods_all:\n",
        "\n",
        "    models_buffer['pruned'][method] = []\n",
        "    models_buffer['finetuned'][method] = []\n",
        "    # models_buffer['kd'][method] = []\n",
        "\n",
        "    for percentage in percentages:\n",
        "\n",
        "      # FROZEN - PRUNED ONLY\n",
        "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_frozen\"\n",
        "      model_path = f\"/content/{model_name}.pth\"\n",
        "\n",
        "      if os.path.exists(model_path):\n",
        "\n",
        "        # Load model - frozen (only pruned)\n",
        "        model = load_model(model_path)\n",
        "\n",
        "        # Evaluate - frozen (only pruned)\n",
        "        accuracy = calculate_accuracy(model, test_loader)\n",
        "        model_size = get_model_size(model_path)\n",
        "        sparsity = calculate_sparsity(model)\n",
        "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
        "\n",
        "        # Save evaluation - frozen (only pruned)\n",
        "        models_buffer['pruned'][method].append({\n",
        "                'name' : model_name,\n",
        "                'pruning_percentage' : percentage,\n",
        "                'accuracy' : accuracy,\n",
        "                'model_size_MB' : model_size,\n",
        "                'sparsity' : sparsity,\n",
        "                'inference_time' : inference_time\n",
        "              })\n",
        "\n",
        "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
        "      else:\n",
        "        print(f\"Pruned model file not found: {model_path}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "      # PRUNED AND FINETUNED\n",
        "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_finetuned_frozen\"\n",
        "      model_path = f\"/content/{model_name}.pth\"\n",
        "\n",
        "      if os.path.exists(model_path):\n",
        "\n",
        "        # Load model - finetuned\n",
        "        model = load_model(model_path)\n",
        "\n",
        "        # Evaluate - finetuned\n",
        "        accuracy = calculate_accuracy(model, test_loader)\n",
        "        model_size = get_model_size(model_path)\n",
        "        sparsity = calculate_sparsity(model)\n",
        "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
        "\n",
        "\n",
        "        # Save evaluation - finetuned\n",
        "        models_buffer['finetuned'][method].append({\n",
        "                'name' : model_name,\n",
        "                'pruning_percentage' : percentage,\n",
        "                'accuracy' : accuracy,\n",
        "                'model_size_MB' : model_size,\n",
        "                'sparsity' : sparsity,\n",
        "                'inference_time' : inference_time\n",
        "              })\n",
        "\n",
        "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
        "      else:\n",
        "        print(f\"Pruned model file not found: {model_path}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "      # # PRUNED AND KD\n",
        "      # model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_<add>\"\n",
        "      # model_path = f\"/content/{model_name}.pth\"\n",
        "\n",
        "      # if os.path.exists(model_path):\n",
        "\n",
        "      #   # Load model - kd\n",
        "      #   model = load_model(model_path)\n",
        "\n",
        "      #   # Evaluate - kd\n",
        "      #   accuracy = calculate_accuracy(model, test_loader)\n",
        "      #   model_size = get_model_size(model_path)\n",
        "      #   sparsity = calculate_sparsity(model)\n",
        "      #   inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
        "\n",
        "\n",
        "      #   # Save evaluation - kd\n",
        "      #   models_buffer['kd'][method].append({\n",
        "      #           'name' : model_name,\n",
        "      #           'pruning_percentage' : percentage,\n",
        "      #           'accuracy' : accuracy,\n",
        "      #           'model_size_MB' : model_size,\n",
        "      #           'sparsity' : sparsity,\n",
        "      #           'inference_time' : inference_time\n",
        "      #         })\n",
        "\n",
        "      #   print(f\"Evaluated Pruned Model: {model_name}\")\n",
        "      #   print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
        "      # else:\n",
        "      #   print(f\"Pruned model file not found: {model_path}\")\n",
        "      #   continue\n",
        "\n",
        "  return models_buffer"
      ],
      "metadata": {
        "id": "KpPP130nLx6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = get_evaluation(pruning_methods_all, [0.1, 0.2, 0.3], test_loader, device, 100)\n",
        "\n",
        "# Save evaluation in pickle file\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('evaluations', exist_ok=True)\n",
        "\n",
        "# Define the file path with a meaningful name\n",
        "pickle_file_path = 'evaluations/evaluation_pruning_results.pkl'\n",
        "\n",
        "# Save evaluation dictionary\n",
        "with open(pickle_file_path, 'wb') as file:\n",
        "    pickle.dump(evaluation, file)\n",
        "\n",
        "print(f\"Evaluation results saved successfully at '{pickle_file_path}'.\")"
      ],
      "metadata": {
        "id": "jm467cxZOfrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualize Evaluation - ALL BY CHATGPT"
      ],
      "metadata": {
        "id": "yn9bbdWHVxpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "umgBmleElzKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buffer_to_dataframe(evaluation, category):\n",
        "    records = []\n",
        "    for method, models in evaluation.get(category, {}).items():\n",
        "        for model_info in models:\n",
        "            record = model_info.copy()\n",
        "            record['pruning_method'] = method\n",
        "            records.append(record)\n",
        "    df = pd.DataFrame(records)\n",
        "    return df\n",
        "\n",
        "###########################\n",
        "# # ONLY IF NEEDED -> load pickle file with evaluation\n",
        "# import pickle\n",
        "\n",
        "# # Define the pickle file path\n",
        "# pickle_file_path = 'evaluations/evaluation_pruning_results.pkl'\n",
        "\n",
        "# # Load the evaluation dictionary from the pickle file\n",
        "# with open(pickle_file_path, 'rb') as file:\n",
        "#     loaded_evaluation = pickle.load(file)\n",
        "\n",
        "# print(\"Evaluation results loaded successfully.\")\n",
        "###########################\n",
        "\n",
        "# Create DataFrames for each category\n",
        "pruned_df = buffer_to_dataframe(evaluation, 'pruned')\n",
        "finetuned_df = buffer_to_dataframe(evaluation, 'finetuned')\n",
        "kd_df = buffer_to_dataframe(evaluation, 'kd')\n"
      ],
      "metadata": {
        "id": "Y3LQrv86V7Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams.update({'font.size': 12})"
      ],
      "metadata": {
        "id": "xnovHhL4V_y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(df, category):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=df, x='pruning_percentage', y='accuracy', hue='pruning_method', marker='o')\n",
        "    plt.title(f'Accuracy vs. Pruning Percentage ({category.capitalize()} Models)')\n",
        "    plt.xlabel('Pruning Percentage')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend(title='Pruning Method')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Accuracy for Each Category\n",
        "plot_accuracy(pruned_df, 'pruned')\n",
        "plot_accuracy(finetuned_df, 'finetuned')\n",
        "plot_accuracy(kd_df, 'kd')\n"
      ],
      "metadata": {
        "id": "L6m1Za_jWAXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_inference_time(df, category):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=df, x='pruning_percentage', y='inference_time_sec', hue='pruning_method', marker='o')\n",
        "    plt.title(f'Inference Time vs. Pruning Percentage ({category.capitalize()} Models)')\n",
        "    plt.xlabel('Pruning Percentage')\n",
        "    plt.ylabel('Inference Time per Batch (sec)')\n",
        "    plt.legend(title='Pruning Method')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Inference Time for Each Category\n",
        "plot_inference_time(pruned_df, 'pruned')\n",
        "plot_inference_time(finetuned_df, 'finetuned')\n",
        "plot_inference_time(kd_df, 'kd')\n"
      ],
      "metadata": {
        "id": "2QzJ3dY2WB24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sparsity(df, category):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=df, x='pruning_percentage', y='sparsity_percent', hue='pruning_method', marker='o')\n",
        "    plt.title(f'Sparsity vs. Pruning Percentage ({category.capitalize()} Models)')\n",
        "    plt.xlabel('Pruning Percentage')\n",
        "    plt.ylabel('Sparsity (%)')\n",
        "    plt.legend(title='Pruning Method')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Sparsity for Each Category\n",
        "plot_sparsity(pruned_df, 'pruned')\n",
        "plot_sparsity(finetuned_df, 'finetuned')\n",
        "plot_sparsity(kd_df, 'kd')\n"
      ],
      "metadata": {
        "id": "C6iA3VSTWDZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_size(df, category):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(data=df, x='pruning_percentage', y='model_size_MB', hue='pruning_method', marker='o')\n",
        "    plt.title(f'Model Size vs. Pruning Percentage ({category.capitalize()} Models)')\n",
        "    plt.xlabel('Pruning Percentage')\n",
        "    plt.ylabel('Model Size (MB)')\n",
        "    plt.legend(title='Pruning Method')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Model Size for Each Category\n",
        "plot_model_size(pruned_df, 'pruned')\n",
        "plot_model_size(finetuned_df, 'finetuned')\n",
        "plot_model_size(kd_df, 'kd')\n"
      ],
      "metadata": {
        "id": "ovpBS1IJWE54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a 'category' column to each DataFrame\n",
        "pruned_df['category'] = 'Pruned'\n",
        "finetuned_df['category'] = 'Finetuned'\n",
        "kd_df['category'] = 'KD'\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "combined_df = pd.concat([pruned_df, finetuned_df, kd_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "r_s1ZCG2WGWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=combined_df, x='pruning_percentage', y='accuracy', hue='category', style='category', markers=True, dashes=False)\n",
        "plt.title('Accuracy Comparison Across Model Categories')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend(title='Model Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UH4Qh_V4WIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=combined_df, x='pruning_percentage', y='inference_time_sec', hue='category', style='category', markers=True, dashes=False)\n",
        "plt.title('Inference Time Comparison Across Model Categories')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Inference Time per Batch (sec)')\n",
        "plt.legend(title='Model Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yhbYiS56WJ8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=combined_df, x='pruning_percentage', y='sparsity_percent', hue='category', style='category', markers=True, dashes=False)\n",
        "plt.title('Sparsity Comparison Across Model Categories')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Sparsity (%)')\n",
        "plt.legend(title='Model Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IxC3zoFcWLkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=combined_df, x='pruning_percentage', y='model_size_MB', hue='category', style='category', markers=True, dashes=False)\n",
        "plt.title('Model Size Comparison Across Model Categories')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Model Size (MB)')\n",
        "plt.legend(title='Model Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tsp1O9NVWM2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create summary tables\n",
        "def create_summary_table(df, category):\n",
        "    summary = df.groupby(['pruning_method', 'pruning_percentage']).agg({\n",
        "        'accuracy': 'mean',\n",
        "        'model_size_MB': 'mean',\n",
        "        'sparsity_percent': 'mean',\n",
        "        'inference_time_sec': 'mean'\n",
        "    }).reset_index()\n",
        "    summary['category'] = category.capitalize()\n",
        "    return summary\n",
        "\n",
        "# Create summary tables\n",
        "pruned_summary = create_summary_table(pruned_df, 'pruned')\n",
        "finetuned_summary = create_summary_table(finetuned_df, 'finetuned')\n",
        "kd_summary = create_summary_table(kd_df, 'kd')\n",
        "\n",
        "# Combine summaries\n",
        "all_summaries = pd.concat([pruned_summary, finetuned_summary, kd_summary], ignore_index=True)\n",
        "\n",
        "# Display the summary table\n",
        "print(all_summaries)\n"
      ],
      "metadata": {
        "id": "hVtPejXEWOPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pivot table for Accuracy\n",
        "accuracy_pivot = all_summaries.pivot_table(\n",
        "    index=['pruning_method', 'pruning_percentage'],\n",
        "    columns='category',\n",
        "    values='accuracy'\n",
        ").reset_index()\n",
        "\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(accuracy_pivot)\n",
        "\n",
        "# Similarly, create pivot tables for Inference Time\n",
        "inference_time_pivot = all_summaries.pivot_table(\n",
        "    index=['pruning_method', 'pruning_percentage'],\n",
        "    columns='category',\n",
        "    values='inference_time_sec'\n",
        ").reset_index()\n",
        "\n",
        "print(\"\\nInference Time Comparison (sec/batch):\")\n",
        "print(inference_time_pivot)\n"
      ],
      "metadata": {
        "id": "RcEe-NTvWQfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot for heatmap\n",
        "accuracy_heatmap = accuracy_pivot.pivot(\"pruning_method\", \"pruning_percentage\", \"Finetuned\")\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(accuracy_heatmap, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
        "plt.title('Finetuned Model Accuracy Heatmap')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Pruning Method')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DCQep28RWR-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the inference_time_pivot for seaborn\n",
        "inference_time_melted = inference_time_pivot.melt(id_vars=['pruning_method', 'pruning_percentage'],\n",
        "                                                var_name='category',\n",
        "                                                value_name='inference_time_sec')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=inference_time_melted, x='pruning_percentage', y='inference_time_sec', hue='category')\n",
        "plt.title('Inference Time Comparison Across Model Categories')\n",
        "plt.xlabel('Pruning Percentage')\n",
        "plt.ylabel('Avg Inference Time per Batch (sec)')\n",
        "plt.legend(title='Model Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8XGs9H3DWT3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(combined_df, col=\"pruning_method\", hue=\"category\", col_wrap=3, height=4, aspect=1)\n",
        "g.map(sns.lineplot, \"pruning_percentage\", \"accuracy\", marker=\"o\")\n",
        "g.add_legend()\n",
        "plt.subplots_adjust(top=0.9)\n",
        "g.fig.suptitle('Accuracy Across Pruning Methods and Categories')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ChVOAetmWVq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grouped_bar(df, metric, title, ylabel):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    sns.barplot(data=df, x='pruning_percentage', y=metric, hue='category', ci=None)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Pruning Percentage')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend(title='Model Category')\n",
        "    plt.show()\n",
        "\n",
        "# Plotting Accuracy Comparison\n",
        "plot_grouped_bar(combined_df, 'accuracy', 'Accuracy Comparison Across Categories', 'Accuracy (%)')\n",
        "\n",
        "# Plotting Inference Time Comparison\n",
        "plot_grouped_bar(combined_df, 'inference_time_sec', 'Inference Time Comparison Across Categories', 'Inference Time per Batch (sec)')\n",
        "\n",
        "# Plotting Sparsity Comparison\n",
        "plot_grouped_bar(combined_df, 'sparsity_percent', 'Sparsity Comparison Across Categories', 'Sparsity (%)')\n",
        "\n",
        "# Plotting Model Size Comparison\n",
        "plot_grouped_bar(combined_df, 'model_size_MB', 'Model Size Comparison Across Categories', 'Model Size (MB)')\n"
      ],
      "metadata": {
        "id": "Ia44SUVZWXXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summary_table(df, category):\n",
        "    summary = df.groupby(['pruning_method', 'pruning_percentage']).agg({\n",
        "        'accuracy': 'mean',\n",
        "        'model_size_MB': 'mean',\n",
        "        'sparsity_percent': 'mean',\n",
        "        'inference_time_sec': 'mean'\n",
        "    }).reset_index()\n",
        "    summary['category'] = category.capitalize()\n",
        "    return summary\n",
        "\n",
        "# Create summary tables\n",
        "pruned_summary = create_summary_table(pruned_df, 'pruned')\n",
        "finetuned_summary = create_summary_table(finetuned_df, 'finetuned')\n",
        "kd_summary = create_summary_table(kd_df, 'kd')\n",
        "\n",
        "# Combine summaries\n",
        "all_summaries = pd.concat([pruned_summary, finetuned_summary, kd_summary], ignore_index=True)\n",
        "\n",
        "# Display the summary table\n",
        "print(all_summaries)\n"
      ],
      "metadata": {
        "id": "jTAipxqAWYnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot for Accuracy\n",
        "accuracy_pivot = all_summaries.pivot_table(\n",
        "    index=['pruning_method', 'pruning_percentage'],\n",
        "    columns='category',\n",
        "    values='accuracy'\n",
        ").reset_index()\n",
        "\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(accuracy_pivot)\n",
        "\n",
        "# Pivot for Inference Time\n",
        "inference_time_pivot = all_summaries.pivot_table(\n",
        "    index=['pruning_method', 'pruning_percentage'],\n",
        "    columns='category',\n",
        "    values='inference_time_sec'\n",
        ").reset_index()\n",
        "\n",
        "print(\"\\nInference Time Comparison (sec/batch):\")\n",
        "print(inference_time_pivot)\n"
      ],
      "metadata": {
        "id": "3MhwjzbhWaNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "3QWIqqW5f0k1",
        "aXES_gnyNhFF"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}