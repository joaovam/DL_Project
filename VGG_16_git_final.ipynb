{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "id": "x40CuzhpNhE-",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZoluXOdNhE_",
    "outputId": "66d95b05-ca99-43fb-d084-f539b5ed5d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration GPU/CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yu_WMuiYNhE_",
    "outputId": "0e632349-881f-4d6a-c4d2-c522d27c6cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUE4DhP7NhFA"
   },
   "source": [
    "## VGG-16 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gFJZgfjxNhFB"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3XXdSy52NhFB"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "num_classes = 10\n",
    "# num_epochs = 30\n",
    "batch_size = 64\n",
    "# learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps49sCQQNhFC",
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XX0TUApNhFC",
    "outputId": "eb48f8ad-7a1c-4fff-93fe-9a7bc8651828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2761))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split dataset into train and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6i7NF-kDNhFD",
    "outputId": "6d46237f-caf6-4223-f4e4-72442b19fd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 32, 32]), Labels: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(f\"Input shape: {inputs.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WQZM0X2CNhFD"
   },
   "outputs": [],
   "source": [
    "# model = VGG16(num_classes=num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "57vOFZOfNhFD"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# num_epochs = 30\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.01\n",
    "\n",
    "num_classes = 10\n",
    "config_1 = {\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"StepLR\",\n",
    "        \"step_size\": 15,\n",
    "        \"gamma\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    \"num_epochs\": 40,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"CosineAnnealingLR\",\n",
    "        \"T_max\": 40\n",
    "    }\n",
    "}\n",
    "\n",
    "config_3 = {\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"ReduceLROnPlateau\",\n",
    "        \"mode\": \"min\",\n",
    "        \"factor\": 0.1,\n",
    "        \"patience\": 10\n",
    "    },\n",
    "    \"regularization\": {\n",
    "        \"dropout_rate\": 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "def config_test(selected_config):\n",
    "    # Atribuindo os hiperparâmetros escolhidos\n",
    "    num_epochs = selected_config[\"num_epochs\"]\n",
    "    batch_size = selected_config[\"batch_size\"]\n",
    "    learning_rate = selected_config[\"learning_rate\"]\n",
    "\n",
    "    model = VGG16(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if selected_config[\"optimizer\"] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif selected_config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=selected_config.get(\"momentum\", 0))\n",
    "\n",
    "    # Configurando o scheduler baseado na configuração\n",
    "    if selected_config[\"scheduler\"][\"type\"] == \"StepLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=selected_config[\"scheduler\"][\"step_size\"],\n",
    "            gamma=selected_config[\"scheduler\"][\"gamma\"]\n",
    "        )\n",
    "    elif selected_config[\"scheduler\"][\"type\"] == \"CosineAnnealingLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=selected_config[\"scheduler\"][\"T_max\"]\n",
    "        )\n",
    "    elif selected_config[\"scheduler\"][\"type\"] == \"ReduceLROnPlateau\":\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=selected_config[\"scheduler\"][\"mode\"],\n",
    "            factor=selected_config[\"scheduler\"][\"factor\"],\n",
    "            patience=selected_config[\"scheduler\"][\"patience\"]\n",
    "        )\n",
    "\n",
    "\n",
    "    return num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCtvmzsrNhFE"
   },
   "source": [
    "# Training Original VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RVikul5zi1nE"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(dataloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3kY4ncykFNXG"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, learning_rate=1.5, batch_size=10):\n",
    "  total_step = len(train_loader)\n",
    "  model.to(device)\n",
    "  model.train()\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "      running_loss = 0.0\n",
    "      for i, (inputs, labels) in enumerate(train_loader):\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "          if i % 100 == 199:  # Print every 100 mini-batches\n",
    "              print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "              running_loss = 0.0\n",
    "\n",
    "      # Validate the model\n",
    "      val_loss , val_accuracy = validate(model, val_loader)\n",
    "      print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "      scheduler.step()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "emlWNyTsI5Ol"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader):\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for inputs, labels in dataloader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = model(inputs)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJsDHrk-ZbOs",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8rn_wX4qNhFE",
    "outputId": "cb716a6d-8d99-4cd2-ab43-d7bc982fae33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_1)\n",
    "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
    "torch.save(model.state_dict(), \"model_t2_test.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvaGF1pXNhFE"
   },
   "source": [
    "The code in the cell looks correct and should work without any errors, given that all the necessary variables and modules are already defined and imported in the previous cells. However, to ensure that the code runs smoothly, you should make sure that the `train_loader`, `val_loader`, `model`, `criterion`, `optimizer`, `device`, and `num_epochs` are properly defined and imported.\n",
    "\n",
    "\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hj_msbsBJdTT",
    "outputId": "2df9fe3b-c5ac-4c4b-b79a-64823bf9764b"
   },
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQLQ8GAqZbOu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsTRenpCZbOu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
    "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
    "torch.save(model.state_dict(), \"model_t2_test2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCIjGjlsJluy",
    "outputId": "f9ada8b3-a6f0-4d88-d3bd-07bb73afa0f5"
   },
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn1CV0LbZbOu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "jqqS2ljFZbOu",
    "outputId": "7aa21862-0125-473f-d0ca-69186753220a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_3)\n",
    "model = train(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler)\n",
    "torch.save(model.state_dict(), \"model_t2_test3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvD1Ge4IIv_R",
    "outputId": "68c98976-f3b9-4ab0-cd32-ea04f621fc24"
   },
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw7H8lkoNhFF"
   },
   "source": [
    "# Training Pruned VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWSC-Bf2uYff"
   },
   "source": [
    "### Prune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LlF14kojJvmm"
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Function to apply pruning to specific layers -> LOCAL\n",
    "def apply_pruning(model, conv_layers_, pruning_method, amount, structured=False):\n",
    "  model.to(device)\n",
    "  model.train()\n",
    "  for name, layer in conv_layers_:\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        if structured:\n",
    "            if pruning_method == 'l1_structured':\n",
    "                prune.ln_structured(layer, name='weight', amount=amount, n=1, dim=0)  # Prune output channels\n",
    "                print(f\"Applied L1 Structured pruning to layer: {name}\")\n",
    "            elif pruning_method == 'l2_structured':\n",
    "                prune.ln_structured(layer, name='weight', amount=amount, n=2, dim=0)\n",
    "                print(f\"Applied L2 Structured pruning to layer: {name}\")\n",
    "            elif pruning_method == 'random_structured':\n",
    "                prune.random_structured(layer, name='weight', amount=amount, dim=0)\n",
    "                print(f\"Applied Random Structured pruning to layer: {name}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported structured pruning method: {pruning_method}\")\n",
    "        else:\n",
    "            if pruning_method == 'l1_unstructured':\n",
    "                prune.l1_unstructured(layer, name='weight', amount=amount)\n",
    "                print(f\"Applied L1 Unstructured pruning to layer: {name}\")\n",
    "            # elif pruning_method == 'l2_unstructured':\n",
    "            #     prune.l2_unstructured(layer, name='weight', amount=amount)\n",
    "            #     print(f\"Applied L2 Unstructured pruning to layer: {name}\")\n",
    "            elif pruning_method == 'random_unstructured':\n",
    "                prune.random_unstructured(layer, name='weight', amount=amount)\n",
    "                print(f\"Applied Random Unstructured pruning to layer: {name}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported unstructured pruning method: {pruning_method}\")\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Y-uVsA5xV5nh"
   },
   "outputs": [],
   "source": [
    "# Function to enforce pruning masks\n",
    "def enforce_pruning_masks(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                module.weight.data.mul_(module.weight_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1NAkPjVpI4pI"
   },
   "outputs": [],
   "source": [
    "# Get all convolutional layers in VGG16\n",
    "def get_conv_layers(model):\n",
    "    conv_layers = []\n",
    "    for name, module in model.features.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            conv_layers.append((name, module))\n",
    "    return conv_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EQAFcOHxjHMd"
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes=10):\n",
    "    model = VGG16(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model_with_masks(model, file_path):\n",
    "#     # Load the state_dict with masks\n",
    "#     state_with_masks = torch.load(file_path, map_location=device)\n",
    "#     model.load_state_dict(state_with_masks, strict=False)  # Load weights without strict check\n",
    "\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Reapply masks to the layers\n",
    "#     for name, module in model.named_modules():\n",
    "#         if isinstance(module, nn.Conv2d):\n",
    "#             mask_key = f\"{name}.weight_mask\"\n",
    "#             if mask_key in state_with_masks:\n",
    "#                 mask = state_with_masks[mask_key].to(device)\n",
    "#                 prune.custom_from_mask(module, name='weight', mask=mask)\n",
    "\n",
    "#     return model\n",
    "\n",
    "def load_model_with_masks(model, file_path):\n",
    "    # Carrega o estado salvo, incluindo máscaras\n",
    "    state_with_masks = torch.load(file_path, map_location=device)    \n",
    "    # Carrega os pesos sem forçar correspondência completa\n",
    "    model.load_state_dict(state_with_masks, strict=False)\n",
    "    model.to(device)\n",
    "\n",
    "    # Reaplica as máscaras às camadas Conv2d\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            mask_key = f\"{name}.weight_mask\"\n",
    "            if mask_key in state_with_masks:\n",
    "                mask = state_with_masks[mask_key].to(device)\n",
    "                prune.custom_from_mask(module, name='weight', mask=mask)\n",
    "                print(f\"Máscara reaplicada para {name}.\")\n",
    "            else:\n",
    "                print(f\"Máscara não encontrada para {name}. Verifique o arquivo salvo.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_pruning_applied(model):\n",
    "    pruned_layers = []\n",
    "    unpruned_layers = []\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):  # Verificar apenas camadas Conv2d\n",
    "            if hasattr(module, 'weight_orig'):  # Verifica se o pruning foi aplicado\n",
    "                pruned_layers.append(name)\n",
    "            else:\n",
    "                unpruned_layers.append(name)\n",
    "    \n",
    "    return pruned_layers, unpruned_layers\n",
    "    \n",
    "\n",
    "def save_model_with_masks(model, file_path):\n",
    "    # Include pruning masks in the state_dict\n",
    "    state_with_masks = model.state_dict()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                state_with_masks[f\"{name}.weight_mask\"] = module.weight_mask\n",
    "\n",
    "    torch.save(state_with_masks, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy1tISJI_4-D",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pruning Conv2d layers - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XNJKFVo_8sw",
    "outputId": "03c150f7-1631-4817-e41c-2ea3d2823a48"
   },
   "outputs": [],
   "source": [
    "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
    "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
    "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
    "\n",
    "for method in pruning_methods_all:\n",
    "  # Load pretrained model\n",
    "  model = load_model(\"/content/model_t2.h5\")\n",
    "\n",
    "  # Prune 20% of weights in all Conv2d layers\n",
    "  conv_layers = get_conv_layers(model)\n",
    "  if method in pruning_methods_structured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.1, structured=True)\n",
    "  elif method in pruning_methods_unstructured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.1, structured=False)\n",
    "\n",
    "  # # Consolidate pruning\n",
    "  # for layer in model.modules():\n",
    "  #     if isinstance(layer, (nn.Conv2d)):\n",
    "  #         prune.remove(layer, 'weight')\n",
    "\n",
    "  save_model_with_masks(model, f'{models_path}vgg16_pruned_allConv2dlayers_{method}_0.1_with_masks.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTSvDyH-f35m",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pruning Conv2d layers - 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzuFYW_8b-ML",
    "outputId": "c08fd651-408a-4dd0-f367-575ce60ecdee"
   },
   "outputs": [],
   "source": [
    "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
    "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
    "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
    "\n",
    "for method in pruning_methods_all:\n",
    "    # Load pretrained model\n",
    "    model = load_model(\"/content/model_t2.h5\")\n",
    "    \n",
    "    # Prune 20% of weights in all Conv2d layers\n",
    "    conv_layers = get_conv_layers(model)\n",
    "        if method in pruning_methods_structured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.2, structured=True)\n",
    "        elif method in pruning_methods_unstructured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.2, structured=False)\n",
    "    \n",
    "    # # Consolidate pruning\n",
    "    # for layer in model.modules():\n",
    "    #     if isinstance(layer, (nn.Conv2d)):\n",
    "    #         prune.remove(layer, 'weight')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'vgg16_pruned_allConv2dlayers_{method}_0.2.pth')\n",
    "    save_model_with_masks(model, f'vgg16_pruned_allConv2dlayers_{method}_0.1_with_masks.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cbKcqnE-07B",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pruning Conv2d layers - 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJ8XBdaj-wg-",
    "outputId": "2b2fe095-a2ff-4c49-e690-a98a9e931398"
   },
   "outputs": [],
   "source": [
    "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
    "pruning_methods_structured = ['l1_structured', 'l2_structured', 'random_structured']\n",
    "pruning_methods_unstructured = ['l1_unstructured', 'random_unstructured']\n",
    "\n",
    "for method in pruning_methods_all:\n",
    "  # Load pretrained model\n",
    "  model = load_model(\"/content/model_t2.h5\")\n",
    "\n",
    "  # Prune 20% of weights in all Conv2d layers\n",
    "  conv_layers = get_conv_layers(model)\n",
    "  if method in pruning_methods_structured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.3, structured=True)\n",
    "  elif method in pruning_methods_unstructured:\n",
    "    apply_pruning(model, conv_layers, pruning_method=f\"{method}\", amount=0.3, structured=False)\n",
    "\n",
    "  # # Consolidate pruning\n",
    "  # for layer in model.modules():\n",
    "  #     if isinstance(layer, (nn.Conv2d)):\n",
    "  #         prune.remove(layer, 'weight')\n",
    "\n",
    "  torch.save(model.state_dict(), f'vgg16_pruned_allConv2dlayers_{method}_0.3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "f7iCV01yVcfq"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Função de treinamento ajustada\n",
    "def finetune(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, pruned_model_name, learning_rate=1.5, batch_size=10):\n",
    "    total_step = len(train_loader)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "    # Lista para armazenar os logs\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 199:  # Salva a média a cada 100 mini-batches\n",
    "                avg_loss = running_loss / 100\n",
    "                logs.append({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"step\": i + 1,\n",
    "                    \"train_loss\": avg_loss\n",
    "                })\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validação do modelo\n",
    "        val_loss, val_accuracy = validate(model, val_loader)\n",
    "        logs.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"validation_loss\": val_loss,\n",
    "            \"validation_accuracy\": val_accuracy\n",
    "        })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Salva os logs em um arquivo CSV\n",
    "    with open(f\"logs/models_finetuned_frozen/logs_{pruned_model_name}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"epoch\", \"validation_loss\", \"validation_accuracy\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for log in logs:\n",
    "            print(log)\n",
    "            writer.writerow(log)\n",
    "\n",
    "    # Verifica o estado do pruning após o fine-tuning\n",
    "    pruned_layers, unpruned_layers = check_pruning_applied(model)\n",
    "    print(f\"Após o treinamento: Camadas podadas ({len(pruned_layers)}): {pruned_layers}\")\n",
    "    print(f\"Camadas não podadas ({len(unpruned_layers)}): {unpruned_layers}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tLdlsDQmZfsa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n",
      "Máscara reaplicada para features.0.\n",
      "Máscara reaplicada para features.3.\n",
      "Máscara reaplicada para features.7.\n",
      "Máscara reaplicada para features.10.\n",
      "Máscara reaplicada para features.14.\n",
      "Máscara reaplicada para features.17.\n",
      "Máscara reaplicada para features.20.\n",
      "Máscara reaplicada para features.24.\n",
      "Máscara reaplicada para features.27.\n",
      "Máscara reaplicada para features.30.\n",
      "Máscara reaplicada para features.34.\n",
      "Máscara reaplicada para features.37.\n",
      "Máscara reaplicada para features.40.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_folder = \"models_pruned_with_mask/\"\n",
    "models_buffer = {}\n",
    "\n",
    "pruning_methods_all = ['l1_structured', 'l2_structured', 'random_structured', 'l1_unstructured', 'random_unstructured']\n",
    "\n",
    "for method in pruning_methods_all:\n",
    "  for percentage in [0.1, 0.2, 0.3]:\n",
    "    model = load_model(\"model_t2.h5\")\n",
    "    model.to(device)\n",
    "    models_buffer[f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}\"] = load_model_with_masks(model, f\"{models_folder}vgg16_pruned_allConv2dlayers_{method}_{percentage}.pth\")\n",
    "    print()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_structured_0.1\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_structured_0.2\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_structured_0.3\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l2_structured_0.1\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l2_structured_0.2\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l2_structured_0.3\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_structured_0.1\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_structured_0.2\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_structured_0.3\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_unstructured_0.1\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_unstructured_0.2\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_l1_unstructured_0.3\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_unstructured_0.1\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_unstructured_0.2\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n",
      "\n",
      "Verificando o modelo: vgg16_pruned_allConv2dlayers_random_unstructured_0.3\n",
      "Camadas podadas (13): ['features.0', 'features.3', 'features.7', 'features.10', 'features.14', 'features.17', 'features.20', 'features.24', 'features.27', 'features.30', 'features.34', 'features.37', 'features.40']\n",
      "Camadas não podadas (0): []\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Função para verificar se o pruning foi aplicado\n",
    "def check_pruning_applied(model):\n",
    "    pruned_layers = []\n",
    "    unpruned_layers = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):  # Verificar apenas camadas Conv2d\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                pruned_layers.append(name)\n",
    "            else:\n",
    "                unpruned_layers.append(name)\n",
    "    \n",
    "    return pruned_layers, unpruned_layers\n",
    "\n",
    "# Iterar sobre todos os modelos no buffer e verificar o pruning\n",
    "for pruned_model_name in models_buffer.keys():\n",
    "    print(f\"\\nVerificando o modelo: {pruned_model_name}\")\n",
    "    model = models_buffer[pruned_model_name]\n",
    "    \n",
    "    pruned_layers, unpruned_layers = check_pruning_applied(model)\n",
    "    \n",
    "    print(f\"Camadas podadas ({len(pruned_layers)}): {pruned_layers}\")\n",
    "    print(f\"Camadas não podadas ({len(unpruned_layers)}): {unpruned_layers}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'models_pruned_with_mask/vgg16_pruned_allConv2dlayers_l1_structured_0.1.pth'\n",
    "\n",
    "# model = load_model(\"model_t2.h5\")\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# model = load_model_with_masks(model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "MRivNV3mDCZ0",
    "outputId": "32aeec3e-bfa6-4824-9478-b71258aac8b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando o modelo: vgg16_pruned_allConv2dlayers_l1_structured_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 625/625 [00:19<00:00, 32.65it/s]\n",
      "Epoch 2/40: 100%|██████████| 625/625 [00:20<00:00, 30.74it/s]\n",
      "Epoch 3/40: 100%|██████████| 625/625 [00:19<00:00, 31.32it/s]\n",
      "Epoch 4/40: 100%|██████████| 625/625 [00:19<00:00, 31.81it/s]\n",
      "Epoch 5/40: 100%|██████████| 625/625 [00:19<00:00, 32.28it/s]\n",
      "Epoch 6/40: 100%|██████████| 625/625 [00:19<00:00, 31.26it/s]\n",
      "Epoch 7/40: 100%|██████████| 625/625 [00:19<00:00, 32.20it/s]\n",
      "Epoch 8/40: 100%|██████████| 625/625 [00:20<00:00, 30.95it/s]\n",
      "Epoch 9/40: 100%|██████████| 625/625 [00:20<00:00, 31.21it/s]\n",
      "Epoch 10/40: 100%|██████████| 625/625 [00:19<00:00, 31.85it/s]\n",
      "Epoch 11/40: 100%|██████████| 625/625 [00:20<00:00, 30.05it/s]\n",
      "Epoch 12/40: 100%|██████████| 625/625 [00:19<00:00, 31.45it/s]\n",
      "Epoch 13/40: 100%|██████████| 625/625 [00:19<00:00, 31.94it/s]\n",
      "Epoch 14/40: 100%|██████████| 625/625 [00:19<00:00, 31.98it/s]\n",
      "Epoch 15/40: 100%|██████████| 625/625 [00:19<00:00, 32.12it/s]\n",
      "Epoch 16/40: 100%|██████████| 625/625 [00:20<00:00, 30.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#using config 2 since it is the config of best professor model\n",
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
    "\n",
    "for pruned_model_name in models_buffer.keys():\n",
    "    print(f\"\\nTreinando o modelo: {pruned_model_name}\")\n",
    "    model = models_buffer[pruned_model_name]\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    pruned_finetuned_model = finetune(train_loader, val_loader, num_epochs, model, criterion, optimizer, scheduler, pruned_model_name)\n",
    "\n",
    "    # Verifica e remove pruning (consolidação)\n",
    "    for layer in pruned_finetuned_model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) and hasattr(layer, 'weight_orig'):\n",
    "            prune.remove(layer, 'weight')\n",
    "            print(f\"Pruning removido da camada {layer}.\")\n",
    "        else:\n",
    "            print(f\"Camada {layer} não possui pruning para remover.\")\n",
    "\n",
    "    # Salva o modelo ajustado\n",
    "    torch.save(pruned_finetuned_model.state_dict(), f\"models_finetuned_frozen_alt/{pruned_model_name}_finetuned_frozen.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_buffer = {}\n",
    "for method in pruning_methods_all:\n",
    "  for percentage in [0.1, 0.2, 0.3]:\n",
    "    model = load_model(\"model_t2.h5\")\n",
    "    model.to(device)\n",
    "    models_buffer[f\"{models_folder}vgg16_pruned_allConv2dlayers_{method}_{percentage}\"] = load_model_with_masks(model, f\"{models_folder}vgg16_pruned_allConv2dlayers_{method}_{percentage}.pth\")\n",
    "\n",
    "models_buffer\n",
    "\n",
    "\n",
    "for pruned_model_name in models_buffer.keys():\n",
    "  for layer in models_buffer[pruned_model_name].modules():\n",
    "      if isinstance(layer, (nn.Conv2d)):\n",
    "          prune.remove(layer, 'weight')\n",
    "  torch.save(models_buffer[pruned_model_name].state_dict(), f\"{pruned_model_name}_frozen.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AxwDk_vNhFF"
   },
   "outputs": [],
   "source": [
    "def train_student(student_model, teacher_model, train_loader, val_loader, num_epochs, soft_target_loss_weight, ce_loss_weight, temperature, learning_rate, scheduler):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    optimizer = torch.optim.SGD(student_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass through teacher model\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "                teacher_probs = nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
    "\n",
    "            # Forward pass through student model\n",
    "            student_outputs = student_model(inputs)\n",
    "            student_probs = nn.functional.log_softmax(student_outputs / temperature, dim=1)\n",
    "\n",
    "            # Compute distillation loss\n",
    "            soft_target_loss = torch.sum(teacher_probs * (teacher_probs.log() - student_probs))/ student_probs.size()[0] * (temperature**2)\n",
    "\n",
    "            label_loss = ce_loss(student_outputs, labels)\n",
    "\n",
    "            loss = soft_target_loss_weight * soft_target_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validate the student model\n",
    "        student_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        student_model.train()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
    "\n",
    "models_buffer = {}\n",
    "teacher = load_model(\"model_t2.h5\")\n",
    "teacher.eval()\n",
    "\n",
    "\n",
    "for method in pruning_methods_all:\n",
    "  for percentage in [0.1, 0.2, 0.3]:\n",
    "    models_buffer[f\"{models_folder}vgg16_pruned_allConv2dlayers_{method}_{percentage}\"] = load_model_with_masks(model, f\"{models_folder}vgg16_pruned_allConv2dlayers_{method}_{percentage}.pth\")\n",
    "\n",
    "\n",
    "for pruned_model_name in models_buffer.keys():\n",
    "    print(f\"\\nTreinando o modelo com KD: {pruned_model_name}\")\n",
    "    student = models_buffer[pruned_model_name]\n",
    "    student.train()\n",
    "    # train_student(student, teacher, train_loader, val_loader, num_epochs,0.25, 0.75, 2, optimizer)\n",
    "    train_student(student, teacher, train_loader, val_loader, num_epochs,0.25, 0.75, 2, learning_rate, scheduler)\n",
    "\n",
    "    torch.save(student, f\"{models_folder}/{pruned_model_name}_with_KD.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size\n",
    "def get_model_size(model_path):\n",
    "    size = os.path.getsize(model_path) / (1024 * 1024)  # Convert to MB\n",
    "    return size\n",
    "\n",
    "# Sparsity\n",
    "def calculate_sparsity(model):\n",
    "    total_weights = 0\n",
    "    zero_weights = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_weights += param.numel()\n",
    "            zero_weights += torch.sum(param == 0).item()\n",
    "    sparsity = 100.0 * zero_weights / total_weights\n",
    "    return sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def get_inference_time(model, test_loader, device, num_iterations=100):\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                inputs, _ = next(iter(test_loader))\n",
    "            except StopIteration:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Timing\n",
    "        for i, (inputs, _) in enumerate(test_loader):\n",
    "            if i >= num_iterations:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            start_time = time.time()\n",
    "            outputs = model(inputs)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()  # Wait for GPU operations to finish\n",
    "            end_time = time.time()\n",
    "            total_time += (end_time - start_time)\n",
    "\n",
    "    avg_time_per_batch = total_time / num_iterations\n",
    "    return avg_time_per_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(pruning_methods_all, percentages, test_loader, device, inference_iterations = 100):\n",
    "\n",
    "  models_buffer = {\n",
    "        'pruned': {},\n",
    "        'finetuned': {},\n",
    "        'kd':{}\n",
    "    }\n",
    "  \n",
    "\n",
    "  for method in pruning_methods_all:\n",
    "\n",
    "    models_buffer['pruned'][method] = []\n",
    "    models_buffer['finetuned'][method] = []\n",
    "    models_buffer['kd'][method] = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "\n",
    "      # FROZEN - PRUNED ONLY\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_frozen\"\n",
    "      model_path = f\"{models_folder}/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "        # Load model - frozen (only pruned)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Evaluate - frozen (only pruned)\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "        # Save evaluation - frozen (only pruned)\n",
    "        models_buffer['pruned'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "      # PRUNED AND FINETUNED\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_finetuned_frozen\"\n",
    "      model_path = f\"{models_folder}/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "        # Load model - finetuned\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Evaluate - finetuned\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "\n",
    "        # Save evaluation - finetuned\n",
    "        models_buffer['finetuned'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "      #  PRUNED AND KD\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_with_KD.pth\"\n",
    "      model_path = f\"{models_folder}/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "    #    Load model - kd\n",
    "        model = load_model(model_path)\n",
    "\n",
    "    #    Evaluate - kd\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "\n",
    "    #    Save evaluation - kd\n",
    "        models_buffer['kd'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "  return models_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = get_evaluation(pruning_methods_all, [0.1, 0.2, 0.3], test_loader, device, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation in pickle file\n",
    "import pickle\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('evaluations', exist_ok=True)\n",
    "\n",
    "# Define the file path with a meaningful name\n",
    "pickle_file_path = 'evaluations/evaluation_pruning_results.pkl'\n",
    "\n",
    "# Save evaluation dictionary\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(evaluation, file)\n",
    "\n",
    "print(f\"Evaluation results saved successfully at '{pickle_file_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNFMFGH0VFE0"
   },
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWxCI6LHVHzz"
   },
   "source": [
    "comparing inference time, memory consumption, and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhIUjtAsix22"
   },
   "source": [
    "# Evaluate pruned, pruned and finetuned and pruned and KD models\n",
    "(TODO add KD on evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFGCMk9RpLCK"
   },
   "outputs": [],
   "source": [
    "# Model size\n",
    "import os\n",
    "\n",
    "def get_model_size(model_path):\n",
    "    size = os.path.getsize(model_path) / (1024 * 1024)  # Convert to MB\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sybIhtk3pg4r"
   },
   "outputs": [],
   "source": [
    "# Sparsity\n",
    "def calculate_sparsity(model):\n",
    "    total_weights = 0\n",
    "    zero_weights = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_weights += param.numel()\n",
    "            zero_weights += torch.sum(param == 0).item()\n",
    "    sparsity = 100.0 * zero_weights / total_weights\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXnRDatnSB3B"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def get_inference_time(model, test_loader, device, num_iterations=100):\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                inputs, _ = next(iter(test_loader))\n",
    "            except StopIteration:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Timing\n",
    "        for i, (inputs, _) in enumerate(test_loader):\n",
    "            if i >= num_iterations:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            start_time = time.time()\n",
    "            outputs = model(inputs)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()  # Wait for GPU operations to finish\n",
    "            end_time = time.time()\n",
    "            total_time += (end_time - start_time)\n",
    "\n",
    "    avg_time_per_batch = total_time / num_iterations\n",
    "    return avg_time_per_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpPP130nLx6c"
   },
   "outputs": [],
   "source": [
    "def get_evaluation(pruning_methods_all, percentages, test_loader, device, inference_iterations = 100):\n",
    "\n",
    "  models_buffer = {\n",
    "        'pruned': {},\n",
    "        'finetuned': {},\n",
    "        'kd': {}\n",
    "    }\n",
    "  \n",
    "\n",
    "  for method in pruning_methods_all:\n",
    "\n",
    "    models_buffer['pruned'][method] = []\n",
    "    models_buffer['finetuned'][method] = []\n",
    "    models_buffer['kd'][method] = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "\n",
    "      # FROZEN - PRUNED ONLY\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_frozen\"\n",
    "      model_path = f\"/content/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "        # Load model - frozen (only pruned)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Evaluate - frozen (only pruned)\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "        # Save evaluation - frozen (only pruned)\n",
    "        models_buffer['pruned'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "      # PRUNED AND FINETUNED\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_finetuned_frozen\"\n",
    "      model_path = f\"/content/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "        # Load model - finetuned\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Evaluate - finetuned\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "\n",
    "        # Save evaluation - finetuned\n",
    "        models_buffer['finetuned'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "      # PRUNED AND KD\n",
    "      model_name = f\"vgg16_pruned_allConv2dlayers_{method}_{percentage}_with_KD.pth\"\n",
    "      model_path = f\"/content/{model_name}.pth\"\n",
    "\n",
    "      if os.path.exists(model_path):\n",
    "\n",
    "        # Load model - kd\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Evaluate - kd\n",
    "        accuracy = calculate_accuracy(model, test_loader)\n",
    "        model_size = get_model_size(model_path)\n",
    "        sparsity = calculate_sparsity(model)\n",
    "        inference_time = get_inference_time(model, test_loader, device, inference_iterations)\n",
    "\n",
    "\n",
    "        # Save evaluation - kd\n",
    "        models_buffer['kd'][method].append({\n",
    "                'name' : model_name,\n",
    "                'pruning_percentage' : percentage,\n",
    "                'accuracy' : accuracy,\n",
    "                'model_size_MB' : model_size,\n",
    "                'sparsity' : sparsity,\n",
    "                'inference_time' : inference_time\n",
    "              })\n",
    "\n",
    "        print(f\"Evaluated Pruned Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Size: {model_size:.2f} MB, Sparsity: {sparsity:.2f}%, Inference Time: {inference_time:.6f} sec/batch\\n\")\n",
    "      else:\n",
    "        print(f\"Pruned model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "  return models_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jm467cxZOfrD"
   },
   "outputs": [],
   "source": [
    "evaluation = get_evaluation(pruning_methods_all, [0.1, 0.2, 0.3], test_loader, device, 100)\n",
    "\n",
    "# Save evaluation in pickle file\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('evaluations', exist_ok=True)\n",
    "\n",
    "# Define the file path with a meaningful name\n",
    "pickle_file_path = 'evaluations/evaluation_pruning_results.pkl'\n",
    "\n",
    "# Save evaluation dictionary\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(evaluation, file)\n",
    "\n",
    "print(f\"Evaluation results saved successfully at '{pickle_file_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yn9bbdWHVxpR"
   },
   "source": [
    "### Visualize Evaluation - ALL BY CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umgBmleElzKP"
   },
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3LQrv86V7Mc"
   },
   "outputs": [],
   "source": [
    "def buffer_to_dataframe(evaluation, category):\n",
    "    records = []\n",
    "    for method, models in evaluation.get(category, {}).items():\n",
    "        for model_info in models:\n",
    "            record = model_info.copy()\n",
    "            record['pruning_method'] = method\n",
    "            records.append(record)\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "###########################\n",
    "# # ONLY IF NEEDED -> load pickle file with evaluation\n",
    "# import pickle\n",
    "\n",
    "# # Define the pickle file path\n",
    "# pickle_file_path = 'evaluations/evaluation_pruning_results.pkl'\n",
    "\n",
    "# # Load the evaluation dictionary from the pickle file\n",
    "# with open(pickle_file_path, 'rb') as file:\n",
    "#     loaded_evaluation = pickle.load(file)\n",
    "\n",
    "# print(\"Evaluation results loaded successfully.\")\n",
    "###########################\n",
    "\n",
    "# Create DataFrames for each category\n",
    "pruned_df = buffer_to_dataframe(evaluation, 'pruned')\n",
    "finetuned_df = buffer_to_dataframe(evaluation, 'finetuned')\n",
    "kd_df = buffer_to_dataframe(evaluation, 'kd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnovHhL4V_y1"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6m1Za_jWAXs"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(df, category):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df, x='pruning_percentage', y='accuracy', hue='pruning_method', marker='o')\n",
    "    plt.title(f'Accuracy vs. Pruning Percentage ({category.capitalize()} Models)')\n",
    "    plt.xlabel('Pruning Percentage')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend(title='Pruning Method')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Accuracy for Each Category\n",
    "plot_accuracy(pruned_df, 'pruned')\n",
    "plot_accuracy(finetuned_df, 'finetuned')\n",
    "plot_accuracy(kd_df, 'kd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QzJ3dY2WB24"
   },
   "outputs": [],
   "source": [
    "def plot_inference_time(df, category):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df, x='pruning_percentage', y='inference_time_sec', hue='pruning_method', marker='o')\n",
    "    plt.title(f'Inference Time vs. Pruning Percentage ({category.capitalize()} Models)')\n",
    "    plt.xlabel('Pruning Percentage')\n",
    "    plt.ylabel('Inference Time per Batch (sec)')\n",
    "    plt.legend(title='Pruning Method')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Inference Time for Each Category\n",
    "plot_inference_time(pruned_df, 'pruned')\n",
    "plot_inference_time(finetuned_df, 'finetuned')\n",
    "plot_inference_time(kd_df, 'kd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6iA3VSTWDZj"
   },
   "outputs": [],
   "source": [
    "def plot_sparsity(df, category):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df, x='pruning_percentage', y='sparsity_percent', hue='pruning_method', marker='o')\n",
    "    plt.title(f'Sparsity vs. Pruning Percentage ({category.capitalize()} Models)')\n",
    "    plt.xlabel('Pruning Percentage')\n",
    "    plt.ylabel('Sparsity (%)')\n",
    "    plt.legend(title='Pruning Method')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Sparsity for Each Category\n",
    "plot_sparsity(pruned_df, 'pruned')\n",
    "plot_sparsity(finetuned_df, 'finetuned')\n",
    "plot_sparsity(kd_df, 'kd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovpBS1IJWE54"
   },
   "outputs": [],
   "source": [
    "def plot_model_size(df, category):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df, x='pruning_percentage', y='model_size_MB', hue='pruning_method', marker='o')\n",
    "    plt.title(f'Model Size vs. Pruning Percentage ({category.capitalize()} Models)')\n",
    "    plt.xlabel('Pruning Percentage')\n",
    "    plt.ylabel('Model Size (MB)')\n",
    "    plt.legend(title='Pruning Method')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Model Size for Each Category\n",
    "plot_model_size(pruned_df, 'pruned')\n",
    "plot_model_size(finetuned_df, 'finetuned')\n",
    "plot_model_size(kd_df, 'kd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_s1ZCG2WGWs"
   },
   "outputs": [],
   "source": [
    "# Add a 'category' column to each DataFrame\n",
    "pruned_df['category'] = 'Pruned'\n",
    "finetuned_df['category'] = 'Finetuned'\n",
    "kd_df['category'] = 'KD'\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat([pruned_df, finetuned_df, kd_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UH4Qh_V4WIKf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=combined_df, x='pruning_percentage', y='accuracy', hue='category', style='category', markers=True, dashes=False)\n",
    "plt.title('Accuracy Comparison Across Model Categories')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(title='Model Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhbYiS56WJ8J"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=combined_df, x='pruning_percentage', y='inference_time_sec', hue='category', style='category', markers=True, dashes=False)\n",
    "plt.title('Inference Time Comparison Across Model Categories')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Inference Time per Batch (sec)')\n",
    "plt.legend(title='Model Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxC3zoFcWLkT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=combined_df, x='pruning_percentage', y='sparsity_percent', hue='category', style='category', markers=True, dashes=False)\n",
    "plt.title('Sparsity Comparison Across Model Categories')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Sparsity (%)')\n",
    "plt.legend(title='Model Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tsp1O9NVWM2x"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=combined_df, x='pruning_percentage', y='model_size_MB', hue='category', style='category', markers=True, dashes=False)\n",
    "plt.title('Model Size Comparison Across Model Categories')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Model Size (MB)')\n",
    "plt.legend(title='Model Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVtPejXEWOPs"
   },
   "outputs": [],
   "source": [
    "# Function to create summary tables\n",
    "def create_summary_table(df, category):\n",
    "    summary = df.groupby(['pruning_method', 'pruning_percentage']).agg({\n",
    "        'accuracy': 'mean',\n",
    "        'model_size_MB': 'mean',\n",
    "        'sparsity_percent': 'mean',\n",
    "        'inference_time_sec': 'mean'\n",
    "    }).reset_index()\n",
    "    summary['category'] = category.capitalize()\n",
    "    return summary\n",
    "\n",
    "# Create summary tables\n",
    "pruned_summary = create_summary_table(pruned_df, 'pruned')\n",
    "finetuned_summary = create_summary_table(finetuned_df, 'finetuned')\n",
    "kd_summary = create_summary_table(kd_df, 'kd')\n",
    "\n",
    "# Combine summaries\n",
    "all_summaries = pd.concat([pruned_summary, finetuned_summary, kd_summary], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(all_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcEe-NTvWQfN"
   },
   "outputs": [],
   "source": [
    "# Create a pivot table for Accuracy\n",
    "accuracy_pivot = all_summaries.pivot_table(\n",
    "    index=['pruning_method', 'pruning_percentage'],\n",
    "    columns='category',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "print(\"Accuracy Comparison:\")\n",
    "print(accuracy_pivot)\n",
    "\n",
    "# Similarly, create pivot tables for Inference Time\n",
    "inference_time_pivot = all_summaries.pivot_table(\n",
    "    index=['pruning_method', 'pruning_percentage'],\n",
    "    columns='category',\n",
    "    values='inference_time_sec'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nInference Time Comparison (sec/batch):\")\n",
    "print(inference_time_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCQep28RWR-h"
   },
   "outputs": [],
   "source": [
    "# Pivot for heatmap\n",
    "accuracy_heatmap = accuracy_pivot.pivot(\"pruning_method\", \"pruning_percentage\", \"Finetuned\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(accuracy_heatmap, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "plt.title('Finetuned Model Accuracy Heatmap')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Pruning Method')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XGs9H3DWT3L"
   },
   "outputs": [],
   "source": [
    "# Melt the inference_time_pivot for seaborn\n",
    "inference_time_melted = inference_time_pivot.melt(id_vars=['pruning_method', 'pruning_percentage'],\n",
    "                                                var_name='category',\n",
    "                                                value_name='inference_time_sec')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=inference_time_melted, x='pruning_percentage', y='inference_time_sec', hue='category')\n",
    "plt.title('Inference Time Comparison Across Model Categories')\n",
    "plt.xlabel('Pruning Percentage')\n",
    "plt.ylabel('Avg Inference Time per Batch (sec)')\n",
    "plt.legend(title='Model Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChVOAetmWVq0"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(combined_df, col=\"pruning_method\", hue=\"category\", col_wrap=3, height=4, aspect=1)\n",
    "g.map(sns.lineplot, \"pruning_percentage\", \"accuracy\", marker=\"o\")\n",
    "g.add_legend()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Accuracy Across Pruning Methods and Categories')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia44SUVZWXXx"
   },
   "outputs": [],
   "source": [
    "def plot_grouped_bar(df, metric, title, ylabel):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(data=df, x='pruning_percentage', y=metric, hue='category', ci=None)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Pruning Percentage')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(title='Model Category')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting Accuracy Comparison\n",
    "plot_grouped_bar(combined_df, 'accuracy', 'Accuracy Comparison Across Categories', 'Accuracy (%)')\n",
    "\n",
    "# Plotting Inference Time Comparison\n",
    "plot_grouped_bar(combined_df, 'inference_time_sec', 'Inference Time Comparison Across Categories', 'Inference Time per Batch (sec)')\n",
    "\n",
    "# Plotting Sparsity Comparison\n",
    "plot_grouped_bar(combined_df, 'sparsity_percent', 'Sparsity Comparison Across Categories', 'Sparsity (%)')\n",
    "\n",
    "# Plotting Model Size Comparison\n",
    "plot_grouped_bar(combined_df, 'model_size_MB', 'Model Size Comparison Across Categories', 'Model Size (MB)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTAipxqAWYnx"
   },
   "outputs": [],
   "source": [
    "def create_summary_table(df, category):\n",
    "    summary = df.groupby(['pruning_method', 'pruning_percentage']).agg({\n",
    "        'accuracy': 'mean',\n",
    "        'model_size_MB': 'mean',\n",
    "        'sparsity_percent': 'mean',\n",
    "        'inference_time_sec': 'mean'\n",
    "    }).reset_index()\n",
    "    summary['category'] = category.capitalize()\n",
    "    return summary\n",
    "\n",
    "# Create summary tables\n",
    "pruned_summary = create_summary_table(pruned_df, 'pruned')\n",
    "finetuned_summary = create_summary_table(finetuned_df, 'finetuned')\n",
    "kd_summary = create_summary_table(kd_df, 'kd')\n",
    "\n",
    "# Combine summaries\n",
    "all_summaries = pd.concat([pruned_summary, finetuned_summary, kd_summary], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(all_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MhwjzbhWaNi"
   },
   "outputs": [],
   "source": [
    "# Pivot for Accuracy\n",
    "accuracy_pivot = all_summaries.pivot_table(\n",
    "    index=['pruning_method', 'pruning_percentage'],\n",
    "    columns='category',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "print(\"Accuracy Comparison:\")\n",
    "print(accuracy_pivot)\n",
    "\n",
    "# Pivot for Inference Time\n",
    "inference_time_pivot = all_summaries.pivot_table(\n",
    "    index=['pruning_method', 'pruning_percentage'],\n",
    "    columns='category',\n",
    "    values='inference_time_sec'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nInference Time Comparison (sec/batch):\")\n",
    "print(inference_time_pivot)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3QWIqqW5f0k1",
    "aXES_gnyNhFF"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
