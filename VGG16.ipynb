{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x40CuzhpNhE-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZoluXOdNhE_",
    "outputId": "499374f8-4b59-455c-81ab-d3404d029c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration GPU/CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yu_WMuiYNhE_",
    "outputId": "f6cc1495-2694-4094-995c-03269bb20230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUE4DhP7NhFA"
   },
   "source": [
    "## VGG-16 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gFJZgfjxNhFB"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3XXdSy52NhFB"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# num_classes = 10\n",
    "# num_epochs = 30\n",
    "batch_size = 64\n",
    "# learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps49sCQQNhFC",
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XX0TUApNhFC",
    "outputId": "72eaf6de-8a52-4120-90f2-b522242e4535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2761))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split dataset into train and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6i7NF-kDNhFD",
    "outputId": "0633a2bd-c5b0-4bb9-a3a0-ae31ad082826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 32, 32]), Labels: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(f\"Input shape: {inputs.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQZM0X2CNhFD"
   },
   "outputs": [],
   "source": [
    "# model = VGG16(num_classes=num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "57vOFZOfNhFD"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "num_classes = 10\n",
    "# num_epochs = 30\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.01\n",
    "\n",
    "config_1 = {\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"StepLR\",\n",
    "        \"step_size\": 15,\n",
    "        \"gamma\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    \"num_epochs\": 40,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"CosineAnnealingLR\",\n",
    "        \"T_max\": 40\n",
    "    }\n",
    "}\n",
    "\n",
    "config_3 = {\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"ReduceLROnPlateau\",\n",
    "        \"mode\": \"min\",\n",
    "        \"factor\": 0.1,\n",
    "        \"patience\": 10\n",
    "    },\n",
    "    \"regularization\": {\n",
    "        \"dropout_rate\": 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "def config_test(selected_config):\n",
    "    print(selected_config[\"num_epochs\"])\n",
    "    # Atribuindo os hiperpar√¢metros escolhidos\n",
    "    num_epochs = selected_config[\"num_epochs\"]\n",
    "    batch_size = selected_config[\"batch_size\"]\n",
    "    learning_rate = selected_config[\"learning_rate\"]\n",
    "    \n",
    "    model = VGG16(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if selected_config[\"optimizer\"] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif selected_config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=selected_config.get(\"momentum\", 0))\n",
    "    \n",
    "    # Configurando o scheduler baseado na configura√ß√£o\n",
    "    if selected_config[\"scheduler\"][\"type\"] == \"StepLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=selected_config[\"scheduler\"][\"step_size\"],\n",
    "            gamma=selected_config[\"scheduler\"][\"gamma\"]\n",
    "        )\n",
    "    elif selected_config[\"scheduler\"][\"type\"] == \"CosineAnnealingLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=selected_config[\"scheduler\"][\"T_max\"]\n",
    "        )\n",
    "    elif selected_config[\"scheduler\"][\"type\"] == \"ReduceLROnPlateau\":\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=selected_config[\"scheduler\"][\"mode\"],\n",
    "            factor=selected_config[\"scheduler\"][\"factor\"],\n",
    "            patience=selected_config[\"scheduler\"][\"patience\"]\n",
    "        )\n",
    "\n",
    "\n",
    "    return num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCtvmzsrNhFE"
   },
   "source": [
    "# Training Original VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8rn_wX4qNhFE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Epoch [1/50], Step [100/625], Loss: 2.3864\n",
      "Epoch [1/50], Step [200/625], Loss: 2.2682\n",
      "Epoch [1/50], Step [300/625], Loss: 2.1015\n",
      "Epoch [1/50], Step [400/625], Loss: 2.0011\n",
      "Epoch [1/50], Step [500/625], Loss: 1.9381\n",
      "Epoch [1/50], Step [600/625], Loss: 1.8948\n",
      "Epoch [1/50], Validation Loss: 1.8884, Validation Accuracy: 26.03%\n",
      "Epoch [2/50], Step [100/625], Loss: 1.9894\n",
      "Epoch [2/50], Step [200/625], Loss: 1.8809\n",
      "Epoch [2/50], Step [300/625], Loss: 1.8523\n",
      "Epoch [2/50], Step [400/625], Loss: 1.8911\n",
      "Epoch [2/50], Step [500/625], Loss: 1.8555\n",
      "Epoch [2/50], Step [600/625], Loss: 1.8407\n",
      "Epoch [2/50], Validation Loss: 1.8853, Validation Accuracy: 27.69%\n",
      "Epoch [3/50], Step [100/625], Loss: 1.7752\n",
      "Epoch [3/50], Step [200/625], Loss: 1.8089\n",
      "Epoch [3/50], Step [300/625], Loss: 1.7971\n",
      "Epoch [3/50], Step [400/625], Loss: 1.7322\n",
      "Epoch [3/50], Step [500/625], Loss: 1.6909\n",
      "Epoch [3/50], Step [600/625], Loss: 1.7109\n",
      "Epoch [3/50], Validation Loss: 1.6736, Validation Accuracy: 32.48%\n",
      "Epoch [4/50], Step [100/625], Loss: 1.6512\n",
      "Epoch [4/50], Step [200/625], Loss: 1.6140\n",
      "Epoch [4/50], Step [300/625], Loss: 1.5994\n",
      "Epoch [4/50], Step [400/625], Loss: 1.5661\n",
      "Epoch [4/50], Step [500/625], Loss: 1.5649\n",
      "Epoch [4/50], Step [600/625], Loss: 1.5056\n",
      "Epoch [4/50], Validation Loss: 1.5318, Validation Accuracy: 40.54%\n",
      "Epoch [5/50], Step [100/625], Loss: 1.4928\n",
      "Epoch [5/50], Step [200/625], Loss: 1.4644\n",
      "Epoch [5/50], Step [300/625], Loss: 1.4303\n",
      "Epoch [5/50], Step [400/625], Loss: 1.4272\n",
      "Epoch [5/50], Step [500/625], Loss: 1.3880\n",
      "Epoch [5/50], Step [600/625], Loss: 1.3648\n",
      "Epoch [5/50], Validation Loss: 1.3636, Validation Accuracy: 50.82%\n",
      "Epoch [6/50], Step [100/625], Loss: 1.3191\n",
      "Epoch [6/50], Step [200/625], Loss: 1.3042\n",
      "Epoch [6/50], Step [300/625], Loss: 1.2597\n",
      "Epoch [6/50], Step [400/625], Loss: 1.2780\n",
      "Epoch [6/50], Step [500/625], Loss: 1.2338\n",
      "Epoch [6/50], Step [600/625], Loss: 1.1993\n",
      "Epoch [6/50], Validation Loss: 1.1697, Validation Accuracy: 56.88%\n",
      "Epoch [7/50], Step [100/625], Loss: 1.1444\n",
      "Epoch [7/50], Step [200/625], Loss: 1.1460\n",
      "Epoch [7/50], Step [300/625], Loss: 1.1056\n",
      "Epoch [7/50], Step [400/625], Loss: 1.0799\n",
      "Epoch [7/50], Step [500/625], Loss: 1.1019\n",
      "Epoch [7/50], Step [600/625], Loss: 1.0852\n",
      "Epoch [7/50], Validation Loss: 1.0518, Validation Accuracy: 62.62%\n",
      "Epoch [8/50], Step [100/625], Loss: 1.0143\n",
      "Epoch [8/50], Step [200/625], Loss: 1.0172\n",
      "Epoch [8/50], Step [300/625], Loss: 0.9965\n",
      "Epoch [8/50], Step [400/625], Loss: 1.0177\n",
      "Epoch [8/50], Step [500/625], Loss: 1.0096\n",
      "Epoch [8/50], Step [600/625], Loss: 0.9878\n",
      "Epoch [8/50], Validation Loss: 0.9837, Validation Accuracy: 66.40%\n",
      "Epoch [9/50], Step [100/625], Loss: 0.9435\n",
      "Epoch [9/50], Step [200/625], Loss: 0.9381\n",
      "Epoch [9/50], Step [300/625], Loss: 0.9374\n",
      "Epoch [9/50], Step [400/625], Loss: 0.9019\n",
      "Epoch [9/50], Step [500/625], Loss: 0.8710\n",
      "Epoch [9/50], Step [600/625], Loss: 0.8988\n",
      "Epoch [9/50], Validation Loss: 0.9385, Validation Accuracy: 68.01%\n",
      "Epoch [10/50], Step [100/625], Loss: 0.8645\n",
      "Epoch [10/50], Step [200/625], Loss: 0.8499\n",
      "Epoch [10/50], Step [300/625], Loss: 0.8562\n",
      "Epoch [10/50], Step [400/625], Loss: 0.8336\n",
      "Epoch [10/50], Step [500/625], Loss: 0.8061\n",
      "Epoch [10/50], Step [600/625], Loss: 0.8159\n",
      "Epoch [10/50], Validation Loss: 0.8773, Validation Accuracy: 70.25%\n",
      "Epoch [11/50], Step [100/625], Loss: 0.7978\n",
      "Epoch [11/50], Step [200/625], Loss: 0.7688\n",
      "Epoch [11/50], Step [300/625], Loss: 0.7450\n",
      "Epoch [11/50], Step [400/625], Loss: 0.7555\n",
      "Epoch [11/50], Step [500/625], Loss: 0.7556\n",
      "Epoch [11/50], Step [600/625], Loss: 0.7810\n",
      "Epoch [11/50], Validation Loss: 0.7872, Validation Accuracy: 73.92%\n",
      "Epoch [12/50], Step [100/625], Loss: 0.7229\n",
      "Epoch [12/50], Step [200/625], Loss: 0.6956\n",
      "Epoch [12/50], Step [300/625], Loss: 0.7137\n",
      "Epoch [12/50], Step [400/625], Loss: 0.6911\n",
      "Epoch [12/50], Step [500/625], Loss: 0.6950\n",
      "Epoch [12/50], Step [600/625], Loss: 0.7272\n",
      "Epoch [12/50], Validation Loss: 0.7648, Validation Accuracy: 75.02%\n",
      "Epoch [13/50], Step [100/625], Loss: 0.6373\n",
      "Epoch [13/50], Step [200/625], Loss: 0.6519\n",
      "Epoch [13/50], Step [300/625], Loss: 0.6553\n",
      "Epoch [13/50], Step [400/625], Loss: 0.6498\n",
      "Epoch [13/50], Step [500/625], Loss: 0.6436\n",
      "Epoch [13/50], Step [600/625], Loss: 0.6419\n",
      "Epoch [13/50], Validation Loss: 0.6962, Validation Accuracy: 77.74%\n",
      "Epoch [14/50], Step [100/625], Loss: 0.6270\n",
      "Epoch [14/50], Step [200/625], Loss: 0.6321\n",
      "Epoch [14/50], Step [300/625], Loss: 0.6085\n",
      "Epoch [14/50], Step [400/625], Loss: 0.5996\n",
      "Epoch [14/50], Step [500/625], Loss: 0.6012\n",
      "Epoch [14/50], Step [600/625], Loss: 0.6167\n",
      "Epoch [14/50], Validation Loss: 0.7027, Validation Accuracy: 76.65%\n",
      "Epoch [15/50], Step [100/625], Loss: 0.5738\n",
      "Epoch [15/50], Step [200/625], Loss: 0.5692\n",
      "Epoch [15/50], Step [300/625], Loss: 0.5579\n",
      "Epoch [15/50], Step [400/625], Loss: 0.5552\n",
      "Epoch [15/50], Step [500/625], Loss: 0.5950\n",
      "Epoch [15/50], Step [600/625], Loss: 0.5906\n",
      "Epoch [15/50], Validation Loss: 0.6758, Validation Accuracy: 78.29%\n",
      "Epoch [16/50], Step [100/625], Loss: 0.4741\n",
      "Epoch [16/50], Step [200/625], Loss: 0.4327\n",
      "Epoch [16/50], Step [300/625], Loss: 0.4374\n",
      "Epoch [16/50], Step [400/625], Loss: 0.4498\n",
      "Epoch [16/50], Step [500/625], Loss: 0.4153\n",
      "Epoch [16/50], Step [600/625], Loss: 0.4204\n",
      "Epoch [16/50], Validation Loss: 0.5473, Validation Accuracy: 81.90%\n",
      "Epoch [17/50], Step [100/625], Loss: 0.4152\n",
      "Epoch [17/50], Step [200/625], Loss: 0.3908\n",
      "Epoch [17/50], Step [300/625], Loss: 0.4007\n",
      "Epoch [17/50], Step [400/625], Loss: 0.3969\n",
      "Epoch [17/50], Step [500/625], Loss: 0.3979\n",
      "Epoch [17/50], Step [600/625], Loss: 0.4236\n",
      "Epoch [17/50], Validation Loss: 0.5421, Validation Accuracy: 82.29%\n",
      "Epoch [18/50], Step [100/625], Loss: 0.4052\n",
      "Epoch [18/50], Step [200/625], Loss: 0.3995\n",
      "Epoch [18/50], Step [300/625], Loss: 0.3875\n",
      "Epoch [18/50], Step [400/625], Loss: 0.3719\n",
      "Epoch [18/50], Step [500/625], Loss: 0.3703\n",
      "Epoch [18/50], Step [600/625], Loss: 0.3921\n",
      "Epoch [18/50], Validation Loss: 0.5329, Validation Accuracy: 82.77%\n",
      "Epoch [19/50], Step [100/625], Loss: 0.3688\n",
      "Epoch [19/50], Step [200/625], Loss: 0.3730\n",
      "Epoch [19/50], Step [300/625], Loss: 0.3742\n",
      "Epoch [19/50], Step [400/625], Loss: 0.3659\n",
      "Epoch [19/50], Step [500/625], Loss: 0.3731\n",
      "Epoch [19/50], Step [600/625], Loss: 0.3749\n",
      "Epoch [19/50], Validation Loss: 0.5230, Validation Accuracy: 82.93%\n",
      "Epoch [20/50], Step [100/625], Loss: 0.3592\n",
      "Epoch [20/50], Step [200/625], Loss: 0.3859\n",
      "Epoch [20/50], Step [300/625], Loss: 0.3623\n",
      "Epoch [20/50], Step [400/625], Loss: 0.3550\n",
      "Epoch [20/50], Step [500/625], Loss: 0.3538\n",
      "Epoch [20/50], Step [600/625], Loss: 0.3804\n",
      "Epoch [20/50], Validation Loss: 0.5270, Validation Accuracy: 83.16%\n",
      "Epoch [21/50], Step [100/625], Loss: 0.3524\n",
      "Epoch [21/50], Step [200/625], Loss: 0.3464\n",
      "Epoch [21/50], Step [300/625], Loss: 0.3647\n",
      "Epoch [21/50], Step [400/625], Loss: 0.3539\n",
      "Epoch [21/50], Step [500/625], Loss: 0.3635\n",
      "Epoch [21/50], Step [600/625], Loss: 0.3677\n",
      "Epoch [21/50], Validation Loss: 0.5120, Validation Accuracy: 83.92%\n",
      "Epoch [22/50], Step [100/625], Loss: 0.3571\n",
      "Epoch [22/50], Step [200/625], Loss: 0.3336\n",
      "Epoch [22/50], Step [300/625], Loss: 0.3411\n",
      "Epoch [22/50], Step [400/625], Loss: 0.3375\n",
      "Epoch [22/50], Step [500/625], Loss: 0.3483\n",
      "Epoch [22/50], Step [600/625], Loss: 0.3516\n",
      "Epoch [22/50], Validation Loss: 0.5254, Validation Accuracy: 83.39%\n",
      "Epoch [23/50], Step [100/625], Loss: 0.3489\n",
      "Epoch [23/50], Step [200/625], Loss: 0.3442\n",
      "Epoch [23/50], Step [300/625], Loss: 0.3342\n",
      "Epoch [23/50], Step [400/625], Loss: 0.3428\n",
      "Epoch [23/50], Step [500/625], Loss: 0.3324\n",
      "Epoch [23/50], Step [600/625], Loss: 0.3560\n",
      "Epoch [23/50], Validation Loss: 0.5127, Validation Accuracy: 83.58%\n",
      "Epoch [24/50], Step [100/625], Loss: 0.3263\n",
      "Epoch [24/50], Step [200/625], Loss: 0.3107\n",
      "Epoch [24/50], Step [300/625], Loss: 0.3188\n",
      "Epoch [24/50], Step [400/625], Loss: 0.3568\n",
      "Epoch [24/50], Step [500/625], Loss: 0.3308\n",
      "Epoch [24/50], Step [600/625], Loss: 0.3324\n",
      "Epoch [24/50], Validation Loss: 0.5171, Validation Accuracy: 84.13%\n",
      "Epoch [25/50], Step [100/625], Loss: 0.3180\n",
      "Epoch [25/50], Step [200/625], Loss: 0.3357\n",
      "Epoch [25/50], Step [300/625], Loss: 0.3445\n",
      "Epoch [25/50], Step [400/625], Loss: 0.3242\n",
      "Epoch [25/50], Step [500/625], Loss: 0.3068\n",
      "Epoch [25/50], Step [600/625], Loss: 0.3276\n",
      "Epoch [25/50], Validation Loss: 0.5148, Validation Accuracy: 83.66%\n",
      "Epoch [26/50], Step [100/625], Loss: 0.3085\n",
      "Epoch [26/50], Step [200/625], Loss: 0.3179\n",
      "Epoch [26/50], Step [300/625], Loss: 0.3254\n",
      "Epoch [26/50], Step [400/625], Loss: 0.3301\n",
      "Epoch [26/50], Step [500/625], Loss: 0.3065\n",
      "Epoch [26/50], Step [600/625], Loss: 0.3045\n",
      "Epoch [26/50], Validation Loss: 0.5093, Validation Accuracy: 84.20%\n",
      "Epoch [27/50], Step [100/625], Loss: 0.2938\n",
      "Epoch [27/50], Step [200/625], Loss: 0.3254\n",
      "Epoch [27/50], Step [300/625], Loss: 0.3122\n",
      "Epoch [27/50], Step [400/625], Loss: 0.3200\n",
      "Epoch [27/50], Step [500/625], Loss: 0.2868\n",
      "Epoch [27/50], Step [600/625], Loss: 0.3195\n",
      "Epoch [27/50], Validation Loss: 0.5178, Validation Accuracy: 84.30%\n",
      "Epoch [28/50], Step [100/625], Loss: 0.3083\n",
      "Epoch [28/50], Step [200/625], Loss: 0.3034\n",
      "Epoch [28/50], Step [300/625], Loss: 0.3192\n",
      "Epoch [28/50], Step [400/625], Loss: 0.2889\n",
      "Epoch [28/50], Step [500/625], Loss: 0.2928\n",
      "Epoch [28/50], Step [600/625], Loss: 0.3071\n",
      "Epoch [28/50], Validation Loss: 0.5217, Validation Accuracy: 84.20%\n",
      "Epoch [29/50], Step [100/625], Loss: 0.3088\n",
      "Epoch [29/50], Step [200/625], Loss: 0.3017\n",
      "Epoch [29/50], Step [300/625], Loss: 0.2839\n",
      "Epoch [29/50], Step [400/625], Loss: 0.2851\n",
      "Epoch [29/50], Step [500/625], Loss: 0.2972\n",
      "Epoch [29/50], Step [600/625], Loss: 0.2906\n",
      "Epoch [29/50], Validation Loss: 0.5156, Validation Accuracy: 83.93%\n",
      "Epoch [30/50], Step [100/625], Loss: 0.2878\n",
      "Epoch [30/50], Step [200/625], Loss: 0.2777\n",
      "Epoch [30/50], Step [300/625], Loss: 0.2945\n",
      "Epoch [30/50], Step [400/625], Loss: 0.2916\n",
      "Epoch [30/50], Step [500/625], Loss: 0.3055\n",
      "Epoch [30/50], Step [600/625], Loss: 0.2818\n",
      "Epoch [30/50], Validation Loss: 0.5206, Validation Accuracy: 84.30%\n",
      "Epoch [31/50], Step [100/625], Loss: 0.2831\n",
      "Epoch [31/50], Step [200/625], Loss: 0.2834\n",
      "Epoch [31/50], Step [300/625], Loss: 0.2792\n",
      "Epoch [31/50], Step [400/625], Loss: 0.2599\n",
      "Epoch [31/50], Step [500/625], Loss: 0.2816\n",
      "Epoch [31/50], Step [600/625], Loss: 0.2609\n",
      "Epoch [31/50], Validation Loss: 0.5002, Validation Accuracy: 84.76%\n",
      "Epoch [32/50], Step [100/625], Loss: 0.2831\n",
      "Epoch [32/50], Step [200/625], Loss: 0.2801\n",
      "Epoch [32/50], Step [300/625], Loss: 0.2790\n",
      "Epoch [32/50], Step [400/625], Loss: 0.2783\n",
      "Epoch [32/50], Step [500/625], Loss: 0.2718\n",
      "Epoch [32/50], Step [600/625], Loss: 0.2483\n",
      "Epoch [32/50], Validation Loss: 0.5125, Validation Accuracy: 84.11%\n",
      "Epoch [33/50], Step [100/625], Loss: 0.2660\n",
      "Epoch [33/50], Step [200/625], Loss: 0.2799\n",
      "Epoch [33/50], Step [300/625], Loss: 0.2707\n",
      "Epoch [33/50], Step [400/625], Loss: 0.2823\n",
      "Epoch [33/50], Step [500/625], Loss: 0.2650\n",
      "Epoch [33/50], Step [600/625], Loss: 0.2539\n",
      "Epoch [33/50], Validation Loss: 0.5051, Validation Accuracy: 84.53%\n",
      "Epoch [34/50], Step [100/625], Loss: 0.2766\n",
      "Epoch [34/50], Step [200/625], Loss: 0.2563\n",
      "Epoch [34/50], Step [300/625], Loss: 0.2610\n",
      "Epoch [34/50], Step [400/625], Loss: 0.2739\n",
      "Epoch [34/50], Step [500/625], Loss: 0.2672\n",
      "Epoch [34/50], Step [600/625], Loss: 0.2789\n",
      "Epoch [34/50], Validation Loss: 0.5090, Validation Accuracy: 84.54%\n",
      "Epoch [35/50], Step [100/625], Loss: 0.2700\n",
      "Epoch [35/50], Step [200/625], Loss: 0.2572\n",
      "Epoch [35/50], Step [300/625], Loss: 0.2699\n",
      "Epoch [35/50], Step [400/625], Loss: 0.2648\n",
      "Epoch [35/50], Step [500/625], Loss: 0.2524\n",
      "Epoch [35/50], Step [600/625], Loss: 0.2641\n",
      "Epoch [35/50], Validation Loss: 0.5108, Validation Accuracy: 84.51%\n",
      "Epoch [36/50], Step [100/625], Loss: 0.2697\n",
      "Epoch [36/50], Step [200/625], Loss: 0.2432\n",
      "Epoch [36/50], Step [300/625], Loss: 0.2599\n",
      "Epoch [36/50], Step [400/625], Loss: 0.2700\n",
      "Epoch [36/50], Step [500/625], Loss: 0.2619\n",
      "Epoch [36/50], Step [600/625], Loss: 0.2656\n",
      "Epoch [36/50], Validation Loss: 0.5032, Validation Accuracy: 85.04%\n",
      "Epoch [37/50], Step [100/625], Loss: 0.2785\n",
      "Epoch [37/50], Step [200/625], Loss: 0.2551\n",
      "Epoch [37/50], Step [300/625], Loss: 0.2742\n",
      "Epoch [37/50], Step [400/625], Loss: 0.2659\n",
      "Epoch [37/50], Step [500/625], Loss: 0.2573\n",
      "Epoch [37/50], Step [600/625], Loss: 0.2516\n",
      "Epoch [37/50], Validation Loss: 0.5037, Validation Accuracy: 84.64%\n",
      "Epoch [38/50], Step [100/625], Loss: 0.2622\n",
      "Epoch [38/50], Step [200/625], Loss: 0.2570\n",
      "Epoch [38/50], Step [300/625], Loss: 0.2611\n",
      "Epoch [38/50], Step [400/625], Loss: 0.2703\n",
      "Epoch [38/50], Step [500/625], Loss: 0.2526\n",
      "Epoch [38/50], Step [600/625], Loss: 0.2654\n",
      "Epoch [38/50], Validation Loss: 0.5172, Validation Accuracy: 84.56%\n",
      "Epoch [39/50], Step [100/625], Loss: 0.2563\n",
      "Epoch [39/50], Step [200/625], Loss: 0.2542\n",
      "Epoch [39/50], Step [300/625], Loss: 0.2468\n",
      "Epoch [39/50], Step [400/625], Loss: 0.2683\n",
      "Epoch [39/50], Step [500/625], Loss: 0.2691\n",
      "Epoch [39/50], Step [600/625], Loss: 0.2557\n",
      "Epoch [39/50], Validation Loss: 0.5182, Validation Accuracy: 84.41%\n",
      "Epoch [40/50], Step [100/625], Loss: 0.2538\n",
      "Epoch [40/50], Step [200/625], Loss: 0.2426\n",
      "Epoch [40/50], Step [300/625], Loss: 0.2491\n",
      "Epoch [40/50], Step [400/625], Loss: 0.2664\n",
      "Epoch [40/50], Step [500/625], Loss: 0.2624\n",
      "Epoch [40/50], Step [600/625], Loss: 0.2769\n",
      "Epoch [40/50], Validation Loss: 0.5195, Validation Accuracy: 84.95%\n",
      "Epoch [41/50], Step [100/625], Loss: 0.2559\n",
      "Epoch [41/50], Step [200/625], Loss: 0.2534\n",
      "Epoch [41/50], Step [300/625], Loss: 0.2663\n",
      "Epoch [41/50], Step [400/625], Loss: 0.2622\n",
      "Epoch [41/50], Step [500/625], Loss: 0.2652\n",
      "Epoch [41/50], Step [600/625], Loss: 0.2461\n",
      "Epoch [41/50], Validation Loss: 0.5239, Validation Accuracy: 84.38%\n",
      "Epoch [42/50], Step [100/625], Loss: 0.2647\n",
      "Epoch [42/50], Step [200/625], Loss: 0.2546\n",
      "Epoch [42/50], Step [300/625], Loss: 0.2615\n",
      "Epoch [42/50], Step [400/625], Loss: 0.2542\n",
      "Epoch [42/50], Step [500/625], Loss: 0.2551\n",
      "Epoch [42/50], Step [600/625], Loss: 0.2404\n",
      "Epoch [42/50], Validation Loss: 0.5155, Validation Accuracy: 84.29%\n",
      "Epoch [43/50], Step [100/625], Loss: 0.2463\n",
      "Epoch [43/50], Step [200/625], Loss: 0.2544\n",
      "Epoch [43/50], Step [300/625], Loss: 0.2685\n",
      "Epoch [43/50], Step [400/625], Loss: 0.2631\n",
      "Epoch [43/50], Step [500/625], Loss: 0.2586\n",
      "Epoch [43/50], Step [600/625], Loss: 0.2649\n",
      "Epoch [43/50], Validation Loss: 0.5192, Validation Accuracy: 84.30%\n",
      "Epoch [44/50], Step [100/625], Loss: 0.2547\n",
      "Epoch [44/50], Step [200/625], Loss: 0.2519\n",
      "Epoch [44/50], Step [300/625], Loss: 0.2604\n",
      "Epoch [44/50], Step [400/625], Loss: 0.2489\n",
      "Epoch [44/50], Step [500/625], Loss: 0.2770\n",
      "Epoch [44/50], Step [600/625], Loss: 0.2627\n",
      "Epoch [44/50], Validation Loss: 0.5160, Validation Accuracy: 85.08%\n",
      "Epoch [45/50], Step [100/625], Loss: 0.2625\n",
      "Epoch [45/50], Step [200/625], Loss: 0.2508\n",
      "Epoch [45/50], Step [300/625], Loss: 0.2695\n",
      "Epoch [45/50], Step [400/625], Loss: 0.2634\n",
      "Epoch [45/50], Step [500/625], Loss: 0.2545\n",
      "Epoch [45/50], Step [600/625], Loss: 0.2457\n",
      "Epoch [45/50], Validation Loss: 0.4997, Validation Accuracy: 84.93%\n",
      "Epoch [46/50], Step [100/625], Loss: 0.2548\n",
      "Epoch [46/50], Step [200/625], Loss: 0.2610\n",
      "Epoch [46/50], Step [300/625], Loss: 0.2521\n",
      "Epoch [46/50], Step [400/625], Loss: 0.2658\n",
      "Epoch [46/50], Step [500/625], Loss: 0.2454\n",
      "Epoch [46/50], Step [600/625], Loss: 0.2511\n",
      "Epoch [46/50], Validation Loss: 0.5167, Validation Accuracy: 84.20%\n",
      "Epoch [47/50], Step [100/625], Loss: 0.2405\n",
      "Epoch [47/50], Step [200/625], Loss: 0.2715\n",
      "Epoch [47/50], Step [300/625], Loss: 0.2653\n",
      "Epoch [47/50], Step [400/625], Loss: 0.2348\n",
      "Epoch [47/50], Step [500/625], Loss: 0.2579\n",
      "Epoch [47/50], Step [600/625], Loss: 0.2522\n",
      "Epoch [47/50], Validation Loss: 0.5075, Validation Accuracy: 84.55%\n",
      "Epoch [48/50], Step [100/625], Loss: 0.2559\n",
      "Epoch [48/50], Step [200/625], Loss: 0.2472\n",
      "Epoch [48/50], Step [300/625], Loss: 0.2537\n",
      "Epoch [48/50], Step [400/625], Loss: 0.2552\n",
      "Epoch [48/50], Step [500/625], Loss: 0.2594\n",
      "Epoch [48/50], Step [600/625], Loss: 0.2605\n",
      "Epoch [48/50], Validation Loss: 0.5031, Validation Accuracy: 85.12%\n",
      "Epoch [49/50], Step [100/625], Loss: 0.2583\n",
      "Epoch [49/50], Step [200/625], Loss: 0.2652\n",
      "Epoch [49/50], Step [300/625], Loss: 0.2526\n",
      "Epoch [49/50], Step [400/625], Loss: 0.2513\n",
      "Epoch [49/50], Step [500/625], Loss: 0.2496\n",
      "Epoch [49/50], Step [600/625], Loss: 0.2520\n",
      "Epoch [49/50], Validation Loss: 0.5197, Validation Accuracy: 84.77%\n",
      "Epoch [50/50], Step [100/625], Loss: 0.2469\n",
      "Epoch [50/50], Step [200/625], Loss: 0.2490\n",
      "Epoch [50/50], Step [300/625], Loss: 0.2519\n",
      "Epoch [50/50], Step [400/625], Loss: 0.2488\n",
      "Epoch [50/50], Step [500/625], Loss: 0.2502\n",
      "Epoch [50/50], Step [600/625], Loss: 0.2628\n",
      "Epoch [50/50], Validation Loss: 0.5092, Validation Accuracy: 84.48%\n"
     ]
    }
   ],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_1)\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"model_t1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvaGF1pXNhFE"
   },
   "source": [
    "The code in the cell looks correct and should work without any errors, given that all the necessary variables and modules are already defined and imported in the previous cells. However, to ensure that the code runs smoothly, you should make sure that the `train_loader`, `val_loader`, `model`, `criterion`, `optimizer`, `device`, and `num_epochs` are properly defined and imported.\n",
    "\n",
    "\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3ruV5TuyNhFF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.49%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Epoch [1/40], Step [100/625], Loss: 2.1439\n",
      "Epoch [1/40], Step [200/625], Loss: 1.8907\n",
      "Epoch [1/40], Step [300/625], Loss: 1.7771\n",
      "Epoch [1/40], Step [400/625], Loss: 1.6532\n",
      "Epoch [1/40], Step [500/625], Loss: 1.5873\n",
      "Epoch [1/40], Step [600/625], Loss: 1.4504\n",
      "Epoch [1/40], Validation Loss: 1.6401, Validation Accuracy: 45.38%\n",
      "Epoch [2/40], Step [100/625], Loss: 2.0406\n",
      "Epoch [2/40], Step [200/625], Loss: 1.8989\n",
      "Epoch [2/40], Step [300/625], Loss: 1.7858\n",
      "Epoch [2/40], Step [400/625], Loss: 1.7573\n",
      "Epoch [2/40], Step [500/625], Loss: 1.6150\n",
      "Epoch [2/40], Step [600/625], Loss: 1.5562\n",
      "Epoch [2/40], Validation Loss: 1.5370, Validation Accuracy: 40.25%\n",
      "Epoch [3/40], Step [100/625], Loss: 1.4780\n",
      "Epoch [3/40], Step [200/625], Loss: 1.4468\n",
      "Epoch [3/40], Step [300/625], Loss: 1.4585\n",
      "Epoch [3/40], Step [400/625], Loss: 1.3172\n",
      "Epoch [3/40], Step [500/625], Loss: 1.3088\n",
      "Epoch [3/40], Step [600/625], Loss: 1.2272\n",
      "Epoch [3/40], Validation Loss: 1.1982, Validation Accuracy: 58.12%\n",
      "Epoch [4/40], Step [100/625], Loss: 1.2133\n",
      "Epoch [4/40], Step [200/625], Loss: 1.1401\n",
      "Epoch [4/40], Step [300/625], Loss: 1.0967\n",
      "Epoch [4/40], Step [400/625], Loss: 1.0952\n",
      "Epoch [4/40], Step [500/625], Loss: 1.0206\n",
      "Epoch [4/40], Step [600/625], Loss: 1.0368\n",
      "Epoch [4/40], Validation Loss: 0.9868, Validation Accuracy: 65.63%\n",
      "Epoch [5/40], Step [100/625], Loss: 1.0148\n",
      "Epoch [5/40], Step [200/625], Loss: 0.9630\n",
      "Epoch [5/40], Step [300/625], Loss: 0.9636\n",
      "Epoch [5/40], Step [400/625], Loss: 0.9359\n",
      "Epoch [5/40], Step [500/625], Loss: 0.9138\n",
      "Epoch [5/40], Step [600/625], Loss: 0.9081\n",
      "Epoch [5/40], Validation Loss: 0.9517, Validation Accuracy: 67.45%\n",
      "Epoch [6/40], Step [100/625], Loss: 0.8835\n",
      "Epoch [6/40], Step [200/625], Loss: 0.8385\n",
      "Epoch [6/40], Step [300/625], Loss: 0.8442\n",
      "Epoch [6/40], Step [400/625], Loss: 0.8131\n",
      "Epoch [6/40], Step [500/625], Loss: 0.8625\n",
      "Epoch [6/40], Step [600/625], Loss: 0.7988\n",
      "Epoch [6/40], Validation Loss: 0.9234, Validation Accuracy: 69.03%\n",
      "Epoch [7/40], Step [100/625], Loss: 0.7773\n",
      "Epoch [7/40], Step [200/625], Loss: 0.7694\n",
      "Epoch [7/40], Step [300/625], Loss: 0.7365\n",
      "Epoch [7/40], Step [400/625], Loss: 0.7324\n",
      "Epoch [7/40], Step [500/625], Loss: 0.7473\n",
      "Epoch [7/40], Step [600/625], Loss: 0.7563\n",
      "Epoch [7/40], Validation Loss: 0.7797, Validation Accuracy: 74.27%\n",
      "Epoch [8/40], Step [100/625], Loss: 0.6788\n",
      "Epoch [8/40], Step [200/625], Loss: 0.7046\n",
      "Epoch [8/40], Step [300/625], Loss: 0.6780\n",
      "Epoch [8/40], Step [400/625], Loss: 0.6882\n",
      "Epoch [8/40], Step [500/625], Loss: 0.6785\n",
      "Epoch [8/40], Step [600/625], Loss: 0.6472\n",
      "Epoch [8/40], Validation Loss: 0.7198, Validation Accuracy: 76.28%\n",
      "Epoch [9/40], Step [100/625], Loss: 0.6287\n",
      "Epoch [9/40], Step [200/625], Loss: 0.6481\n",
      "Epoch [9/40], Step [300/625], Loss: 0.6118\n",
      "Epoch [9/40], Step [400/625], Loss: 0.6300\n",
      "Epoch [9/40], Step [500/625], Loss: 0.6218\n",
      "Epoch [9/40], Step [600/625], Loss: 0.6209\n",
      "Epoch [9/40], Validation Loss: 0.6335, Validation Accuracy: 79.00%\n",
      "Epoch [10/40], Step [100/625], Loss: 0.5717\n",
      "Epoch [10/40], Step [200/625], Loss: 0.6049\n",
      "Epoch [10/40], Step [300/625], Loss: 0.5775\n",
      "Epoch [10/40], Step [400/625], Loss: 0.5882\n",
      "Epoch [10/40], Step [500/625], Loss: 0.5639\n",
      "Epoch [10/40], Step [600/625], Loss: 0.6074\n",
      "Epoch [10/40], Validation Loss: 0.6228, Validation Accuracy: 79.63%\n",
      "Epoch [11/40], Step [100/625], Loss: 0.5523\n",
      "Epoch [11/40], Step [200/625], Loss: 0.5148\n",
      "Epoch [11/40], Step [300/625], Loss: 0.5424\n",
      "Epoch [11/40], Step [400/625], Loss: 0.5443\n",
      "Epoch [11/40], Step [500/625], Loss: 0.5442\n",
      "Epoch [11/40], Step [600/625], Loss: 0.5370\n",
      "Epoch [11/40], Validation Loss: 0.5940, Validation Accuracy: 81.04%\n",
      "Epoch [12/40], Step [100/625], Loss: 0.5045\n",
      "Epoch [12/40], Step [200/625], Loss: 0.5044\n",
      "Epoch [12/40], Step [300/625], Loss: 0.4833\n",
      "Epoch [12/40], Step [400/625], Loss: 0.4944\n",
      "Epoch [12/40], Step [500/625], Loss: 0.5105\n",
      "Epoch [12/40], Step [600/625], Loss: 0.5066\n",
      "Epoch [12/40], Validation Loss: 0.5885, Validation Accuracy: 80.80%\n",
      "Epoch [13/40], Step [100/625], Loss: 0.4535\n",
      "Epoch [13/40], Step [200/625], Loss: 0.4795\n",
      "Epoch [13/40], Step [300/625], Loss: 0.4531\n",
      "Epoch [13/40], Step [400/625], Loss: 0.4592\n",
      "Epoch [13/40], Step [500/625], Loss: 0.4905\n",
      "Epoch [13/40], Step [600/625], Loss: 0.4350\n",
      "Epoch [13/40], Validation Loss: 0.5589, Validation Accuracy: 82.30%\n",
      "Epoch [14/40], Step [100/625], Loss: 0.4265\n",
      "Epoch [14/40], Step [200/625], Loss: 0.4294\n",
      "Epoch [14/40], Step [300/625], Loss: 0.4120\n",
      "Epoch [14/40], Step [400/625], Loss: 0.4150\n",
      "Epoch [14/40], Step [500/625], Loss: 0.4324\n",
      "Epoch [14/40], Step [600/625], Loss: 0.4521\n",
      "Epoch [14/40], Validation Loss: 0.5607, Validation Accuracy: 82.13%\n",
      "Epoch [15/40], Step [100/625], Loss: 0.3906\n",
      "Epoch [15/40], Step [200/625], Loss: 0.3877\n",
      "Epoch [15/40], Step [300/625], Loss: 0.4183\n",
      "Epoch [15/40], Step [400/625], Loss: 0.4083\n",
      "Epoch [15/40], Step [500/625], Loss: 0.3896\n",
      "Epoch [15/40], Step [600/625], Loss: 0.3740\n",
      "Epoch [15/40], Validation Loss: 0.4967, Validation Accuracy: 84.07%\n",
      "Epoch [16/40], Step [100/625], Loss: 0.3493\n",
      "Epoch [16/40], Step [200/625], Loss: 0.3820\n",
      "Epoch [16/40], Step [300/625], Loss: 0.3579\n",
      "Epoch [16/40], Step [400/625], Loss: 0.3757\n",
      "Epoch [16/40], Step [500/625], Loss: 0.3687\n",
      "Epoch [16/40], Step [600/625], Loss: 0.3765\n",
      "Epoch [16/40], Validation Loss: 0.5015, Validation Accuracy: 83.52%\n",
      "Epoch [17/40], Step [100/625], Loss: 0.3409\n",
      "Epoch [17/40], Step [200/625], Loss: 0.3400\n",
      "Epoch [17/40], Step [300/625], Loss: 0.3399\n",
      "Epoch [17/40], Step [400/625], Loss: 0.3502\n",
      "Epoch [17/40], Step [500/625], Loss: 0.3522\n",
      "Epoch [17/40], Step [600/625], Loss: 0.3430\n",
      "Epoch [17/40], Validation Loss: 0.4994, Validation Accuracy: 83.82%\n",
      "Epoch [18/40], Step [100/625], Loss: 0.2983\n",
      "Epoch [18/40], Step [200/625], Loss: 0.3175\n",
      "Epoch [18/40], Step [300/625], Loss: 0.3211\n",
      "Epoch [18/40], Step [400/625], Loss: 0.3133\n",
      "Epoch [18/40], Step [500/625], Loss: 0.3170\n",
      "Epoch [18/40], Step [600/625], Loss: 0.3213\n",
      "Epoch [18/40], Validation Loss: 0.4747, Validation Accuracy: 84.66%\n",
      "Epoch [19/40], Step [100/625], Loss: 0.2923\n",
      "Epoch [19/40], Step [200/625], Loss: 0.2906\n",
      "Epoch [19/40], Step [300/625], Loss: 0.2740\n",
      "Epoch [19/40], Step [400/625], Loss: 0.3004\n",
      "Epoch [19/40], Step [500/625], Loss: 0.2965\n",
      "Epoch [19/40], Step [600/625], Loss: 0.2933\n",
      "Epoch [19/40], Validation Loss: 0.4787, Validation Accuracy: 84.56%\n",
      "Epoch [20/40], Step [100/625], Loss: 0.2635\n",
      "Epoch [20/40], Step [200/625], Loss: 0.2571\n",
      "Epoch [20/40], Step [300/625], Loss: 0.2611\n",
      "Epoch [20/40], Step [400/625], Loss: 0.2756\n",
      "Epoch [20/40], Step [500/625], Loss: 0.2637\n",
      "Epoch [20/40], Step [600/625], Loss: 0.2790\n",
      "Epoch [20/40], Validation Loss: 0.4823, Validation Accuracy: 84.30%\n",
      "Epoch [21/40], Step [100/625], Loss: 0.2443\n",
      "Epoch [21/40], Step [200/625], Loss: 0.2283\n",
      "Epoch [21/40], Step [300/625], Loss: 0.2339\n",
      "Epoch [21/40], Step [400/625], Loss: 0.2706\n",
      "Epoch [21/40], Step [500/625], Loss: 0.2498\n",
      "Epoch [21/40], Step [600/625], Loss: 0.2705\n",
      "Epoch [21/40], Validation Loss: 0.4666, Validation Accuracy: 84.98%\n",
      "Epoch [22/40], Step [100/625], Loss: 0.2160\n",
      "Epoch [22/40], Step [200/625], Loss: 0.2322\n",
      "Epoch [22/40], Step [300/625], Loss: 0.2283\n",
      "Epoch [22/40], Step [400/625], Loss: 0.2328\n",
      "Epoch [22/40], Step [500/625], Loss: 0.2364\n",
      "Epoch [22/40], Step [600/625], Loss: 0.2486\n",
      "Epoch [22/40], Validation Loss: 0.4455, Validation Accuracy: 85.80%\n",
      "Epoch [23/40], Step [100/625], Loss: 0.1820\n",
      "Epoch [23/40], Step [200/625], Loss: 0.2113\n",
      "Epoch [23/40], Step [300/625], Loss: 0.2001\n",
      "Epoch [23/40], Step [400/625], Loss: 0.2077\n",
      "Epoch [23/40], Step [500/625], Loss: 0.1847\n",
      "Epoch [23/40], Step [600/625], Loss: 0.2191\n",
      "Epoch [23/40], Validation Loss: 0.4749, Validation Accuracy: 85.89%\n",
      "Epoch [24/40], Step [100/625], Loss: 0.1837\n",
      "Epoch [24/40], Step [200/625], Loss: 0.1907\n",
      "Epoch [24/40], Step [300/625], Loss: 0.2013\n",
      "Epoch [24/40], Step [400/625], Loss: 0.1940\n",
      "Epoch [24/40], Step [500/625], Loss: 0.1955\n",
      "Epoch [24/40], Step [600/625], Loss: 0.2000\n",
      "Epoch [24/40], Validation Loss: 0.4582, Validation Accuracy: 86.50%\n",
      "Epoch [25/40], Step [100/625], Loss: 0.1672\n",
      "Epoch [25/40], Step [200/625], Loss: 0.1746\n",
      "Epoch [25/40], Step [300/625], Loss: 0.1799\n",
      "Epoch [25/40], Step [400/625], Loss: 0.1674\n",
      "Epoch [25/40], Step [500/625], Loss: 0.1799\n",
      "Epoch [25/40], Step [600/625], Loss: 0.1806\n",
      "Epoch [25/40], Validation Loss: 0.4611, Validation Accuracy: 86.59%\n",
      "Epoch [26/40], Step [100/625], Loss: 0.1700\n",
      "Epoch [26/40], Step [200/625], Loss: 0.1523\n",
      "Epoch [26/40], Step [300/625], Loss: 0.1639\n",
      "Epoch [26/40], Step [400/625], Loss: 0.1615\n",
      "Epoch [26/40], Step [500/625], Loss: 0.1482\n",
      "Epoch [26/40], Step [600/625], Loss: 0.1636\n",
      "Epoch [26/40], Validation Loss: 0.4513, Validation Accuracy: 86.97%\n",
      "Epoch [27/40], Step [100/625], Loss: 0.1319\n",
      "Epoch [27/40], Step [200/625], Loss: 0.1480\n",
      "Epoch [27/40], Step [300/625], Loss: 0.1384\n",
      "Epoch [27/40], Step [400/625], Loss: 0.1378\n",
      "Epoch [27/40], Step [500/625], Loss: 0.1403\n",
      "Epoch [27/40], Step [600/625], Loss: 0.1384\n",
      "Epoch [27/40], Validation Loss: 0.4940, Validation Accuracy: 86.47%\n",
      "Epoch [28/40], Step [100/625], Loss: 0.1207\n",
      "Epoch [28/40], Step [200/625], Loss: 0.1334\n",
      "Epoch [28/40], Step [300/625], Loss: 0.1353\n",
      "Epoch [28/40], Step [400/625], Loss: 0.1322\n",
      "Epoch [28/40], Step [500/625], Loss: 0.1318\n",
      "Epoch [28/40], Step [600/625], Loss: 0.1229\n",
      "Epoch [28/40], Validation Loss: 0.4650, Validation Accuracy: 87.07%\n",
      "Epoch [29/40], Step [100/625], Loss: 0.1184\n",
      "Epoch [29/40], Step [200/625], Loss: 0.1128\n",
      "Epoch [29/40], Step [300/625], Loss: 0.1184\n",
      "Epoch [29/40], Step [400/625], Loss: 0.1237\n",
      "Epoch [29/40], Step [500/625], Loss: 0.1249\n",
      "Epoch [29/40], Step [600/625], Loss: 0.1127\n",
      "Epoch [29/40], Validation Loss: 0.4654, Validation Accuracy: 87.47%\n",
      "Epoch [30/40], Step [100/625], Loss: 0.1048\n",
      "Epoch [30/40], Step [200/625], Loss: 0.1029\n",
      "Epoch [30/40], Step [300/625], Loss: 0.1084\n",
      "Epoch [30/40], Step [400/625], Loss: 0.1064\n",
      "Epoch [30/40], Step [500/625], Loss: 0.1028\n",
      "Epoch [30/40], Step [600/625], Loss: 0.1059\n",
      "Epoch [30/40], Validation Loss: 0.4889, Validation Accuracy: 87.00%\n",
      "Epoch [31/40], Step [100/625], Loss: 0.0890\n",
      "Epoch [31/40], Step [200/625], Loss: 0.0872\n",
      "Epoch [31/40], Step [300/625], Loss: 0.0957\n",
      "Epoch [31/40], Step [400/625], Loss: 0.0933\n",
      "Epoch [31/40], Step [500/625], Loss: 0.0885\n",
      "Epoch [31/40], Step [600/625], Loss: 0.0992\n",
      "Epoch [31/40], Validation Loss: 0.4823, Validation Accuracy: 87.79%\n",
      "Epoch [32/40], Step [100/625], Loss: 0.0907\n",
      "Epoch [32/40], Step [200/625], Loss: 0.0880\n",
      "Epoch [32/40], Step [300/625], Loss: 0.0847\n",
      "Epoch [32/40], Step [400/625], Loss: 0.0997\n",
      "Epoch [32/40], Step [500/625], Loss: 0.0759\n",
      "Epoch [32/40], Step [600/625], Loss: 0.0916\n",
      "Epoch [32/40], Validation Loss: 0.4719, Validation Accuracy: 87.81%\n",
      "Epoch [33/40], Step [100/625], Loss: 0.0739\n",
      "Epoch [33/40], Step [200/625], Loss: 0.0788\n",
      "Epoch [33/40], Step [300/625], Loss: 0.0731\n",
      "Epoch [33/40], Step [400/625], Loss: 0.0743\n",
      "Epoch [33/40], Step [500/625], Loss: 0.0818\n",
      "Epoch [33/40], Step [600/625], Loss: 0.0792\n",
      "Epoch [33/40], Validation Loss: 0.4796, Validation Accuracy: 87.98%\n",
      "Epoch [34/40], Step [100/625], Loss: 0.0713\n",
      "Epoch [34/40], Step [200/625], Loss: 0.0718\n",
      "Epoch [34/40], Step [300/625], Loss: 0.0771\n",
      "Epoch [34/40], Step [400/625], Loss: 0.0749\n",
      "Epoch [34/40], Step [500/625], Loss: 0.0713\n",
      "Epoch [34/40], Step [600/625], Loss: 0.0699\n",
      "Epoch [34/40], Validation Loss: 0.4883, Validation Accuracy: 87.83%\n",
      "Epoch [35/40], Step [100/625], Loss: 0.0565\n",
      "Epoch [35/40], Step [200/625], Loss: 0.0676\n",
      "Epoch [35/40], Step [300/625], Loss: 0.0648\n",
      "Epoch [35/40], Step [400/625], Loss: 0.0664\n",
      "Epoch [35/40], Step [500/625], Loss: 0.0747\n",
      "Epoch [35/40], Step [600/625], Loss: 0.0730\n",
      "Epoch [35/40], Validation Loss: 0.5015, Validation Accuracy: 87.65%\n",
      "Epoch [36/40], Step [100/625], Loss: 0.0573\n",
      "Epoch [36/40], Step [200/625], Loss: 0.0664\n",
      "Epoch [36/40], Step [300/625], Loss: 0.0616\n",
      "Epoch [36/40], Step [400/625], Loss: 0.0565\n",
      "Epoch [36/40], Step [500/625], Loss: 0.0618\n",
      "Epoch [36/40], Step [600/625], Loss: 0.0497\n",
      "Epoch [36/40], Validation Loss: 0.5042, Validation Accuracy: 87.92%\n",
      "Epoch [37/40], Step [100/625], Loss: 0.0670\n",
      "Epoch [37/40], Step [200/625], Loss: 0.0572\n",
      "Epoch [37/40], Step [300/625], Loss: 0.0501\n",
      "Epoch [37/40], Step [400/625], Loss: 0.0499\n",
      "Epoch [37/40], Step [500/625], Loss: 0.0520\n",
      "Epoch [37/40], Step [600/625], Loss: 0.0530\n",
      "Epoch [37/40], Validation Loss: 0.5003, Validation Accuracy: 88.11%\n",
      "Epoch [38/40], Step [100/625], Loss: 0.0413\n",
      "Epoch [38/40], Step [200/625], Loss: 0.0609\n",
      "Epoch [38/40], Step [300/625], Loss: 0.0653\n",
      "Epoch [38/40], Step [400/625], Loss: 0.0548\n",
      "Epoch [38/40], Step [500/625], Loss: 0.0605\n",
      "Epoch [38/40], Step [600/625], Loss: 0.0563\n",
      "Epoch [38/40], Validation Loss: 0.4939, Validation Accuracy: 88.39%\n",
      "Epoch [39/40], Step [100/625], Loss: 0.0474\n",
      "Epoch [39/40], Step [200/625], Loss: 0.0528\n",
      "Epoch [39/40], Step [300/625], Loss: 0.0562\n",
      "Epoch [39/40], Step [400/625], Loss: 0.0500\n",
      "Epoch [39/40], Step [500/625], Loss: 0.0536\n",
      "Epoch [39/40], Step [600/625], Loss: 0.0455\n",
      "Epoch [39/40], Validation Loss: 0.5054, Validation Accuracy: 88.01%\n",
      "Epoch [40/40], Step [100/625], Loss: 0.0573\n",
      "Epoch [40/40], Step [200/625], Loss: 0.0572\n",
      "Epoch [40/40], Step [300/625], Loss: 0.0504\n",
      "Epoch [40/40], Step [400/625], Loss: 0.0546\n",
      "Epoch [40/40], Step [500/625], Loss: 0.0570\n",
      "Epoch [40/40], Step [600/625], Loss: 0.0520\n",
      "Epoch [40/40], Validation Loss: 0.5023, Validation Accuracy: 88.24%\n"
     ]
    }
   ],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_2)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"model_t2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.91%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Epoch [1/100], Step [100/625], Loss: 2.1860\n",
      "Epoch [1/100], Step [200/625], Loss: 2.0093\n",
      "Epoch [1/100], Step [300/625], Loss: 1.9389\n",
      "Epoch [1/100], Step [400/625], Loss: 1.9202\n",
      "Epoch [1/100], Step [500/625], Loss: 1.8860\n",
      "Epoch [1/100], Step [600/625], Loss: 1.8605\n",
      "Epoch [1/100], Validation Loss: 1.9942, Validation Accuracy: 27.16%\n",
      "Epoch [2/100], Step [100/625], Loss: 1.9567\n",
      "Epoch [2/100], Step [200/625], Loss: 1.8770\n",
      "Epoch [2/100], Step [300/625], Loss: 1.8985\n",
      "Epoch [2/100], Step [400/625], Loss: 1.8642\n",
      "Epoch [2/100], Step [500/625], Loss: 1.8313\n",
      "Epoch [2/100], Step [600/625], Loss: 1.7995\n",
      "Epoch [2/100], Validation Loss: 1.8582, Validation Accuracy: 22.86%\n",
      "Epoch [3/100], Step [100/625], Loss: 1.8098\n",
      "Epoch [3/100], Step [200/625], Loss: 1.7725\n",
      "Epoch [3/100], Step [300/625], Loss: 1.7149\n",
      "Epoch [3/100], Step [400/625], Loss: 1.6572\n",
      "Epoch [3/100], Step [500/625], Loss: 1.6283\n",
      "Epoch [3/100], Step [600/625], Loss: 1.5925\n",
      "Epoch [3/100], Validation Loss: 1.5274, Validation Accuracy: 38.89%\n",
      "Epoch [4/100], Step [100/625], Loss: 1.4961\n",
      "Epoch [4/100], Step [200/625], Loss: 1.4948\n",
      "Epoch [4/100], Step [300/625], Loss: 1.4842\n",
      "Epoch [4/100], Step [400/625], Loss: 1.4267\n",
      "Epoch [4/100], Step [500/625], Loss: 1.4229\n",
      "Epoch [4/100], Step [600/625], Loss: 1.3857\n",
      "Epoch [4/100], Validation Loss: 1.3722, Validation Accuracy: 49.70%\n",
      "Epoch [5/100], Step [100/625], Loss: 1.3309\n",
      "Epoch [5/100], Step [200/625], Loss: 1.2699\n",
      "Epoch [5/100], Step [300/625], Loss: 1.2557\n",
      "Epoch [5/100], Step [400/625], Loss: 1.2507\n",
      "Epoch [5/100], Step [500/625], Loss: 1.2178\n",
      "Epoch [5/100], Step [600/625], Loss: 1.1971\n",
      "Epoch [5/100], Validation Loss: 1.1475, Validation Accuracy: 58.49%\n",
      "Epoch [6/100], Step [100/625], Loss: 1.1760\n",
      "Epoch [6/100], Step [200/625], Loss: 1.0936\n",
      "Epoch [6/100], Step [300/625], Loss: 1.0844\n",
      "Epoch [6/100], Step [400/625], Loss: 1.0137\n",
      "Epoch [6/100], Step [500/625], Loss: 1.0835\n",
      "Epoch [6/100], Step [600/625], Loss: 1.0224\n",
      "Epoch [6/100], Validation Loss: 1.0195, Validation Accuracy: 64.61%\n",
      "Epoch [7/100], Step [100/625], Loss: 0.9873\n",
      "Epoch [7/100], Step [200/625], Loss: 0.9856\n",
      "Epoch [7/100], Step [300/625], Loss: 0.9705\n",
      "Epoch [7/100], Step [400/625], Loss: 0.9469\n",
      "Epoch [7/100], Step [500/625], Loss: 0.9144\n",
      "Epoch [7/100], Step [600/625], Loss: 0.9033\n",
      "Epoch [7/100], Validation Loss: 0.9547, Validation Accuracy: 66.79%\n",
      "Epoch [8/100], Step [100/625], Loss: 0.8741\n",
      "Epoch [8/100], Step [200/625], Loss: 0.8959\n",
      "Epoch [8/100], Step [300/625], Loss: 0.8208\n",
      "Epoch [8/100], Step [400/625], Loss: 0.8608\n",
      "Epoch [8/100], Step [500/625], Loss: 0.8515\n",
      "Epoch [8/100], Step [600/625], Loss: 0.8341\n",
      "Epoch [8/100], Validation Loss: 0.8755, Validation Accuracy: 69.80%\n",
      "Epoch [9/100], Step [100/625], Loss: 0.8184\n",
      "Epoch [9/100], Step [200/625], Loss: 0.8043\n",
      "Epoch [9/100], Step [300/625], Loss: 0.7792\n",
      "Epoch [9/100], Step [400/625], Loss: 0.7851\n",
      "Epoch [9/100], Step [500/625], Loss: 0.7493\n",
      "Epoch [9/100], Step [600/625], Loss: 0.7712\n",
      "Epoch [9/100], Validation Loss: 0.7766, Validation Accuracy: 73.97%\n",
      "Epoch [10/100], Step [100/625], Loss: 0.7342\n",
      "Epoch [10/100], Step [200/625], Loss: 0.7184\n",
      "Epoch [10/100], Step [300/625], Loss: 0.7212\n",
      "Epoch [10/100], Step [400/625], Loss: 0.7262\n",
      "Epoch [10/100], Step [500/625], Loss: 0.6965\n",
      "Epoch [10/100], Step [600/625], Loss: 0.7002\n",
      "Epoch [10/100], Validation Loss: 0.7164, Validation Accuracy: 76.72%\n",
      "Epoch [11/100], Step [100/625], Loss: 0.6564\n",
      "Epoch [11/100], Step [200/625], Loss: 0.6409\n",
      "Epoch [11/100], Step [300/625], Loss: 0.6619\n",
      "Epoch [11/100], Step [400/625], Loss: 0.6824\n",
      "Epoch [11/100], Step [500/625], Loss: 0.6631\n",
      "Epoch [11/100], Step [600/625], Loss: 0.6819\n",
      "Epoch [11/100], Validation Loss: 0.7124, Validation Accuracy: 77.15%\n",
      "Epoch [12/100], Step [100/625], Loss: 0.6312\n",
      "Epoch [12/100], Step [200/625], Loss: 0.6490\n",
      "Epoch [12/100], Step [300/625], Loss: 0.6104\n",
      "Epoch [12/100], Step [400/625], Loss: 0.6068\n",
      "Epoch [12/100], Step [500/625], Loss: 0.6087\n",
      "Epoch [12/100], Step [600/625], Loss: 0.6246\n",
      "Epoch [12/100], Validation Loss: 0.7058, Validation Accuracy: 78.23%\n",
      "Epoch [13/100], Step [100/625], Loss: 0.5786\n",
      "Epoch [13/100], Step [200/625], Loss: 0.5880\n",
      "Epoch [13/100], Step [300/625], Loss: 0.5645\n",
      "Epoch [13/100], Step [400/625], Loss: 0.5652\n",
      "Epoch [13/100], Step [500/625], Loss: 0.5853\n",
      "Epoch [13/100], Step [600/625], Loss: 0.5832\n",
      "Epoch [13/100], Validation Loss: 0.6734, Validation Accuracy: 77.92%\n",
      "Epoch [14/100], Step [100/625], Loss: 0.5444\n",
      "Epoch [14/100], Step [200/625], Loss: 0.5360\n",
      "Epoch [14/100], Step [300/625], Loss: 0.5368\n",
      "Epoch [14/100], Step [400/625], Loss: 0.5663\n",
      "Epoch [14/100], Step [500/625], Loss: 0.5454\n",
      "Epoch [14/100], Step [600/625], Loss: 0.5458\n",
      "Epoch [14/100], Validation Loss: 0.6487, Validation Accuracy: 79.25%\n",
      "Epoch [15/100], Step [100/625], Loss: 0.5054\n",
      "Epoch [15/100], Step [200/625], Loss: 0.5062\n",
      "Epoch [15/100], Step [300/625], Loss: 0.5410\n",
      "Epoch [15/100], Step [400/625], Loss: 0.5067\n",
      "Epoch [15/100], Step [500/625], Loss: 0.5321\n",
      "Epoch [15/100], Step [600/625], Loss: 0.5157\n",
      "Epoch [15/100], Validation Loss: 0.6253, Validation Accuracy: 79.99%\n",
      "Epoch [16/100], Step [100/625], Loss: 0.4830\n",
      "Epoch [16/100], Step [200/625], Loss: 0.4701\n",
      "Epoch [16/100], Step [300/625], Loss: 0.5038\n",
      "Epoch [16/100], Step [400/625], Loss: 0.4812\n",
      "Epoch [16/100], Step [500/625], Loss: 0.5002\n",
      "Epoch [16/100], Step [600/625], Loss: 0.4595\n",
      "Epoch [16/100], Validation Loss: 0.5703, Validation Accuracy: 81.80%\n",
      "Epoch [17/100], Step [100/625], Loss: 0.4509\n",
      "Epoch [17/100], Step [200/625], Loss: 0.4396\n",
      "Epoch [17/100], Step [300/625], Loss: 0.4563\n",
      "Epoch [17/100], Step [400/625], Loss: 0.4554\n",
      "Epoch [17/100], Step [500/625], Loss: 0.4499\n",
      "Epoch [17/100], Step [600/625], Loss: 0.4754\n",
      "Epoch [17/100], Validation Loss: 0.5645, Validation Accuracy: 82.21%\n",
      "Epoch [18/100], Step [100/625], Loss: 0.4475\n",
      "Epoch [18/100], Step [200/625], Loss: 0.4278\n",
      "Epoch [18/100], Step [300/625], Loss: 0.4618\n",
      "Epoch [18/100], Step [400/625], Loss: 0.4211\n",
      "Epoch [18/100], Step [500/625], Loss: 0.4518\n",
      "Epoch [18/100], Step [600/625], Loss: 0.4413\n",
      "Epoch [18/100], Validation Loss: 0.6024, Validation Accuracy: 81.24%\n",
      "Epoch [19/100], Step [100/625], Loss: 0.4196\n",
      "Epoch [19/100], Step [200/625], Loss: 0.4112\n",
      "Epoch [19/100], Step [300/625], Loss: 0.4157\n",
      "Epoch [19/100], Step [400/625], Loss: 0.4174\n",
      "Epoch [19/100], Step [500/625], Loss: 0.4352\n",
      "Epoch [19/100], Step [600/625], Loss: 0.4019\n",
      "Epoch [19/100], Validation Loss: 0.5553, Validation Accuracy: 82.92%\n",
      "Epoch [20/100], Step [100/625], Loss: 0.3883\n",
      "Epoch [20/100], Step [200/625], Loss: 0.3931\n",
      "Epoch [20/100], Step [300/625], Loss: 0.4100\n",
      "Epoch [20/100], Step [400/625], Loss: 0.3991\n",
      "Epoch [20/100], Step [500/625], Loss: 0.4069\n",
      "Epoch [20/100], Step [600/625], Loss: 0.3835\n",
      "Epoch [20/100], Validation Loss: 0.5713, Validation Accuracy: 82.58%\n",
      "Epoch [21/100], Step [100/625], Loss: 0.3510\n",
      "Epoch [21/100], Step [200/625], Loss: 0.3891\n",
      "Epoch [21/100], Step [300/625], Loss: 0.3844\n",
      "Epoch [21/100], Step [400/625], Loss: 0.3893\n",
      "Epoch [21/100], Step [500/625], Loss: 0.3993\n",
      "Epoch [21/100], Step [600/625], Loss: 0.3849\n",
      "Epoch [21/100], Validation Loss: 0.5268, Validation Accuracy: 83.92%\n",
      "Epoch [22/100], Step [100/625], Loss: 0.3386\n",
      "Epoch [22/100], Step [200/625], Loss: 0.3756\n",
      "Epoch [22/100], Step [300/625], Loss: 0.3480\n",
      "Epoch [22/100], Step [400/625], Loss: 0.3666\n",
      "Epoch [22/100], Step [500/625], Loss: 0.3632\n",
      "Epoch [22/100], Step [600/625], Loss: 0.3746\n",
      "Epoch [22/100], Validation Loss: 0.5435, Validation Accuracy: 83.20%\n",
      "Epoch [23/100], Step [100/625], Loss: 0.3234\n",
      "Epoch [23/100], Step [200/625], Loss: 0.3379\n",
      "Epoch [23/100], Step [300/625], Loss: 0.3775\n",
      "Epoch [23/100], Step [400/625], Loss: 0.3840\n",
      "Epoch [23/100], Step [500/625], Loss: 0.3751\n",
      "Epoch [23/100], Step [600/625], Loss: 0.3417\n",
      "Epoch [23/100], Validation Loss: 0.5606, Validation Accuracy: 83.56%\n",
      "Epoch [24/100], Step [100/625], Loss: 0.3211\n",
      "Epoch [24/100], Step [200/625], Loss: 0.3398\n",
      "Epoch [24/100], Step [300/625], Loss: 0.3161\n",
      "Epoch [24/100], Step [400/625], Loss: 0.3227\n",
      "Epoch [24/100], Step [500/625], Loss: 0.3297\n",
      "Epoch [24/100], Step [600/625], Loss: 0.3319\n",
      "Epoch [24/100], Validation Loss: 0.5333, Validation Accuracy: 84.86%\n",
      "Epoch [25/100], Step [100/625], Loss: 0.3050\n",
      "Epoch [25/100], Step [200/625], Loss: 0.3110\n",
      "Epoch [25/100], Step [300/625], Loss: 0.3131\n",
      "Epoch [25/100], Step [400/625], Loss: 0.3293\n",
      "Epoch [25/100], Step [500/625], Loss: 0.3290\n",
      "Epoch [25/100], Step [600/625], Loss: 0.3331\n",
      "Epoch [25/100], Validation Loss: 0.5063, Validation Accuracy: 84.74%\n",
      "Epoch [26/100], Step [100/625], Loss: 0.3033\n",
      "Epoch [26/100], Step [200/625], Loss: 0.3018\n",
      "Epoch [26/100], Step [300/625], Loss: 0.3071\n",
      "Epoch [26/100], Step [400/625], Loss: 0.3095\n",
      "Epoch [26/100], Step [500/625], Loss: 0.3061\n",
      "Epoch [26/100], Step [600/625], Loss: 0.3067\n",
      "Epoch [26/100], Validation Loss: 0.5231, Validation Accuracy: 84.49%\n",
      "Epoch [27/100], Step [100/625], Loss: 0.2600\n",
      "Epoch [27/100], Step [200/625], Loss: 0.2812\n",
      "Epoch [27/100], Step [300/625], Loss: 0.3070\n",
      "Epoch [27/100], Step [400/625], Loss: 0.2985\n",
      "Epoch [27/100], Step [500/625], Loss: 0.3067\n",
      "Epoch [27/100], Step [600/625], Loss: 0.2903\n",
      "Epoch [27/100], Validation Loss: 0.5368, Validation Accuracy: 84.57%\n",
      "Epoch [28/100], Step [100/625], Loss: 0.2642\n",
      "Epoch [28/100], Step [200/625], Loss: 0.2625\n",
      "Epoch [28/100], Step [300/625], Loss: 0.3055\n",
      "Epoch [28/100], Step [400/625], Loss: 0.2634\n",
      "Epoch [28/100], Step [500/625], Loss: 0.2896\n",
      "Epoch [28/100], Step [600/625], Loss: 0.2781\n",
      "Epoch [28/100], Validation Loss: 0.5686, Validation Accuracy: 83.68%\n",
      "Epoch [29/100], Step [100/625], Loss: 0.2554\n",
      "Epoch [29/100], Step [200/625], Loss: 0.2730\n",
      "Epoch [29/100], Step [300/625], Loss: 0.2657\n",
      "Epoch [29/100], Step [400/625], Loss: 0.2836\n",
      "Epoch [29/100], Step [500/625], Loss: 0.2693\n",
      "Epoch [29/100], Step [600/625], Loss: 0.2772\n",
      "Epoch [29/100], Validation Loss: 0.5466, Validation Accuracy: 84.09%\n",
      "Epoch [30/100], Step [100/625], Loss: 0.2438\n",
      "Epoch [30/100], Step [200/625], Loss: 0.2696\n",
      "Epoch [30/100], Step [300/625], Loss: 0.2422\n",
      "Epoch [30/100], Step [400/625], Loss: 0.2492\n",
      "Epoch [30/100], Step [500/625], Loss: 0.2772\n",
      "Epoch [30/100], Step [600/625], Loss: 0.3020\n",
      "Epoch [30/100], Validation Loss: 0.5148, Validation Accuracy: 84.80%\n",
      "Epoch [31/100], Step [100/625], Loss: 0.2353\n",
      "Epoch [31/100], Step [200/625], Loss: 0.2650\n",
      "Epoch [31/100], Step [300/625], Loss: 0.2724\n",
      "Epoch [31/100], Step [400/625], Loss: 0.2703\n",
      "Epoch [31/100], Step [500/625], Loss: 0.2588\n",
      "Epoch [31/100], Step [600/625], Loss: 0.2392\n",
      "Epoch [31/100], Validation Loss: 0.5947, Validation Accuracy: 83.51%\n",
      "Epoch [32/100], Step [100/625], Loss: 0.2159\n",
      "Epoch [32/100], Step [200/625], Loss: 0.2540\n",
      "Epoch [32/100], Step [300/625], Loss: 0.2439\n",
      "Epoch [32/100], Step [400/625], Loss: 0.2518\n",
      "Epoch [32/100], Step [500/625], Loss: 0.2459\n",
      "Epoch [32/100], Step [600/625], Loss: 0.2413\n",
      "Epoch [32/100], Validation Loss: 0.5352, Validation Accuracy: 85.29%\n",
      "Epoch [33/100], Step [100/625], Loss: 0.2083\n",
      "Epoch [33/100], Step [200/625], Loss: 0.2369\n",
      "Epoch [33/100], Step [300/625], Loss: 0.2510\n",
      "Epoch [33/100], Step [400/625], Loss: 0.2210\n",
      "Epoch [33/100], Step [500/625], Loss: 0.2403\n",
      "Epoch [33/100], Step [600/625], Loss: 0.2588\n",
      "Epoch [33/100], Validation Loss: 0.5130, Validation Accuracy: 85.38%\n",
      "Epoch [34/100], Step [100/625], Loss: 0.2208\n",
      "Epoch [34/100], Step [200/625], Loss: 0.2213\n",
      "Epoch [34/100], Step [300/625], Loss: 0.2163\n",
      "Epoch [34/100], Step [400/625], Loss: 0.2609\n",
      "Epoch [34/100], Step [500/625], Loss: 0.2068\n",
      "Epoch [34/100], Step [600/625], Loss: 0.2220\n",
      "Epoch [34/100], Validation Loss: 0.5181, Validation Accuracy: 85.17%\n",
      "Epoch [35/100], Step [100/625], Loss: 0.2170\n",
      "Epoch [35/100], Step [200/625], Loss: 0.2099\n",
      "Epoch [35/100], Step [300/625], Loss: 0.2119\n",
      "Epoch [35/100], Step [400/625], Loss: 0.2197\n",
      "Epoch [35/100], Step [500/625], Loss: 0.2160\n",
      "Epoch [35/100], Step [600/625], Loss: 0.2280\n",
      "Epoch [35/100], Validation Loss: 0.5159, Validation Accuracy: 85.52%\n",
      "Epoch [36/100], Step [100/625], Loss: 0.1923\n",
      "Epoch [36/100], Step [200/625], Loss: 0.1907\n",
      "Epoch [36/100], Step [300/625], Loss: 0.2086\n",
      "Epoch [36/100], Step [400/625], Loss: 0.2173\n",
      "Epoch [36/100], Step [500/625], Loss: 0.2063\n",
      "Epoch [36/100], Step [600/625], Loss: 0.2134\n",
      "Epoch [36/100], Validation Loss: 0.5306, Validation Accuracy: 85.01%\n",
      "Epoch [37/100], Step [100/625], Loss: 0.1667\n",
      "Epoch [37/100], Step [200/625], Loss: 0.1485\n",
      "Epoch [37/100], Step [300/625], Loss: 0.1283\n",
      "Epoch [37/100], Step [400/625], Loss: 0.1300\n",
      "Epoch [37/100], Step [500/625], Loss: 0.1297\n",
      "Epoch [37/100], Step [600/625], Loss: 0.1130\n",
      "Epoch [37/100], Validation Loss: 0.5161, Validation Accuracy: 87.21%\n",
      "Epoch [38/100], Step [100/625], Loss: 0.1077\n",
      "Epoch [38/100], Step [200/625], Loss: 0.1210\n",
      "Epoch [38/100], Step [300/625], Loss: 0.1069\n",
      "Epoch [38/100], Step [400/625], Loss: 0.1098\n",
      "Epoch [38/100], Step [500/625], Loss: 0.1044\n",
      "Epoch [38/100], Step [600/625], Loss: 0.1124\n",
      "Epoch [38/100], Validation Loss: 0.5111, Validation Accuracy: 87.07%\n",
      "Epoch [39/100], Step [100/625], Loss: 0.1140\n",
      "Epoch [39/100], Step [200/625], Loss: 0.1056\n",
      "Epoch [39/100], Step [300/625], Loss: 0.1052\n",
      "Epoch [39/100], Step [400/625], Loss: 0.1003\n",
      "Epoch [39/100], Step [500/625], Loss: 0.1031\n",
      "Epoch [39/100], Step [600/625], Loss: 0.0939\n",
      "Epoch [39/100], Validation Loss: 0.5247, Validation Accuracy: 86.91%\n",
      "Epoch [40/100], Step [100/625], Loss: 0.1004\n",
      "Epoch [40/100], Step [200/625], Loss: 0.0899\n",
      "Epoch [40/100], Step [300/625], Loss: 0.1002\n",
      "Epoch [40/100], Step [400/625], Loss: 0.1021\n",
      "Epoch [40/100], Step [500/625], Loss: 0.0946\n",
      "Epoch [40/100], Step [600/625], Loss: 0.0878\n",
      "Epoch [40/100], Validation Loss: 0.5262, Validation Accuracy: 87.35%\n",
      "Epoch [41/100], Step [100/625], Loss: 0.0994\n",
      "Epoch [41/100], Step [200/625], Loss: 0.0832\n",
      "Epoch [41/100], Step [300/625], Loss: 0.0971\n",
      "Epoch [41/100], Step [400/625], Loss: 0.0887\n",
      "Epoch [41/100], Step [500/625], Loss: 0.0968\n",
      "Epoch [41/100], Step [600/625], Loss: 0.0824\n",
      "Epoch [41/100], Validation Loss: 0.5323, Validation Accuracy: 87.75%\n",
      "Epoch [42/100], Step [100/625], Loss: 0.0832\n",
      "Epoch [42/100], Step [200/625], Loss: 0.0928\n",
      "Epoch [42/100], Step [300/625], Loss: 0.0854\n",
      "Epoch [42/100], Step [400/625], Loss: 0.0964\n",
      "Epoch [42/100], Step [500/625], Loss: 0.0880\n",
      "Epoch [42/100], Step [600/625], Loss: 0.0826\n",
      "Epoch [42/100], Validation Loss: 0.5132, Validation Accuracy: 87.65%\n",
      "Epoch [43/100], Step [100/625], Loss: 0.0850\n",
      "Epoch [43/100], Step [200/625], Loss: 0.0749\n",
      "Epoch [43/100], Step [300/625], Loss: 0.0860\n",
      "Epoch [43/100], Step [400/625], Loss: 0.0764\n",
      "Epoch [43/100], Step [500/625], Loss: 0.0763\n",
      "Epoch [43/100], Step [600/625], Loss: 0.0869\n",
      "Epoch [43/100], Validation Loss: 0.5282, Validation Accuracy: 87.44%\n",
      "Epoch [44/100], Step [100/625], Loss: 0.0839\n",
      "Epoch [44/100], Step [200/625], Loss: 0.0862\n",
      "Epoch [44/100], Step [300/625], Loss: 0.0797\n",
      "Epoch [44/100], Step [400/625], Loss: 0.0871\n",
      "Epoch [44/100], Step [500/625], Loss: 0.0741\n",
      "Epoch [44/100], Step [600/625], Loss: 0.0822\n",
      "Epoch [44/100], Validation Loss: 0.5253, Validation Accuracy: 87.63%\n",
      "Epoch [45/100], Step [100/625], Loss: 0.0713\n",
      "Epoch [45/100], Step [200/625], Loss: 0.0799\n",
      "Epoch [45/100], Step [300/625], Loss: 0.0795\n",
      "Epoch [45/100], Step [400/625], Loss: 0.0772\n",
      "Epoch [45/100], Step [500/625], Loss: 0.0753\n",
      "Epoch [45/100], Step [600/625], Loss: 0.0812\n",
      "Epoch [45/100], Validation Loss: 0.5394, Validation Accuracy: 87.94%\n",
      "Epoch [46/100], Step [100/625], Loss: 0.0723\n",
      "Epoch [46/100], Step [200/625], Loss: 0.0672\n",
      "Epoch [46/100], Step [300/625], Loss: 0.0685\n",
      "Epoch [46/100], Step [400/625], Loss: 0.0799\n",
      "Epoch [46/100], Step [500/625], Loss: 0.0796\n",
      "Epoch [46/100], Step [600/625], Loss: 0.0733\n",
      "Epoch [46/100], Validation Loss: 0.5374, Validation Accuracy: 87.40%\n",
      "Epoch [47/100], Step [100/625], Loss: 0.0672\n",
      "Epoch [47/100], Step [200/625], Loss: 0.0646\n",
      "Epoch [47/100], Step [300/625], Loss: 0.0718\n",
      "Epoch [47/100], Step [400/625], Loss: 0.0734\n",
      "Epoch [47/100], Step [500/625], Loss: 0.0757\n",
      "Epoch [47/100], Step [600/625], Loss: 0.0644\n",
      "Epoch [47/100], Validation Loss: 0.5637, Validation Accuracy: 87.66%\n",
      "Epoch [48/100], Step [100/625], Loss: 0.0622\n",
      "Epoch [48/100], Step [200/625], Loss: 0.0624\n",
      "Epoch [48/100], Step [300/625], Loss: 0.0595\n",
      "Epoch [48/100], Step [400/625], Loss: 0.0715\n",
      "Epoch [48/100], Step [500/625], Loss: 0.0637\n",
      "Epoch [48/100], Step [600/625], Loss: 0.0674\n",
      "Epoch [48/100], Validation Loss: 0.5476, Validation Accuracy: 87.75%\n",
      "Epoch [49/100], Step [100/625], Loss: 0.0606\n",
      "Epoch [49/100], Step [200/625], Loss: 0.0710\n",
      "Epoch [49/100], Step [300/625], Loss: 0.0679\n",
      "Epoch [49/100], Step [400/625], Loss: 0.0626\n",
      "Epoch [49/100], Step [500/625], Loss: 0.0712\n",
      "Epoch [49/100], Step [600/625], Loss: 0.0656\n",
      "Epoch [49/100], Validation Loss: 0.5575, Validation Accuracy: 88.00%\n",
      "Epoch [50/100], Step [100/625], Loss: 0.0631\n",
      "Epoch [50/100], Step [200/625], Loss: 0.0628\n",
      "Epoch [50/100], Step [300/625], Loss: 0.0567\n",
      "Epoch [50/100], Step [400/625], Loss: 0.0611\n",
      "Epoch [50/100], Step [500/625], Loss: 0.0649\n",
      "Epoch [50/100], Step [600/625], Loss: 0.0563\n",
      "Epoch [50/100], Validation Loss: 0.5423, Validation Accuracy: 88.10%\n",
      "Epoch [51/100], Step [100/625], Loss: 0.0629\n",
      "Epoch [51/100], Step [200/625], Loss: 0.0555\n",
      "Epoch [51/100], Step [300/625], Loss: 0.0638\n",
      "Epoch [51/100], Step [400/625], Loss: 0.0636\n",
      "Epoch [51/100], Step [500/625], Loss: 0.0635\n",
      "Epoch [51/100], Step [600/625], Loss: 0.0593\n",
      "Epoch [51/100], Validation Loss: 0.5637, Validation Accuracy: 87.87%\n",
      "Epoch [52/100], Step [100/625], Loss: 0.0627\n",
      "Epoch [52/100], Step [200/625], Loss: 0.0588\n",
      "Epoch [52/100], Step [300/625], Loss: 0.0591\n",
      "Epoch [52/100], Step [400/625], Loss: 0.0693\n",
      "Epoch [52/100], Step [500/625], Loss: 0.0623\n",
      "Epoch [52/100], Step [600/625], Loss: 0.0580\n",
      "Epoch [52/100], Validation Loss: 0.5704, Validation Accuracy: 88.02%\n",
      "Epoch [53/100], Step [100/625], Loss: 0.0572\n",
      "Epoch [53/100], Step [200/625], Loss: 0.0599\n",
      "Epoch [53/100], Step [300/625], Loss: 0.0672\n",
      "Epoch [53/100], Step [400/625], Loss: 0.0550\n",
      "Epoch [53/100], Step [500/625], Loss: 0.0666\n",
      "Epoch [53/100], Step [600/625], Loss: 0.0557\n",
      "Epoch [53/100], Validation Loss: 0.5532, Validation Accuracy: 87.90%\n",
      "Epoch [54/100], Step [100/625], Loss: 0.0647\n",
      "Epoch [54/100], Step [200/625], Loss: 0.0637\n",
      "Epoch [54/100], Step [300/625], Loss: 0.0589\n",
      "Epoch [54/100], Step [400/625], Loss: 0.0597\n",
      "Epoch [54/100], Step [500/625], Loss: 0.0655\n",
      "Epoch [54/100], Step [600/625], Loss: 0.0568\n",
      "Epoch [54/100], Validation Loss: 0.5499, Validation Accuracy: 88.24%\n",
      "Epoch [55/100], Step [100/625], Loss: 0.0644\n",
      "Epoch [55/100], Step [200/625], Loss: 0.0582\n",
      "Epoch [55/100], Step [300/625], Loss: 0.0618\n",
      "Epoch [55/100], Step [400/625], Loss: 0.0595\n",
      "Epoch [55/100], Step [500/625], Loss: 0.0716\n",
      "Epoch [55/100], Step [600/625], Loss: 0.0671\n",
      "Epoch [55/100], Validation Loss: 0.5647, Validation Accuracy: 87.81%\n",
      "Epoch [56/100], Step [100/625], Loss: 0.0598\n",
      "Epoch [56/100], Step [200/625], Loss: 0.0604\n",
      "Epoch [56/100], Step [300/625], Loss: 0.0630\n",
      "Epoch [56/100], Step [400/625], Loss: 0.0500\n",
      "Epoch [56/100], Step [500/625], Loss: 0.0633\n",
      "Epoch [56/100], Step [600/625], Loss: 0.0669\n",
      "Epoch [56/100], Validation Loss: 0.5814, Validation Accuracy: 87.54%\n",
      "Epoch [57/100], Step [100/625], Loss: 0.0559\n",
      "Epoch [57/100], Step [200/625], Loss: 0.0631\n",
      "Epoch [57/100], Step [300/625], Loss: 0.0556\n",
      "Epoch [57/100], Step [400/625], Loss: 0.0582\n",
      "Epoch [57/100], Step [500/625], Loss: 0.0580\n",
      "Epoch [57/100], Step [600/625], Loss: 0.0654\n",
      "Epoch [57/100], Validation Loss: 0.5492, Validation Accuracy: 88.15%\n",
      "Epoch [58/100], Step [100/625], Loss: 0.0614\n",
      "Epoch [58/100], Step [200/625], Loss: 0.0580\n",
      "Epoch [58/100], Step [300/625], Loss: 0.0666\n",
      "Epoch [58/100], Step [400/625], Loss: 0.0536\n",
      "Epoch [58/100], Step [500/625], Loss: 0.0551\n",
      "Epoch [58/100], Step [600/625], Loss: 0.0563\n",
      "Epoch [58/100], Validation Loss: 0.5586, Validation Accuracy: 87.97%\n",
      "Epoch [59/100], Step [100/625], Loss: 0.0527\n",
      "Epoch [59/100], Step [200/625], Loss: 0.0548\n",
      "Epoch [59/100], Step [300/625], Loss: 0.0645\n",
      "Epoch [59/100], Step [400/625], Loss: 0.0565\n",
      "Epoch [59/100], Step [500/625], Loss: 0.0669\n",
      "Epoch [59/100], Step [600/625], Loss: 0.0545\n",
      "Epoch [59/100], Validation Loss: 0.5704, Validation Accuracy: 87.28%\n",
      "Epoch [60/100], Step [100/625], Loss: 0.0585\n",
      "Epoch [60/100], Step [200/625], Loss: 0.0600\n",
      "Epoch [60/100], Step [300/625], Loss: 0.0653\n",
      "Epoch [60/100], Step [400/625], Loss: 0.0658\n",
      "Epoch [60/100], Step [500/625], Loss: 0.0605\n",
      "Epoch [60/100], Step [600/625], Loss: 0.0612\n",
      "Epoch [60/100], Validation Loss: 0.5599, Validation Accuracy: 87.97%\n",
      "Epoch [61/100], Step [100/625], Loss: 0.0640\n",
      "Epoch [61/100], Step [200/625], Loss: 0.0607\n",
      "Epoch [61/100], Step [300/625], Loss: 0.0673\n",
      "Epoch [61/100], Step [400/625], Loss: 0.0590\n",
      "Epoch [61/100], Step [500/625], Loss: 0.0545\n",
      "Epoch [61/100], Step [600/625], Loss: 0.0576\n",
      "Epoch [61/100], Validation Loss: 0.5942, Validation Accuracy: 87.86%\n",
      "Epoch [62/100], Step [100/625], Loss: 0.0644\n",
      "Epoch [62/100], Step [200/625], Loss: 0.0530\n",
      "Epoch [62/100], Step [300/625], Loss: 0.0601\n",
      "Epoch [62/100], Step [400/625], Loss: 0.0569\n",
      "Epoch [62/100], Step [500/625], Loss: 0.0626\n",
      "Epoch [62/100], Step [600/625], Loss: 0.0587\n",
      "Epoch [62/100], Validation Loss: 0.5624, Validation Accuracy: 87.83%\n",
      "Epoch [63/100], Step [100/625], Loss: 0.0558\n",
      "Epoch [63/100], Step [200/625], Loss: 0.0626\n",
      "Epoch [63/100], Step [300/625], Loss: 0.0574\n",
      "Epoch [63/100], Step [400/625], Loss: 0.0635\n",
      "Epoch [63/100], Step [500/625], Loss: 0.0631\n",
      "Epoch [63/100], Step [600/625], Loss: 0.0593\n",
      "Epoch [63/100], Validation Loss: 0.5636, Validation Accuracy: 87.91%\n",
      "Epoch [64/100], Step [100/625], Loss: 0.0578\n",
      "Epoch [64/100], Step [200/625], Loss: 0.0591\n",
      "Epoch [64/100], Step [300/625], Loss: 0.0477\n",
      "Epoch [64/100], Step [400/625], Loss: 0.0664\n",
      "Epoch [64/100], Step [500/625], Loss: 0.0668\n",
      "Epoch [64/100], Step [600/625], Loss: 0.0539\n",
      "Epoch [64/100], Validation Loss: 0.5758, Validation Accuracy: 87.52%\n",
      "Epoch [65/100], Step [100/625], Loss: 0.0629\n",
      "Epoch [65/100], Step [200/625], Loss: 0.0584\n",
      "Epoch [65/100], Step [300/625], Loss: 0.0589\n",
      "Epoch [65/100], Step [400/625], Loss: 0.0560\n",
      "Epoch [65/100], Step [500/625], Loss: 0.0567\n",
      "Epoch [65/100], Step [600/625], Loss: 0.0588\n",
      "Epoch [65/100], Validation Loss: 0.5779, Validation Accuracy: 87.63%\n",
      "Epoch [66/100], Step [100/625], Loss: 0.0572\n",
      "Epoch [66/100], Step [200/625], Loss: 0.0554\n",
      "Epoch [66/100], Step [300/625], Loss: 0.0637\n",
      "Epoch [66/100], Step [400/625], Loss: 0.0637\n",
      "Epoch [66/100], Step [500/625], Loss: 0.0614\n",
      "Epoch [66/100], Step [600/625], Loss: 0.0573\n",
      "Epoch [66/100], Validation Loss: 0.5727, Validation Accuracy: 87.89%\n",
      "Epoch [67/100], Step [100/625], Loss: 0.0576\n",
      "Epoch [67/100], Step [200/625], Loss: 0.0554\n",
      "Epoch [67/100], Step [300/625], Loss: 0.0571\n",
      "Epoch [67/100], Step [400/625], Loss: 0.0597\n",
      "Epoch [67/100], Step [500/625], Loss: 0.0536\n",
      "Epoch [67/100], Step [600/625], Loss: 0.0516\n",
      "Epoch [67/100], Validation Loss: 0.5504, Validation Accuracy: 88.18%\n",
      "Epoch [68/100], Step [100/625], Loss: 0.0601\n",
      "Epoch [68/100], Step [200/625], Loss: 0.0594\n",
      "Epoch [68/100], Step [300/625], Loss: 0.0538\n",
      "Epoch [68/100], Step [400/625], Loss: 0.0564\n",
      "Epoch [68/100], Step [500/625], Loss: 0.0502\n",
      "Epoch [68/100], Step [600/625], Loss: 0.0576\n",
      "Epoch [68/100], Validation Loss: 0.5751, Validation Accuracy: 87.62%\n",
      "Epoch [69/100], Step [100/625], Loss: 0.0543\n",
      "Epoch [69/100], Step [200/625], Loss: 0.0607\n",
      "Epoch [69/100], Step [300/625], Loss: 0.0582\n",
      "Epoch [69/100], Step [400/625], Loss: 0.0579\n",
      "Epoch [69/100], Step [500/625], Loss: 0.0576\n",
      "Epoch [69/100], Step [600/625], Loss: 0.0586\n",
      "Epoch [69/100], Validation Loss: 0.5502, Validation Accuracy: 88.15%\n",
      "Epoch [70/100], Step [100/625], Loss: 0.0625\n",
      "Epoch [70/100], Step [200/625], Loss: 0.0537\n",
      "Epoch [70/100], Step [300/625], Loss: 0.0522\n",
      "Epoch [70/100], Step [400/625], Loss: 0.0516\n",
      "Epoch [70/100], Step [500/625], Loss: 0.0582\n",
      "Epoch [70/100], Step [600/625], Loss: 0.0641\n",
      "Epoch [70/100], Validation Loss: 0.5641, Validation Accuracy: 87.87%\n",
      "Epoch [71/100], Step [100/625], Loss: 0.0562\n",
      "Epoch [71/100], Step [200/625], Loss: 0.0604\n",
      "Epoch [71/100], Step [300/625], Loss: 0.0587\n",
      "Epoch [71/100], Step [400/625], Loss: 0.0564\n",
      "Epoch [71/100], Step [500/625], Loss: 0.0561\n",
      "Epoch [71/100], Step [600/625], Loss: 0.0637\n",
      "Epoch [71/100], Validation Loss: 0.5768, Validation Accuracy: 87.67%\n",
      "Epoch [72/100], Step [100/625], Loss: 0.0563\n",
      "Epoch [72/100], Step [200/625], Loss: 0.0626\n",
      "Epoch [72/100], Step [300/625], Loss: 0.0560\n",
      "Epoch [72/100], Step [400/625], Loss: 0.0567\n",
      "Epoch [72/100], Step [500/625], Loss: 0.0575\n",
      "Epoch [72/100], Step [600/625], Loss: 0.0618\n",
      "Epoch [72/100], Validation Loss: 0.5637, Validation Accuracy: 88.01%\n",
      "Epoch [73/100], Step [100/625], Loss: 0.0610\n",
      "Epoch [73/100], Step [200/625], Loss: 0.0630\n",
      "Epoch [73/100], Step [300/625], Loss: 0.0553\n",
      "Epoch [73/100], Step [400/625], Loss: 0.0539\n",
      "Epoch [73/100], Step [500/625], Loss: 0.0634\n",
      "Epoch [73/100], Step [600/625], Loss: 0.0607\n",
      "Epoch [73/100], Validation Loss: 0.5520, Validation Accuracy: 88.03%\n",
      "Epoch [74/100], Step [100/625], Loss: 0.0553\n",
      "Epoch [74/100], Step [200/625], Loss: 0.0669\n",
      "Epoch [74/100], Step [300/625], Loss: 0.0612\n",
      "Epoch [74/100], Step [400/625], Loss: 0.0542\n",
      "Epoch [74/100], Step [500/625], Loss: 0.0662\n",
      "Epoch [74/100], Step [600/625], Loss: 0.0570\n",
      "Epoch [74/100], Validation Loss: 0.5598, Validation Accuracy: 88.00%\n",
      "Epoch [75/100], Step [100/625], Loss: 0.0580\n",
      "Epoch [75/100], Step [200/625], Loss: 0.0585\n",
      "Epoch [75/100], Step [300/625], Loss: 0.0605\n",
      "Epoch [75/100], Step [400/625], Loss: 0.0570\n",
      "Epoch [75/100], Step [500/625], Loss: 0.0634\n",
      "Epoch [75/100], Step [600/625], Loss: 0.0565\n",
      "Epoch [75/100], Validation Loss: 0.5659, Validation Accuracy: 87.76%\n",
      "Epoch [76/100], Step [100/625], Loss: 0.0577\n",
      "Epoch [76/100], Step [200/625], Loss: 0.0492\n",
      "Epoch [76/100], Step [300/625], Loss: 0.0630\n",
      "Epoch [76/100], Step [400/625], Loss: 0.0559\n",
      "Epoch [76/100], Step [500/625], Loss: 0.0615\n",
      "Epoch [76/100], Step [600/625], Loss: 0.0505\n",
      "Epoch [76/100], Validation Loss: 0.5821, Validation Accuracy: 87.89%\n",
      "Epoch [77/100], Step [100/625], Loss: 0.0607\n",
      "Epoch [77/100], Step [200/625], Loss: 0.0578\n",
      "Epoch [77/100], Step [300/625], Loss: 0.0519\n",
      "Epoch [77/100], Step [400/625], Loss: 0.0534\n",
      "Epoch [77/100], Step [500/625], Loss: 0.0583\n",
      "Epoch [77/100], Step [600/625], Loss: 0.0649\n",
      "Epoch [77/100], Validation Loss: 0.5812, Validation Accuracy: 88.12%\n",
      "Epoch [78/100], Step [100/625], Loss: 0.0530\n",
      "Epoch [78/100], Step [200/625], Loss: 0.0634\n",
      "Epoch [78/100], Step [300/625], Loss: 0.0608\n",
      "Epoch [78/100], Step [400/625], Loss: 0.0553\n",
      "Epoch [78/100], Step [500/625], Loss: 0.0633\n",
      "Epoch [78/100], Step [600/625], Loss: 0.0608\n",
      "Epoch [78/100], Validation Loss: 0.5608, Validation Accuracy: 88.05%\n",
      "Epoch [79/100], Step [100/625], Loss: 0.0637\n",
      "Epoch [79/100], Step [200/625], Loss: 0.0526\n",
      "Epoch [79/100], Step [300/625], Loss: 0.0551\n",
      "Epoch [79/100], Step [400/625], Loss: 0.0583\n",
      "Epoch [79/100], Step [500/625], Loss: 0.0611\n",
      "Epoch [79/100], Step [600/625], Loss: 0.0537\n",
      "Epoch [79/100], Validation Loss: 0.5723, Validation Accuracy: 88.07%\n",
      "Epoch [80/100], Step [100/625], Loss: 0.0605\n",
      "Epoch [80/100], Step [200/625], Loss: 0.0541\n",
      "Epoch [80/100], Step [300/625], Loss: 0.0705\n",
      "Epoch [80/100], Step [400/625], Loss: 0.0543\n",
      "Epoch [80/100], Step [500/625], Loss: 0.0679\n",
      "Epoch [80/100], Step [600/625], Loss: 0.0468\n",
      "Epoch [80/100], Validation Loss: 0.5633, Validation Accuracy: 87.90%\n",
      "Epoch [81/100], Step [100/625], Loss: 0.0553\n",
      "Epoch [81/100], Step [200/625], Loss: 0.0549\n",
      "Epoch [81/100], Step [300/625], Loss: 0.0589\n",
      "Epoch [81/100], Step [400/625], Loss: 0.0544\n",
      "Epoch [81/100], Step [500/625], Loss: 0.0626\n",
      "Epoch [81/100], Step [600/625], Loss: 0.0528\n",
      "Epoch [81/100], Validation Loss: 0.5636, Validation Accuracy: 88.01%\n",
      "Epoch [82/100], Step [100/625], Loss: 0.0593\n",
      "Epoch [82/100], Step [200/625], Loss: 0.0587\n",
      "Epoch [82/100], Step [300/625], Loss: 0.0579\n",
      "Epoch [82/100], Step [400/625], Loss: 0.0580\n",
      "Epoch [82/100], Step [500/625], Loss: 0.0478\n",
      "Epoch [82/100], Step [600/625], Loss: 0.0559\n",
      "Epoch [82/100], Validation Loss: 0.5726, Validation Accuracy: 87.68%\n",
      "Epoch [83/100], Step [100/625], Loss: 0.0578\n",
      "Epoch [83/100], Step [200/625], Loss: 0.0546\n",
      "Epoch [83/100], Step [300/625], Loss: 0.0552\n",
      "Epoch [83/100], Step [400/625], Loss: 0.0532\n",
      "Epoch [83/100], Step [500/625], Loss: 0.0612\n",
      "Epoch [83/100], Step [600/625], Loss: 0.0611\n",
      "Epoch [83/100], Validation Loss: 0.5436, Validation Accuracy: 88.44%\n",
      "Epoch [84/100], Step [100/625], Loss: 0.0545\n",
      "Epoch [84/100], Step [200/625], Loss: 0.0596\n",
      "Epoch [84/100], Step [300/625], Loss: 0.0651\n",
      "Epoch [84/100], Step [400/625], Loss: 0.0583\n",
      "Epoch [84/100], Step [500/625], Loss: 0.0529\n",
      "Epoch [84/100], Step [600/625], Loss: 0.0528\n",
      "Epoch [84/100], Validation Loss: 0.5553, Validation Accuracy: 87.84%\n",
      "Epoch [85/100], Step [100/625], Loss: 0.0631\n",
      "Epoch [85/100], Step [200/625], Loss: 0.0559\n",
      "Epoch [85/100], Step [300/625], Loss: 0.0568\n",
      "Epoch [85/100], Step [400/625], Loss: 0.0641\n",
      "Epoch [85/100], Step [500/625], Loss: 0.0587\n",
      "Epoch [85/100], Step [600/625], Loss: 0.0490\n",
      "Epoch [85/100], Validation Loss: 0.5988, Validation Accuracy: 87.80%\n",
      "Epoch [86/100], Step [100/625], Loss: 0.0588\n",
      "Epoch [86/100], Step [200/625], Loss: 0.0482\n",
      "Epoch [86/100], Step [300/625], Loss: 0.0635\n",
      "Epoch [86/100], Step [400/625], Loss: 0.0559\n",
      "Epoch [86/100], Step [500/625], Loss: 0.0600\n",
      "Epoch [86/100], Step [600/625], Loss: 0.0511\n",
      "Epoch [86/100], Validation Loss: 0.5417, Validation Accuracy: 88.50%\n",
      "Epoch [87/100], Step [100/625], Loss: 0.0572\n",
      "Epoch [87/100], Step [200/625], Loss: 0.0588\n",
      "Epoch [87/100], Step [300/625], Loss: 0.0518\n",
      "Epoch [87/100], Step [400/625], Loss: 0.0576\n",
      "Epoch [87/100], Step [500/625], Loss: 0.0563\n",
      "Epoch [87/100], Step [600/625], Loss: 0.0576\n",
      "Epoch [87/100], Validation Loss: 0.5855, Validation Accuracy: 87.64%\n",
      "Epoch [88/100], Step [100/625], Loss: 0.0577\n",
      "Epoch [88/100], Step [200/625], Loss: 0.0649\n",
      "Epoch [88/100], Step [300/625], Loss: 0.0566\n",
      "Epoch [88/100], Step [400/625], Loss: 0.0600\n",
      "Epoch [88/100], Step [500/625], Loss: 0.0580\n",
      "Epoch [88/100], Step [600/625], Loss: 0.0582\n",
      "Epoch [88/100], Validation Loss: 0.5808, Validation Accuracy: 87.64%\n",
      "Epoch [89/100], Step [100/625], Loss: 0.0541\n",
      "Epoch [89/100], Step [200/625], Loss: 0.0593\n",
      "Epoch [89/100], Step [300/625], Loss: 0.0642\n",
      "Epoch [89/100], Step [400/625], Loss: 0.0609\n",
      "Epoch [89/100], Step [500/625], Loss: 0.0559\n",
      "Epoch [89/100], Step [600/625], Loss: 0.0585\n",
      "Epoch [89/100], Validation Loss: 0.5689, Validation Accuracy: 87.92%\n",
      "Epoch [90/100], Step [100/625], Loss: 0.0619\n",
      "Epoch [90/100], Step [200/625], Loss: 0.0557\n",
      "Epoch [90/100], Step [300/625], Loss: 0.0574\n",
      "Epoch [90/100], Step [400/625], Loss: 0.0598\n",
      "Epoch [90/100], Step [500/625], Loss: 0.0623\n",
      "Epoch [90/100], Step [600/625], Loss: 0.0547\n",
      "Epoch [90/100], Validation Loss: 0.5786, Validation Accuracy: 88.03%\n",
      "Epoch [91/100], Step [100/625], Loss: 0.0613\n",
      "Epoch [91/100], Step [200/625], Loss: 0.0568\n",
      "Epoch [91/100], Step [300/625], Loss: 0.0601\n",
      "Epoch [91/100], Step [400/625], Loss: 0.0623\n",
      "Epoch [91/100], Step [500/625], Loss: 0.0608\n",
      "Epoch [91/100], Step [600/625], Loss: 0.0530\n",
      "Epoch [91/100], Validation Loss: 0.5821, Validation Accuracy: 87.79%\n",
      "Epoch [92/100], Step [100/625], Loss: 0.0503\n",
      "Epoch [92/100], Step [200/625], Loss: 0.0540\n",
      "Epoch [92/100], Step [300/625], Loss: 0.0624\n",
      "Epoch [92/100], Step [400/625], Loss: 0.0596\n",
      "Epoch [92/100], Step [500/625], Loss: 0.0597\n",
      "Epoch [92/100], Step [600/625], Loss: 0.0598\n",
      "Epoch [92/100], Validation Loss: 0.5532, Validation Accuracy: 88.28%\n",
      "Epoch [93/100], Step [100/625], Loss: 0.0591\n",
      "Epoch [93/100], Step [200/625], Loss: 0.0635\n",
      "Epoch [93/100], Step [300/625], Loss: 0.0577\n",
      "Epoch [93/100], Step [400/625], Loss: 0.0576\n",
      "Epoch [93/100], Step [500/625], Loss: 0.0620\n",
      "Epoch [93/100], Step [600/625], Loss: 0.0552\n",
      "Epoch [93/100], Validation Loss: 0.5729, Validation Accuracy: 88.12%\n",
      "Epoch [94/100], Step [100/625], Loss: 0.0583\n",
      "Epoch [94/100], Step [200/625], Loss: 0.0538\n",
      "Epoch [94/100], Step [300/625], Loss: 0.0575\n",
      "Epoch [94/100], Step [400/625], Loss: 0.0530\n",
      "Epoch [94/100], Step [500/625], Loss: 0.0604\n",
      "Epoch [94/100], Step [600/625], Loss: 0.0575\n",
      "Epoch [94/100], Validation Loss: 0.5669, Validation Accuracy: 87.72%\n",
      "Epoch [95/100], Step [100/625], Loss: 0.0504\n",
      "Epoch [95/100], Step [200/625], Loss: 0.0599\n",
      "Epoch [95/100], Step [300/625], Loss: 0.0609\n",
      "Epoch [95/100], Step [400/625], Loss: 0.0606\n",
      "Epoch [95/100], Step [500/625], Loss: 0.0613\n",
      "Epoch [95/100], Step [600/625], Loss: 0.0500\n",
      "Epoch [95/100], Validation Loss: 0.5794, Validation Accuracy: 87.89%\n",
      "Epoch [96/100], Step [100/625], Loss: 0.0577\n",
      "Epoch [96/100], Step [200/625], Loss: 0.0582\n",
      "Epoch [96/100], Step [300/625], Loss: 0.0563\n",
      "Epoch [96/100], Step [400/625], Loss: 0.0576\n",
      "Epoch [96/100], Step [500/625], Loss: 0.0530\n",
      "Epoch [96/100], Step [600/625], Loss: 0.0529\n",
      "Epoch [96/100], Validation Loss: 0.5645, Validation Accuracy: 88.15%\n",
      "Epoch [97/100], Step [100/625], Loss: 0.0642\n",
      "Epoch [97/100], Step [200/625], Loss: 0.0524\n",
      "Epoch [97/100], Step [300/625], Loss: 0.0576\n",
      "Epoch [97/100], Step [400/625], Loss: 0.0514\n",
      "Epoch [97/100], Step [500/625], Loss: 0.0608\n",
      "Epoch [97/100], Step [600/625], Loss: 0.0537\n",
      "Epoch [97/100], Validation Loss: 0.5600, Validation Accuracy: 87.99%\n",
      "Epoch [98/100], Step [100/625], Loss: 0.0545\n",
      "Epoch [98/100], Step [200/625], Loss: 0.0535\n",
      "Epoch [98/100], Step [300/625], Loss: 0.0643\n",
      "Epoch [98/100], Step [400/625], Loss: 0.0614\n",
      "Epoch [98/100], Step [500/625], Loss: 0.0595\n",
      "Epoch [98/100], Step [600/625], Loss: 0.0516\n",
      "Epoch [98/100], Validation Loss: 0.5801, Validation Accuracy: 87.74%\n",
      "Epoch [99/100], Step [100/625], Loss: 0.0616\n",
      "Epoch [99/100], Step [200/625], Loss: 0.0507\n",
      "Epoch [99/100], Step [300/625], Loss: 0.0632\n",
      "Epoch [99/100], Step [400/625], Loss: 0.0563\n",
      "Epoch [99/100], Step [500/625], Loss: 0.0629\n",
      "Epoch [99/100], Step [600/625], Loss: 0.0597\n",
      "Epoch [99/100], Validation Loss: 0.5736, Validation Accuracy: 87.85%\n",
      "Epoch [100/100], Step [100/625], Loss: 0.0541\n",
      "Epoch [100/100], Step [200/625], Loss: 0.0598\n",
      "Epoch [100/100], Step [300/625], Loss: 0.0587\n",
      "Epoch [100/100], Step [400/625], Loss: 0.0561\n",
      "Epoch [100/100], Step [500/625], Loss: 0.0531\n",
      "Epoch [100/100], Step [600/625], Loss: 0.0632\n",
      "Epoch [100/100], Validation Loss: 0.5848, Validation Accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "num_epochs, batch_size, learning_rate, model, criterion, optimizer, scheduler = config_test(config_3)\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "torch.save(model.state_dict(), \"model_t3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.87%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw7H8lkoNhFF"
   },
   "source": [
    "# Training Pruned VGG16 (TODO!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzbyaggXNhFF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXES_gnyNhFF"
   },
   "source": [
    "# Training with Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AxwDk_vNhFF"
   },
   "outputs": [],
   "source": [
    "def train_student(student_model, teacher_model, train_loader, val_loader, num_epochs, soft_target_loss_weight, ce_loss_weight, temperature):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    optimizer = torch.optim.SGD(student_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass through teacher model\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "                teacher_probs = nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
    "\n",
    "            # Forward pass through student model\n",
    "            student_outputs = student_model(inputs)\n",
    "            student_probs = nn.functional.log_softmax(student_outputs / temperature, dim=1)\n",
    "\n",
    "            # Compute distillation loss\n",
    "            soft_target_loss = torch.sum(teacher_probs * (teacher_probs.log() - student_probs))/ student_probs.size()[0] * (temperature**2)\n",
    "\n",
    "            label_loss = ce_loss(student_outputs, labels)\n",
    "\n",
    "            loss = soft_target_loss_weight * soft_target_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validate the student model\n",
    "        student_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    torch.save(student_model.state_dict(), \"student_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQg1zr4eNhFF"
   },
   "outputs": [],
   "source": [
    "teacher = VGG16(num_classes)\n",
    "teacher.load_state_dict(torch.load(\"teacher.pth\", weights_only=True))\n",
    "teacher.eval()\n",
    "\n",
    "student = None\n",
    "\n",
    "train_student(student, teacher, train_loader, val_loader, num_epochs,0.25, 0.75, 2 )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
